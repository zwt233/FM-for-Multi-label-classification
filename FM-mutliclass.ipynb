{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-FM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from sklearn.datasets import load_iris,load_digits\n",
    "iris_dataset = load_digits()\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(iris_dataset['data'],iris_dataset['target'],\n",
    "                              test_size=0.25,random_state=0)\n",
    "\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "X_train, X_test, y_train, y_test = torch.from_numpy(X_train), torch.from_numpy(X_test), torch.from_numpy(y_train),torch.from_numpy(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, labels):\n",
    "    preds = output.max(1)[1].type_as(labels)\n",
    "    correct = preds.eq(labels).double()\n",
    "    correct = correct.sum()\n",
    "    return correct / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output1 = model(X_train)\n",
    "    loss_train = F.nll_loss(output1, y_train)\n",
    "    acc_train = accuracy(output1, y_train)\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "    model.eval()\n",
    "    output2 = model(X_test)\n",
    "\n",
    "    loss_val = F.nll_loss(output2,y_test)\n",
    "    acc_val = accuracy(output2,y_test)\n",
    "    \n",
    "    print('Epoch: {:04d}'.format(epoch+1),\n",
    "        'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "              'acc_train: {:.4f}'.format(acc_train.item()),\n",
    "              'acc_val: {:.4f}'.format(acc_val.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchFM(nn.Module):\n",
    "    def __init__(self, classes=None, Feature_number=None, embedding=None):\n",
    "        super().__init__()\n",
    "        # Initially we fill V with random values sampled from Gaussian distribution\n",
    "        # NB: use nn.Parameter to compute gradients\n",
    "        self.classes = classes\n",
    "        self.V = nn.Parameter(torch.randn(classes, Feature_number, embedding),requires_grad=True)\n",
    "        self.lin = nn.Linear(Feature_number, classes)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out_1 = torch.matmul(x,self.V).pow(2).sum(2, keepdim=True).view(self.classes,x.shape[0]).t()\n",
    "        out_2 = torch.matmul(x.pow(2), self.V.pow(2)).sum(2, keepdim=True).view(self.classes,x.shape[0]).t() \n",
    "        \n",
    "        out_inter = 0.5*(out_1 - out_2)\n",
    "        out_lin = self.lin(x)\n",
    "        out = out_inter + out_lin\n",
    "#         out = F.dropout(out, 0.2, training=self.training)\n",
    "        \n",
    "        return F.log_softmax(out, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TorchFM(classes=10, Feature_number=64, embedding=15)\n",
    "optimizer = optim.Adam(model.parameters(), \n",
    "                       lr=0.1, \n",
    "                       weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 0002 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 0003 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 0004 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 0005 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 0006 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 0007 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 0008 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 0009 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 0010 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 0011 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 0012 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 0013 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 0014 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 0015 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 0016 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 0017 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 0018 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 0019 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 0020 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 0021 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 0022 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 0023 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 0024 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 0025 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 0026 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 0027 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 0028 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 0029 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 0030 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 0031 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 0032 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 0033 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 0034 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 0035 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 0036 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 0037 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 0038 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 0039 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 0040 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 0041 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 0042 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 0043 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 0044 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 0045 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 0046 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 0047 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9822\n",
      "Epoch: 0048 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9822\n",
      "Epoch: 0049 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9822\n",
      "Epoch: 0050 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9822\n",
      "Epoch: 0051 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9822\n",
      "Epoch: 0052 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9822\n",
      "Epoch: 0053 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9822\n",
      "Epoch: 0054 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9822\n",
      "Epoch: 0055 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9822\n",
      "Epoch: 0056 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9822\n",
      "Epoch: 0057 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9822\n",
      "Epoch: 0058 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0059 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0060 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0061 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0062 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0063 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0064 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0065 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0066 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0067 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0068 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0069 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0070 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0071 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0072 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0073 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0074 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0075 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0076 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0077 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0078 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0079 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0080 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0081 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0082 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0083 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0084 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0085 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0086 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0087 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0088 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0089 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0090 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0091 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0092 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0093 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0094 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0095 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0096 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0097 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0098 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0099 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0100 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0101 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0102 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0103 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0104 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0105 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0106 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0107 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0108 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0109 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0110 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0111 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0112 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0113 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0114 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0115 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0116 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0117 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0118 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0119 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0120 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0121 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0122 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0123 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0124 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0125 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0126 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0127 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0128 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0129 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0130 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0131 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0132 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0133 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0134 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0135 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0136 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0137 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0138 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0139 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0140 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0141 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0142 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0143 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0144 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0145 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0146 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0147 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0148 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0149 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0150 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0151 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0152 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0153 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0154 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0155 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0156 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0157 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0158 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0159 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0160 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0161 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0162 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0163 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0164 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0165 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0166 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0167 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0168 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0169 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0170 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0171 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0172 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0173 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0174 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0175 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0176 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0177 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0178 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0179 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0180 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0181 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0182 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0183 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0184 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0185 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0186 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0187 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0188 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0189 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0190 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0191 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0192 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0193 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0194 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0195 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0196 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0197 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0198 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0199 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0200 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0201 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0202 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0203 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0204 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0205 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0206 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0207 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0208 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0209 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0210 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0211 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0212 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0213 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0214 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0215 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0216 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0217 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0218 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0219 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0220 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0221 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0222 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0223 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0224 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0225 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0226 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0227 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0228 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0229 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0230 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0231 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0232 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0233 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0234 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0235 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0236 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0237 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0238 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0239 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0240 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0241 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0242 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0243 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0244 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0245 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0246 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0247 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0248 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0249 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0250 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0251 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0252 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0253 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0254 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0255 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0256 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0257 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0258 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0259 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0260 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0261 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0262 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0263 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0264 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0265 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0266 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0267 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0268 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0269 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0270 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0271 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0272 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0273 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0274 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0275 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0276 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0277 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0278 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0279 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0280 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0281 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0282 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0283 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0284 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0285 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0286 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0287 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0288 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0289 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0290 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0291 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0292 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0293 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0294 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0295 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0296 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0297 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0298 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0299 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0300 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0301 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0302 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0303 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0304 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0305 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0306 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0307 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0308 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0309 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0310 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0311 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0312 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0313 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0314 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0315 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0316 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0317 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0318 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0319 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0320 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0321 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0322 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0323 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0324 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0325 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0326 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0327 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0328 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0329 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0330 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0331 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0332 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0333 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0334 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0335 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0336 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0337 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0338 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0339 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0340 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0341 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0342 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0343 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0344 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0345 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0346 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0347 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0348 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0349 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0350 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0351 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0352 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0353 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0354 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0355 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0356 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0357 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0358 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0359 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0360 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0361 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0362 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0363 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0364 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0365 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0366 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0367 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0368 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0369 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0370 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0371 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0372 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0373 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0374 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0375 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0376 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0377 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0378 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0379 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0380 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0381 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0382 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0383 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0384 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0385 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0386 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0387 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0388 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0389 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0390 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0391 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0392 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0393 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0394 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0395 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0396 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0397 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0398 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0399 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0400 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0401 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0402 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0403 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0404 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0405 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0406 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0407 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0408 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0409 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0410 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0411 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0412 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0413 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0414 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0415 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0416 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0417 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0418 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0419 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0420 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0421 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0422 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0423 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0424 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0425 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0426 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0427 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0428 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0429 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0430 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0431 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0432 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0433 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0434 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0435 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0436 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0437 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0438 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0439 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0440 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0441 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0442 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0443 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0444 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0445 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0446 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0447 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0448 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0449 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0450 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0451 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0452 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0453 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0454 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0455 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0456 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0457 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0458 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0459 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0460 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0461 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0462 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0463 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0464 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0465 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0466 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0467 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0468 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0469 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0470 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0471 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0472 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0473 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0474 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0475 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0476 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0477 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0478 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0479 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0480 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0481 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0482 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0483 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0484 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0485 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0486 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0487 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0488 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0489 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0490 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0491 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0492 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0493 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0494 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0495 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0496 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0497 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0498 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0499 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0500 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0501 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0502 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0503 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0504 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0505 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0506 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0507 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0508 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0509 loss_train: 0.0163 acc_train: 0.9993 acc_val: 0.9800\n",
      "Epoch: 0510 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0511 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0512 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0513 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0514 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9822\n",
      "Epoch: 0515 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9822\n",
      "Epoch: 0516 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9822\n",
      "Epoch: 0517 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9822\n",
      "Epoch: 0518 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0519 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0520 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 0521 loss_train: 1.4613 acc_train: 0.9993 acc_val: 0.9822\n",
      "Epoch: 0522 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 0523 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9822\n",
      "Epoch: 0524 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9822\n",
      "Epoch: 0525 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9822\n",
      "Epoch: 0526 loss_train: 4.5580 acc_train: 0.9985 acc_val: 0.9800\n",
      "Epoch: 0527 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 0528 loss_train: 4.8156 acc_train: 0.9985 acc_val: 0.9800\n",
      "Epoch: 0529 loss_train: 6.4460 acc_train: 0.9993 acc_val: 0.9800\n",
      "Epoch: 0530 loss_train: 2.0537 acc_train: 0.9993 acc_val: 0.9733\n",
      "Epoch: 0531 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0532 loss_train: 26.1964 acc_train: 0.9970 acc_val: 0.9711\n",
      "Epoch: 0533 loss_train: 10.9467 acc_train: 0.9985 acc_val: 0.9756\n",
      "Epoch: 0534 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 0535 loss_train: 3.5380 acc_train: 0.9993 acc_val: 0.9800\n",
      "Epoch: 0536 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0537 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0538 loss_train: 0.1047 acc_train: 0.9993 acc_val: 0.9711\n",
      "Epoch: 0539 loss_train: 3.2310 acc_train: 0.9993 acc_val: 0.9689\n",
      "Epoch: 0540 loss_train: 12.5620 acc_train: 0.9978 acc_val: 0.9711\n",
      "Epoch: 0541 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0542 loss_train: 4.2574 acc_train: 0.9993 acc_val: 0.9778\n",
      "Epoch: 0543 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0544 loss_train: 7.4894 acc_train: 0.9985 acc_val: 0.9733\n",
      "Epoch: 0545 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0546 loss_train: 0.8388 acc_train: 0.9993 acc_val: 0.9667\n",
      "Epoch: 0547 loss_train: 14.3499 acc_train: 0.9970 acc_val: 0.9689\n",
      "Epoch: 0548 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0549 loss_train: 8.5948 acc_train: 0.9993 acc_val: 0.9756\n",
      "Epoch: 0550 loss_train: 12.5788 acc_train: 0.9978 acc_val: 0.9711\n",
      "Epoch: 0551 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0552 loss_train: 11.3371 acc_train: 0.9978 acc_val: 0.9733\n",
      "Epoch: 0553 loss_train: 13.2581 acc_train: 0.9970 acc_val: 0.9733\n",
      "Epoch: 0554 loss_train: 4.0844 acc_train: 0.9993 acc_val: 0.9778\n",
      "Epoch: 0555 loss_train: 8.9231 acc_train: 0.9985 acc_val: 0.9778\n",
      "Epoch: 0556 loss_train: 0.5083 acc_train: 0.9993 acc_val: 0.9800\n",
      "Epoch: 0557 loss_train: 10.9186 acc_train: 0.9970 acc_val: 0.9711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0558 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0559 loss_train: 92.1038 acc_train: 0.9918 acc_val: 0.9756\n",
      "Epoch: 0560 loss_train: 3.7024 acc_train: 0.9993 acc_val: 0.9733\n",
      "Epoch: 0561 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 0562 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0563 loss_train: 73.1584 acc_train: 0.9933 acc_val: 0.9756\n",
      "Epoch: 0564 loss_train: 7.0028 acc_train: 0.9993 acc_val: 0.9689\n",
      "Epoch: 0565 loss_train: 171.5203 acc_train: 0.9896 acc_val: 0.9756\n",
      "Epoch: 0566 loss_train: 1.9534 acc_train: 0.9993 acc_val: 0.9756\n",
      "Epoch: 0567 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0568 loss_train: 18.4571 acc_train: 0.9970 acc_val: 0.9711\n",
      "Epoch: 0569 loss_train: 13.3310 acc_train: 0.9978 acc_val: 0.9733\n",
      "Epoch: 0570 loss_train: 5.1041 acc_train: 0.9993 acc_val: 0.9711\n",
      "Epoch: 0571 loss_train: 1.3107 acc_train: 0.9993 acc_val: 0.9689\n",
      "Epoch: 0572 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0573 loss_train: 8.4435 acc_train: 0.9985 acc_val: 0.9644\n",
      "Epoch: 0574 loss_train: 1.9136 acc_train: 0.9985 acc_val: 0.9644\n",
      "Epoch: 0575 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0576 loss_train: 7.9857 acc_train: 0.9993 acc_val: 0.9667\n",
      "Epoch: 0577 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0578 loss_train: 1.1263 acc_train: 0.9993 acc_val: 0.9689\n",
      "Epoch: 0579 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0580 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0581 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0582 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0583 loss_train: 11.4197 acc_train: 0.9978 acc_val: 0.9644\n",
      "Epoch: 0584 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 0585 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 0586 loss_train: 1.6867 acc_train: 0.9993 acc_val: 0.9622\n",
      "Epoch: 0587 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9578\n",
      "Epoch: 0588 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9556\n",
      "Epoch: 0589 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9578\n",
      "Epoch: 0590 loss_train: 4.4347 acc_train: 0.9985 acc_val: 0.9600\n",
      "Epoch: 0591 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0592 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0593 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 0594 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0595 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0596 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0597 loss_train: 2.5554 acc_train: 0.9985 acc_val: 0.9711\n",
      "Epoch: 0598 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0599 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0600 loss_train: 0.0207 acc_train: 0.9993 acc_val: 0.9689\n",
      "Epoch: 0601 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0602 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 0603 loss_train: 0.6493 acc_train: 0.9993 acc_val: 0.9644\n",
      "Epoch: 0604 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 0605 loss_train: 0.1573 acc_train: 0.9993 acc_val: 0.9622\n",
      "Epoch: 0606 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0607 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 0608 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 0609 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0610 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0611 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0612 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 0613 loss_train: 0.3306 acc_train: 0.9993 acc_val: 0.9622\n",
      "Epoch: 0614 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0615 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0616 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0617 loss_train: 0.6055 acc_train: 0.9993 acc_val: 0.9644\n",
      "Epoch: 0618 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 0619 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 0620 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0621 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0622 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0623 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0624 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0625 loss_train: 2.4355 acc_train: 0.9993 acc_val: 0.9622\n",
      "Epoch: 0626 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 0627 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0628 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0629 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0630 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0631 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0632 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 0633 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 0634 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 0635 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 0636 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 0637 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 0638 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 0639 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0640 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0641 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0642 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0643 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0644 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0645 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0646 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0647 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0648 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0649 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0650 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0651 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0652 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0653 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0654 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0655 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0656 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0657 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0658 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0659 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0660 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0661 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0662 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0663 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0664 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0665 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0666 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0667 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0668 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0669 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0670 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0671 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0672 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0673 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0674 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0675 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0676 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0677 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0678 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0679 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0680 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0681 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0682 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0683 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0684 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0685 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0686 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0687 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0688 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0689 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0690 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0691 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0692 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0693 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0694 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0695 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0696 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0697 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0698 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0699 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0700 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0701 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0702 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0703 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0704 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0705 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0706 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0707 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0708 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0709 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0710 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0711 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0712 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0713 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0714 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0715 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0716 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0717 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0718 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0719 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0720 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0721 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0722 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0723 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0724 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0725 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0726 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0727 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0728 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0729 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0730 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0731 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0732 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0733 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0734 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0735 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0736 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0737 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0738 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0739 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0740 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0741 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0742 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0743 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0744 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0745 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0746 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0747 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0748 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0749 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0750 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0751 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0752 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0753 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0754 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0755 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0756 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0757 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0758 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0759 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0760 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0761 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0762 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0763 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0764 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0765 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0766 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0767 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0768 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0769 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0770 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0771 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0772 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0773 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0774 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0775 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0776 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0777 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0778 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0779 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0780 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0781 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0782 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0783 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0784 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0785 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0786 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0787 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0788 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0789 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0790 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0791 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0792 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0793 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0794 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0795 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0796 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0797 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0798 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0799 loss_train: 0.0002 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0800 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0801 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 0802 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0803 loss_train: 1.8493 acc_train: 0.9993 acc_val: 0.9644\n",
      "Epoch: 0804 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 0805 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 0806 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 0807 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0808 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0809 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0810 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0811 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0812 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0813 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0814 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0815 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0816 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0817 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0818 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0819 loss_train: 2.4249 acc_train: 0.9993 acc_val: 0.9667\n",
      "Epoch: 0820 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0821 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0822 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0823 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0824 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0825 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0826 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0827 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0828 loss_train: 2.4408 acc_train: 0.9993 acc_val: 0.9667\n",
      "Epoch: 0829 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0830 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0831 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0832 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0833 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0834 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0835 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0836 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0837 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0838 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0839 loss_train: 2.0724 acc_train: 0.9993 acc_val: 0.9667\n",
      "Epoch: 0840 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0841 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0842 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0843 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0844 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0845 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 0846 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 0847 loss_train: 8.6187 acc_train: 0.9993 acc_val: 0.9667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0848 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0849 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0850 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0851 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0852 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0853 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0854 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0855 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0856 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0857 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0858 loss_train: 5.3919 acc_train: 0.9993 acc_val: 0.9667\n",
      "Epoch: 0859 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0860 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0861 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0862 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0863 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0864 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0865 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0866 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0867 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0868 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0869 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0870 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0871 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0872 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0873 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0874 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0875 loss_train: 1.6108 acc_train: 0.9993 acc_val: 0.9689\n",
      "Epoch: 0876 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0877 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0878 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0879 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0880 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0881 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0882 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0883 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0884 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0885 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0886 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0887 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0888 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0889 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 0890 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 0891 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 0892 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 0893 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 0894 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 0895 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 0896 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 0897 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 0898 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 0899 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 0900 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 0901 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 0902 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 0903 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 0904 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 0905 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 0906 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 0907 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0908 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0909 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0910 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0911 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0912 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0913 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0914 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0915 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0916 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0917 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0918 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0919 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0920 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0921 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0922 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0923 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0924 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0925 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0926 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0927 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0928 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0929 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0930 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0931 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0932 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0933 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0934 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0935 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0936 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0937 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0938 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0939 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0940 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0941 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0942 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0943 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0944 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0945 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0946 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0947 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0948 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0949 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0950 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0951 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0952 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0953 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0954 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0955 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0956 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0957 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0958 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0959 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0960 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0961 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0962 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0963 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0964 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0965 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0966 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0967 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0968 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0969 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0970 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0971 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0972 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0973 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0974 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0975 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0976 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0977 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0978 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0979 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0980 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0981 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0982 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0983 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0984 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0985 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0986 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0987 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0988 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0989 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0990 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0991 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0992 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0993 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0994 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0995 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0996 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0997 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0998 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 0999 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1000 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1001 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1002 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1003 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1004 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1005 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1006 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1007 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1008 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1009 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1010 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1011 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1012 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1013 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1014 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1015 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1016 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1017 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1018 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1019 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1020 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1021 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1022 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1023 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1024 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1025 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1026 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1027 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1028 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1029 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1030 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1031 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1032 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1033 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1034 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1035 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1036 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1037 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1038 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1039 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1040 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1041 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1042 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1043 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1044 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1045 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1046 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1047 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1048 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1049 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1050 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1051 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1052 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1053 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1054 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1055 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1056 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1057 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1058 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1059 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1060 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1061 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1062 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1063 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1064 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1065 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1066 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1067 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1068 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1069 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1070 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1071 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1072 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1073 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1074 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1075 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1076 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1077 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1078 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1079 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1080 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1081 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1082 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1083 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1084 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1085 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1086 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1087 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1088 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1089 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1090 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1091 loss_train: 0.0008 acc_train: 0.9993 acc_val: 0.9667\n",
      "Epoch: 1092 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1093 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1094 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1095 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1096 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1097 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1098 loss_train: 0.1649 acc_train: 0.9993 acc_val: 0.9644\n",
      "Epoch: 1099 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1100 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1101 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1102 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1103 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1104 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1105 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 1106 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 1107 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 1108 loss_train: 3.2381 acc_train: 0.9993 acc_val: 0.9600\n",
      "Epoch: 1109 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1110 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1111 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1112 loss_train: 1.9589 acc_train: 0.9993 acc_val: 0.9622\n",
      "Epoch: 1113 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1114 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1115 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1116 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1117 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1118 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1119 loss_train: 1.0569 acc_train: 0.9993 acc_val: 0.9667\n",
      "Epoch: 1120 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1121 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1122 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1123 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1124 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1125 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1126 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1127 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1128 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1129 loss_train: 0.8357 acc_train: 0.9993 acc_val: 0.9667\n",
      "Epoch: 1130 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1131 loss_train: 7.4545 acc_train: 0.9993 acc_val: 0.9644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1132 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1133 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1134 loss_train: 2.6393 acc_train: 0.9993 acc_val: 0.9622\n",
      "Epoch: 1135 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1136 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1137 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1138 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1139 loss_train: 20.1438 acc_train: 0.9970 acc_val: 0.9667\n",
      "Epoch: 1140 loss_train: 0.5153 acc_train: 0.9993 acc_val: 0.9689\n",
      "Epoch: 1141 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1142 loss_train: 7.4524 acc_train: 0.9993 acc_val: 0.9689\n",
      "Epoch: 1143 loss_train: 11.3899 acc_train: 0.9978 acc_val: 0.9667\n",
      "Epoch: 1144 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1145 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1146 loss_train: 46.3833 acc_train: 0.9963 acc_val: 0.9644\n",
      "Epoch: 1147 loss_train: 8.9559 acc_train: 0.9985 acc_val: 0.9689\n",
      "Epoch: 1148 loss_train: 0.6070 acc_train: 0.9993 acc_val: 0.9667\n",
      "Epoch: 1149 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1150 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1151 loss_train: 11.9656 acc_train: 0.9985 acc_val: 0.9644\n",
      "Epoch: 1152 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1153 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1154 loss_train: 31.3833 acc_train: 0.9985 acc_val: 0.9667\n",
      "Epoch: 1155 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1156 loss_train: 1.4261 acc_train: 0.9993 acc_val: 0.9689\n",
      "Epoch: 1157 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1158 loss_train: 0.1760 acc_train: 0.9993 acc_val: 0.9667\n",
      "Epoch: 1159 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1160 loss_train: 1.6335 acc_train: 0.9993 acc_val: 0.9644\n",
      "Epoch: 1161 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1162 loss_train: 1.1939 acc_train: 0.9985 acc_val: 0.9644\n",
      "Epoch: 1163 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1164 loss_train: 0.1581 acc_train: 0.9993 acc_val: 0.9644\n",
      "Epoch: 1165 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1166 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1167 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1168 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1169 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1170 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1171 loss_train: 2.5680 acc_train: 0.9985 acc_val: 0.9689\n",
      "Epoch: 1172 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1173 loss_train: 1.4955 acc_train: 0.9993 acc_val: 0.9667\n",
      "Epoch: 1174 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1175 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1176 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1177 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1178 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1179 loss_train: 0.5390 acc_train: 0.9993 acc_val: 0.9667\n",
      "Epoch: 1180 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1181 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1182 loss_train: 0.3327 acc_train: 0.9993 acc_val: 0.9689\n",
      "Epoch: 1183 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1184 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1185 loss_train: 3.6096 acc_train: 0.9993 acc_val: 0.9689\n",
      "Epoch: 1186 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1187 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1188 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1189 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1190 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1191 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1192 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1193 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1194 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1195 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1196 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1197 loss_train: 0.1163 acc_train: 0.9993 acc_val: 0.9733\n",
      "Epoch: 1198 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1199 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1200 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1201 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1202 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1203 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1204 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 1205 loss_train: 1.3601 acc_train: 0.9993 acc_val: 0.9600\n",
      "Epoch: 1206 loss_train: 2.5073 acc_train: 0.9993 acc_val: 0.9667\n",
      "Epoch: 1207 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1208 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1209 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1210 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1211 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1212 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1213 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1214 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1215 loss_train: 0.6926 acc_train: 0.9993 acc_val: 0.9689\n",
      "Epoch: 1216 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1217 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1218 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1219 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1220 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1221 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1222 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1223 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1224 loss_train: 6.0456 acc_train: 0.9993 acc_val: 0.9733\n",
      "Epoch: 1225 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1226 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1227 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1228 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1229 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1230 loss_train: 4.1390 acc_train: 0.9985 acc_val: 0.9733\n",
      "Epoch: 1231 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1232 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1233 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1234 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1235 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1236 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1237 loss_train: 3.1193 acc_train: 0.9993 acc_val: 0.9733\n",
      "Epoch: 1238 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 1239 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 1240 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 1241 loss_train: 6.2998 acc_train: 0.9993 acc_val: 0.9778\n",
      "Epoch: 1242 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1243 loss_train: 1.3202 acc_train: 0.9993 acc_val: 0.9778\n",
      "Epoch: 1244 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 1245 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 1246 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 1247 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1248 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1249 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1250 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1251 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1252 loss_train: 1.5166 acc_train: 0.9993 acc_val: 0.9778\n",
      "Epoch: 1253 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1254 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1255 loss_train: 1.1779 acc_train: 0.9993 acc_val: 0.9756\n",
      "Epoch: 1256 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1257 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 1258 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 1259 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 1260 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1261 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1262 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1263 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1264 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1265 loss_train: 5.9547 acc_train: 0.9993 acc_val: 0.9733\n",
      "Epoch: 1266 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1267 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1268 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1269 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1270 loss_train: 1.8713 acc_train: 0.9993 acc_val: 0.9711\n",
      "Epoch: 1271 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1272 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1273 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1274 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1275 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1276 loss_train: 0.7613 acc_train: 0.9993 acc_val: 0.9711\n",
      "Epoch: 1277 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1278 loss_train: 6.2024 acc_train: 0.9993 acc_val: 0.9778\n",
      "Epoch: 1279 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 1280 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 1281 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 1282 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 1283 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 1284 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1285 loss_train: 4.8341 acc_train: 0.9993 acc_val: 0.9778\n",
      "Epoch: 1286 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 1287 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1288 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1289 loss_train: 1.4177 acc_train: 0.9985 acc_val: 0.9711\n",
      "Epoch: 1290 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1291 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1292 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1293 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1294 loss_train: 0.4633 acc_train: 0.9993 acc_val: 0.9689\n",
      "Epoch: 1295 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1296 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1297 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1298 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1299 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1300 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1301 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1302 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1303 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1304 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1305 loss_train: 6.2507 acc_train: 0.9993 acc_val: 0.9711\n",
      "Epoch: 1306 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1307 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1308 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1309 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1310 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1311 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1312 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1313 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1314 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1315 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 1316 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 1317 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 1318 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 1319 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 1320 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1321 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1322 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1323 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1324 loss_train: 0.3153 acc_train: 0.9993 acc_val: 0.9733\n",
      "Epoch: 1325 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1326 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1327 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1328 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1329 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1330 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1331 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1332 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1333 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1334 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1335 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1336 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1337 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1338 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1339 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1340 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1341 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1342 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1343 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1344 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1345 loss_train: 0.3510 acc_train: 0.9993 acc_val: 0.9622\n",
      "Epoch: 1346 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1347 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1348 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1349 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1350 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1351 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1352 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1353 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1354 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1355 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1356 loss_train: 1.0321 acc_train: 0.9993 acc_val: 0.9689\n",
      "Epoch: 1357 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1358 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1359 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1360 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1361 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1362 loss_train: 5.6401 acc_train: 0.9985 acc_val: 0.9622\n",
      "Epoch: 1363 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1364 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1365 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1366 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1367 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1368 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1369 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1370 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1371 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1372 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1373 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1374 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1375 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1376 loss_train: 0.6072 acc_train: 0.9993 acc_val: 0.9644\n",
      "Epoch: 1377 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1378 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1379 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1380 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 1381 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9556\n",
      "Epoch: 1382 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9578\n",
      "Epoch: 1383 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9578\n",
      "Epoch: 1384 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9578\n",
      "Epoch: 1385 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 1386 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9578\n",
      "Epoch: 1387 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9578\n",
      "Epoch: 1388 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9578\n",
      "Epoch: 1389 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9578\n",
      "Epoch: 1390 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9578\n",
      "Epoch: 1391 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9578\n",
      "Epoch: 1392 loss_train: 1.0281 acc_train: 0.9993 acc_val: 0.9578\n",
      "Epoch: 1393 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9578\n",
      "Epoch: 1394 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9578\n",
      "Epoch: 1395 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9578\n",
      "Epoch: 1396 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9578\n",
      "Epoch: 1397 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 1398 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9578\n",
      "Epoch: 1399 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 1400 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 1401 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 1402 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9600\n",
      "Epoch: 1403 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1404 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1405 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1406 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1407 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1408 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1409 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1410 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1411 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1412 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1413 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1414 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1415 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1416 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1417 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1418 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1419 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1420 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1421 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1422 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1423 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1424 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1425 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1426 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1427 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1428 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1429 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1430 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1431 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1432 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1433 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1434 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1435 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1436 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1437 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1438 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1439 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1440 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1441 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1442 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1443 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1444 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1445 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1446 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1447 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1448 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1449 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1450 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1451 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1452 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1453 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1454 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1455 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1456 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1457 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1458 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1459 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1460 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1461 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1462 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1463 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1464 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1465 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1466 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1467 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1468 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1469 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1470 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1471 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1472 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1473 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1474 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1475 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1476 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1477 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1478 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1479 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1480 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1481 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1482 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1483 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1484 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1485 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1486 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1487 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1488 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1489 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1490 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1491 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1492 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1493 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1494 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1495 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1496 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1497 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1498 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1499 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1500 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1501 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1502 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1503 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1504 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1505 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1506 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1507 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1508 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1509 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1510 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1511 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1512 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1513 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1514 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1515 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1516 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1517 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1518 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1519 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1520 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1521 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1522 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1523 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1524 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1525 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1526 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1527 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1528 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1529 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1530 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1531 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1532 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1533 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1534 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1535 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1536 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1537 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1538 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9622\n",
      "Epoch: 1539 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1540 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1541 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1542 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1543 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1544 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1545 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1546 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1547 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1548 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1549 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1550 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1551 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1552 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1553 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1554 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1555 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1556 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1557 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1558 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1559 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1560 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1561 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1562 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1563 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1564 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1565 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1566 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1567 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1568 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1569 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1570 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1571 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1572 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1573 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1574 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1575 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1576 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1577 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1578 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1579 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1580 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1581 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1582 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1583 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1584 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1585 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1586 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1587 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1588 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1589 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1590 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1591 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1592 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1593 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1594 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1595 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1596 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1597 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1598 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1599 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1600 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1601 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1602 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1603 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1604 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1605 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1606 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1607 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1608 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1609 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1610 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1611 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1612 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1613 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1614 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1615 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1616 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1617 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1618 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1619 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1620 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1621 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1622 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1623 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1624 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1625 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1626 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1627 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1628 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1629 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1630 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1631 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1632 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1633 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1634 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1635 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1636 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1637 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1638 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1639 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1640 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1641 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1642 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1643 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1644 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1645 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1646 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1647 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1648 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1649 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1650 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1651 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1652 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1653 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1654 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1655 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1656 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1657 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1658 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1659 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1660 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1661 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1662 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1663 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1664 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1665 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1666 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1667 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1668 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1669 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1670 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1671 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1672 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1673 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1674 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1675 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1676 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1677 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1678 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1679 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1680 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1681 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1682 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1683 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1684 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1685 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1686 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1687 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1688 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1689 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1690 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1691 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1692 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1693 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1694 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1695 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1696 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1697 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1698 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1699 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1700 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1701 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1702 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1703 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1704 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1705 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1706 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1707 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1708 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1709 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1710 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1711 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1712 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1713 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1714 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1715 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1716 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1717 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1718 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1719 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1720 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1721 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1722 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1723 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1724 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1725 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1726 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1727 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1728 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1729 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1730 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1731 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1732 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1733 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1734 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1735 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1736 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1737 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1738 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1739 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1740 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1741 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1742 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1743 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1744 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1745 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1746 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1747 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1748 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1749 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1750 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1751 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1752 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1753 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1754 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1755 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1756 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1757 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1758 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1759 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1760 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1761 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1762 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1763 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1764 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1765 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1766 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1767 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1768 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1769 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1770 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1771 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1772 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1773 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1774 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1775 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1776 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1777 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1778 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1779 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1780 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1781 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1782 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1783 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1784 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1785 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1786 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1787 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1788 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1789 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1790 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1791 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1792 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1793 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1794 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1795 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1796 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1797 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1798 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1799 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1800 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1801 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1802 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1803 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1804 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1805 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1806 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1807 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1808 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1809 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1810 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1811 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1812 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1813 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1814 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1815 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1816 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1817 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1818 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1819 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1820 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1821 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1822 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1823 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1824 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1825 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1826 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1827 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1828 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1829 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1830 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1831 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1832 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1833 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1834 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1835 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1836 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1837 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1838 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1839 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1840 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1841 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1842 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1843 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1844 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1845 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1846 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1847 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1848 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1849 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1850 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1851 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1852 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1853 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1854 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1855 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1856 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1857 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1858 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1859 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1860 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1861 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1862 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1863 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1864 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1865 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1866 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1867 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1868 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1869 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1870 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1871 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1872 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1873 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9644\n",
      "Epoch: 1874 loss_train: 0.0348 acc_train: 0.9993 acc_val: 0.9644\n",
      "Epoch: 1875 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1876 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1877 loss_train: 7.6329 acc_train: 0.9993 acc_val: 0.9756\n",
      "Epoch: 1878 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1879 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1880 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1881 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1882 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1883 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1884 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1885 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1886 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1887 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1888 loss_train: 2.6045 acc_train: 0.9985 acc_val: 0.9689\n",
      "Epoch: 1889 loss_train: 20.2527 acc_train: 0.9978 acc_val: 0.9733\n",
      "Epoch: 1890 loss_train: 2.2397 acc_train: 0.9993 acc_val: 0.9800\n",
      "Epoch: 1891 loss_train: 8.0331 acc_train: 0.9993 acc_val: 0.9822\n",
      "Epoch: 1892 loss_train: 14.9728 acc_train: 0.9985 acc_val: 0.9844\n",
      "Epoch: 1893 loss_train: 1.4507 acc_train: 0.9993 acc_val: 0.9689\n",
      "Epoch: 1894 loss_train: 62.8807 acc_train: 0.9978 acc_val: 0.9689\n",
      "Epoch: 1895 loss_train: 52.9831 acc_train: 0.9970 acc_val: 0.9822\n",
      "Epoch: 1896 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1897 loss_train: 14.8070 acc_train: 0.9993 acc_val: 0.9733\n",
      "Epoch: 1898 loss_train: 14.1614 acc_train: 0.9993 acc_val: 0.9756\n",
      "Epoch: 1899 loss_train: 16.9508 acc_train: 0.9978 acc_val: 0.9822\n",
      "Epoch: 1900 loss_train: 10.1069 acc_train: 0.9985 acc_val: 0.9844\n",
      "Epoch: 1901 loss_train: 6.2771 acc_train: 0.9985 acc_val: 0.9822\n",
      "Epoch: 1902 loss_train: 36.4005 acc_train: 0.9963 acc_val: 0.9756\n",
      "Epoch: 1903 loss_train: 0.0620 acc_train: 0.9993 acc_val: 0.9778\n",
      "Epoch: 1904 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 1905 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1906 loss_train: 45.8620 acc_train: 0.9970 acc_val: 0.9689\n",
      "Epoch: 1907 loss_train: 218.0193 acc_train: 0.9889 acc_val: 0.9756\n",
      "Epoch: 1908 loss_train: 23.5188 acc_train: 0.9978 acc_val: 0.9644\n",
      "Epoch: 1909 loss_train: 333.5351 acc_train: 0.9903 acc_val: 0.9667\n",
      "Epoch: 1910 loss_train: 144.5279 acc_train: 0.9955 acc_val: 0.9778\n",
      "Epoch: 1911 loss_train: 12.8468 acc_train: 0.9993 acc_val: 0.9800\n",
      "Epoch: 1912 loss_train: 97.4558 acc_train: 0.9963 acc_val: 0.9756\n",
      "Epoch: 1913 loss_train: 414.9342 acc_train: 0.9866 acc_val: 0.9822\n",
      "Epoch: 1914 loss_train: 19.4716 acc_train: 0.9985 acc_val: 0.9711\n",
      "Epoch: 1915 loss_train: 336.4604 acc_train: 0.9933 acc_val: 0.9600\n",
      "Epoch: 1916 loss_train: 690.9601 acc_train: 0.9807 acc_val: 0.9689\n",
      "Epoch: 1917 loss_train: 20.6146 acc_train: 0.9970 acc_val: 0.9622\n",
      "Epoch: 1918 loss_train: 111.4796 acc_train: 0.9933 acc_val: 0.9533\n",
      "Epoch: 1919 loss_train: 741.5926 acc_train: 0.9822 acc_val: 0.9733\n",
      "Epoch: 1920 loss_train: 28.9311 acc_train: 0.9970 acc_val: 0.9667\n",
      "Epoch: 1921 loss_train: 520.3813 acc_train: 0.9859 acc_val: 0.9644\n",
      "Epoch: 1922 loss_train: 127.5089 acc_train: 0.9941 acc_val: 0.9556\n",
      "Epoch: 1923 loss_train: 588.8590 acc_train: 0.9829 acc_val: 0.9778\n",
      "Epoch: 1924 loss_train: 65.4065 acc_train: 0.9963 acc_val: 0.9689\n",
      "Epoch: 1925 loss_train: 47.5915 acc_train: 0.9963 acc_val: 0.9644\n",
      "Epoch: 1926 loss_train: 218.5096 acc_train: 0.9903 acc_val: 0.9689\n",
      "Epoch: 1927 loss_train: 83.4872 acc_train: 0.9955 acc_val: 0.9600\n",
      "Epoch: 1928 loss_train: 439.1590 acc_train: 0.9837 acc_val: 0.9711\n",
      "Epoch: 1929 loss_train: 11.8663 acc_train: 0.9993 acc_val: 0.9711\n",
      "Epoch: 1930 loss_train: 152.6433 acc_train: 0.9933 acc_val: 0.9711\n",
      "Epoch: 1931 loss_train: 101.2495 acc_train: 0.9926 acc_val: 0.9733\n",
      "Epoch: 1932 loss_train: 39.0168 acc_train: 0.9970 acc_val: 0.9756\n",
      "Epoch: 1933 loss_train: 43.7279 acc_train: 0.9955 acc_val: 0.9733\n",
      "Epoch: 1934 loss_train: 76.3169 acc_train: 0.9955 acc_val: 0.9711\n",
      "Epoch: 1935 loss_train: 17.1733 acc_train: 0.9970 acc_val: 0.9733\n",
      "Epoch: 1936 loss_train: 39.4937 acc_train: 0.9985 acc_val: 0.9711\n",
      "Epoch: 1937 loss_train: 54.5968 acc_train: 0.9955 acc_val: 0.9778\n",
      "Epoch: 1938 loss_train: 6.4303 acc_train: 0.9978 acc_val: 0.9822\n",
      "Epoch: 1939 loss_train: 31.6103 acc_train: 0.9970 acc_val: 0.9822\n",
      "Epoch: 1940 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 1941 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 1942 loss_train: 5.6195 acc_train: 0.9993 acc_val: 0.9756\n",
      "Epoch: 1943 loss_train: 3.6955 acc_train: 0.9985 acc_val: 0.9733\n",
      "Epoch: 1944 loss_train: 14.0684 acc_train: 0.9970 acc_val: 0.9711\n",
      "Epoch: 1945 loss_train: 45.1770 acc_train: 0.9970 acc_val: 0.9733\n",
      "Epoch: 1946 loss_train: 11.6110 acc_train: 0.9985 acc_val: 0.9778\n",
      "Epoch: 1947 loss_train: 3.2103 acc_train: 0.9993 acc_val: 0.9733\n",
      "Epoch: 1948 loss_train: 25.8922 acc_train: 0.9985 acc_val: 0.9711\n",
      "Epoch: 1949 loss_train: 15.7660 acc_train: 0.9985 acc_val: 0.9778\n",
      "Epoch: 1950 loss_train: 4.0565 acc_train: 0.9993 acc_val: 0.9756\n",
      "Epoch: 1951 loss_train: 4.8466 acc_train: 0.9985 acc_val: 0.9756\n",
      "Epoch: 1952 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 1953 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1954 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1955 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1956 loss_train: 13.3699 acc_train: 0.9985 acc_val: 0.9756\n",
      "Epoch: 1957 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 1958 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9822\n",
      "Epoch: 1959 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 1960 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 1961 loss_train: 1.9950 acc_train: 0.9993 acc_val: 0.9844\n",
      "Epoch: 1962 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 1963 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 1964 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9844\n",
      "Epoch: 1965 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 1966 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9800\n",
      "Epoch: 1967 loss_train: 1.3389 acc_train: 0.9993 acc_val: 0.9844\n",
      "Epoch: 1968 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9889\n",
      "Epoch: 1969 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9889\n",
      "Epoch: 1970 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9867\n",
      "Epoch: 1971 loss_train: 0.5289 acc_train: 0.9993 acc_val: 0.9889\n",
      "Epoch: 1972 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9889\n",
      "Epoch: 1973 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9889\n",
      "Epoch: 1974 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9889\n",
      "Epoch: 1975 loss_train: 1.4201 acc_train: 0.9993 acc_val: 0.9889\n",
      "Epoch: 1976 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9911\n",
      "Epoch: 1977 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9911\n",
      "Epoch: 1978 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9911\n",
      "Epoch: 1979 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9911\n",
      "Epoch: 1980 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9889\n",
      "Epoch: 1981 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9867\n",
      "Epoch: 1982 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9867\n",
      "Epoch: 1983 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9867\n",
      "Epoch: 1984 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9867\n",
      "Epoch: 1985 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9867\n",
      "Epoch: 1986 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9867\n",
      "Epoch: 1987 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9867\n",
      "Epoch: 1988 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9867\n",
      "Epoch: 1989 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9867\n",
      "Epoch: 1990 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9867\n",
      "Epoch: 1991 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9867\n",
      "Epoch: 1992 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9867\n",
      "Epoch: 1993 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9867\n",
      "Epoch: 1994 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9867\n",
      "Epoch: 1995 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9867\n",
      "Epoch: 1996 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9867\n",
      "Epoch: 1997 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1998 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9867\n",
      "Epoch: 1999 loss_train: 0.7551 acc_train: 0.9993 acc_val: 0.9867\n",
      "Epoch: 2000 loss_train: 0.0000 acc_train: 1.0000 acc_val: 0.9911\n",
      "Optimization Finished!\n",
      "Total time elapsed: 20.0369s\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "t_total = time.time()\n",
    "for epoch in range(2000):\n",
    "    train(epoch,model)\n",
    "print(\"Optimization Finished!\")\n",
    "print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 layers DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "     def __init__(self,n_feature,n_hidden,n_out):\n",
    "          super(Net,self).__init__()\n",
    "          self.hidden = nn.Linear(n_feature,n_hidden)\n",
    "          self.out = nn.Linear(n_hidden,n_out)\n",
    " \n",
    "     def forward(self, x):\n",
    "          x = F.relu(self.hidden(x))\n",
    "#           x = F.dropout(x, 0.1, training=self.training)\n",
    "          x = self.out(x)\n",
    "#           x = F.dropout(x, 0.2, training=self.training)\n",
    "          out = F.log_softmax(x,dim=1)\n",
    "          return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(n_feature=64,n_hidden=20,n_out=10)\n",
    "# optimizer = torch.optim.SGD(model.parameters(),lr=0.03)\n",
    "optimizer = optim.Adam(model.parameters(), \n",
    "                       lr=0.01, \n",
    "                       weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss_train: 3.8761 acc_train: 0.1180 acc_val: 0.1267\n",
      "Epoch: 0002 loss_train: 2.6177 acc_train: 0.1203 acc_val: 0.2978\n",
      "Epoch: 0003 loss_train: 2.1371 acc_train: 0.2687 acc_val: 0.3600\n",
      "Epoch: 0004 loss_train: 2.0204 acc_train: 0.3393 acc_val: 0.3756\n",
      "Epoch: 0005 loss_train: 1.9621 acc_train: 0.3749 acc_val: 0.4089\n",
      "Epoch: 0006 loss_train: 1.7955 acc_train: 0.4558 acc_val: 0.4556\n",
      "Epoch: 0007 loss_train: 1.5877 acc_train: 0.4878 acc_val: 0.5244\n",
      "Epoch: 0008 loss_train: 1.3870 acc_train: 0.5219 acc_val: 0.5844\n",
      "Epoch: 0009 loss_train: 1.2254 acc_train: 0.5857 acc_val: 0.6444\n",
      "Epoch: 0010 loss_train: 1.1120 acc_train: 0.6511 acc_val: 0.6689\n",
      "Epoch: 0011 loss_train: 1.0049 acc_train: 0.7023 acc_val: 0.7111\n",
      "Epoch: 0012 loss_train: 0.9072 acc_train: 0.7424 acc_val: 0.7511\n",
      "Epoch: 0013 loss_train: 0.8257 acc_train: 0.7743 acc_val: 0.7844\n",
      "Epoch: 0014 loss_train: 0.7585 acc_train: 0.7854 acc_val: 0.7956\n",
      "Epoch: 0015 loss_train: 0.7003 acc_train: 0.8040 acc_val: 0.8111\n",
      "Epoch: 0016 loss_train: 0.6453 acc_train: 0.8218 acc_val: 0.8356\n",
      "Epoch: 0017 loss_train: 0.5894 acc_train: 0.8255 acc_val: 0.8511\n",
      "Epoch: 0018 loss_train: 0.5381 acc_train: 0.8434 acc_val: 0.8444\n",
      "Epoch: 0019 loss_train: 0.4926 acc_train: 0.8545 acc_val: 0.8533\n",
      "Epoch: 0020 loss_train: 0.4521 acc_train: 0.8693 acc_val: 0.8733\n",
      "Epoch: 0021 loss_train: 0.4153 acc_train: 0.8805 acc_val: 0.8867\n",
      "Epoch: 0022 loss_train: 0.3828 acc_train: 0.8909 acc_val: 0.9000\n",
      "Epoch: 0023 loss_train: 0.3557 acc_train: 0.8976 acc_val: 0.9044\n",
      "Epoch: 0024 loss_train: 0.3345 acc_train: 0.9042 acc_val: 0.9067\n",
      "Epoch: 0025 loss_train: 0.3185 acc_train: 0.9065 acc_val: 0.9067\n",
      "Epoch: 0026 loss_train: 0.3060 acc_train: 0.9072 acc_val: 0.9089\n",
      "Epoch: 0027 loss_train: 0.2928 acc_train: 0.9102 acc_val: 0.9156\n",
      "Epoch: 0028 loss_train: 0.2780 acc_train: 0.9124 acc_val: 0.9200\n",
      "Epoch: 0029 loss_train: 0.2651 acc_train: 0.9176 acc_val: 0.9244\n",
      "Epoch: 0030 loss_train: 0.2551 acc_train: 0.9213 acc_val: 0.9222\n",
      "Epoch: 0031 loss_train: 0.2445 acc_train: 0.9265 acc_val: 0.9267\n",
      "Epoch: 0032 loss_train: 0.2324 acc_train: 0.9295 acc_val: 0.9356\n",
      "Epoch: 0033 loss_train: 0.2221 acc_train: 0.9310 acc_val: 0.9444\n",
      "Epoch: 0034 loss_train: 0.2141 acc_train: 0.9339 acc_val: 0.9489\n",
      "Epoch: 0035 loss_train: 0.2059 acc_train: 0.9339 acc_val: 0.9489\n",
      "Epoch: 0036 loss_train: 0.1964 acc_train: 0.9376 acc_val: 0.9444\n",
      "Epoch: 0037 loss_train: 0.1874 acc_train: 0.9391 acc_val: 0.9511\n",
      "Epoch: 0038 loss_train: 0.1800 acc_train: 0.9421 acc_val: 0.9511\n",
      "Epoch: 0039 loss_train: 0.1739 acc_train: 0.9443 acc_val: 0.9556\n",
      "Epoch: 0040 loss_train: 0.1680 acc_train: 0.9473 acc_val: 0.9556\n",
      "Epoch: 0041 loss_train: 0.1618 acc_train: 0.9525 acc_val: 0.9578\n",
      "Epoch: 0042 loss_train: 0.1558 acc_train: 0.9555 acc_val: 0.9578\n",
      "Epoch: 0043 loss_train: 0.1498 acc_train: 0.9599 acc_val: 0.9556\n",
      "Epoch: 0044 loss_train: 0.1442 acc_train: 0.9629 acc_val: 0.9533\n",
      "Epoch: 0045 loss_train: 0.1392 acc_train: 0.9651 acc_val: 0.9533\n",
      "Epoch: 0046 loss_train: 0.1347 acc_train: 0.9659 acc_val: 0.9556\n",
      "Epoch: 0047 loss_train: 0.1304 acc_train: 0.9681 acc_val: 0.9533\n",
      "Epoch: 0048 loss_train: 0.1263 acc_train: 0.9681 acc_val: 0.9578\n",
      "Epoch: 0049 loss_train: 0.1225 acc_train: 0.9703 acc_val: 0.9578\n",
      "Epoch: 0050 loss_train: 0.1190 acc_train: 0.9718 acc_val: 0.9600\n",
      "Epoch: 0051 loss_train: 0.1156 acc_train: 0.9733 acc_val: 0.9600\n",
      "Epoch: 0052 loss_train: 0.1125 acc_train: 0.9740 acc_val: 0.9556\n",
      "Epoch: 0053 loss_train: 0.1098 acc_train: 0.9748 acc_val: 0.9556\n",
      "Epoch: 0054 loss_train: 0.1072 acc_train: 0.9755 acc_val: 0.9578\n",
      "Epoch: 0055 loss_train: 0.1047 acc_train: 0.9755 acc_val: 0.9600\n",
      "Epoch: 0056 loss_train: 0.1022 acc_train: 0.9762 acc_val: 0.9644\n",
      "Epoch: 0057 loss_train: 0.0997 acc_train: 0.9762 acc_val: 0.9644\n",
      "Epoch: 0058 loss_train: 0.0973 acc_train: 0.9785 acc_val: 0.9667\n",
      "Epoch: 0059 loss_train: 0.0952 acc_train: 0.9792 acc_val: 0.9667\n",
      "Epoch: 0060 loss_train: 0.0931 acc_train: 0.9814 acc_val: 0.9667\n",
      "Epoch: 0061 loss_train: 0.0911 acc_train: 0.9822 acc_val: 0.9644\n",
      "Epoch: 0062 loss_train: 0.0891 acc_train: 0.9837 acc_val: 0.9689\n",
      "Epoch: 0063 loss_train: 0.0872 acc_train: 0.9837 acc_val: 0.9689\n",
      "Epoch: 0064 loss_train: 0.0854 acc_train: 0.9829 acc_val: 0.9689\n",
      "Epoch: 0065 loss_train: 0.0837 acc_train: 0.9837 acc_val: 0.9644\n",
      "Epoch: 0066 loss_train: 0.0819 acc_train: 0.9837 acc_val: 0.9644\n",
      "Epoch: 0067 loss_train: 0.0803 acc_train: 0.9837 acc_val: 0.9667\n",
      "Epoch: 0068 loss_train: 0.0788 acc_train: 0.9837 acc_val: 0.9667\n",
      "Epoch: 0069 loss_train: 0.0774 acc_train: 0.9844 acc_val: 0.9689\n",
      "Epoch: 0070 loss_train: 0.0759 acc_train: 0.9844 acc_val: 0.9711\n",
      "Epoch: 0071 loss_train: 0.0746 acc_train: 0.9844 acc_val: 0.9711\n",
      "Epoch: 0072 loss_train: 0.0733 acc_train: 0.9852 acc_val: 0.9711\n",
      "Epoch: 0073 loss_train: 0.0720 acc_train: 0.9852 acc_val: 0.9711\n",
      "Epoch: 0074 loss_train: 0.0707 acc_train: 0.9852 acc_val: 0.9689\n",
      "Epoch: 0075 loss_train: 0.0696 acc_train: 0.9852 acc_val: 0.9689\n",
      "Epoch: 0076 loss_train: 0.0684 acc_train: 0.9859 acc_val: 0.9689\n",
      "Epoch: 0077 loss_train: 0.0672 acc_train: 0.9859 acc_val: 0.9689\n",
      "Epoch: 0078 loss_train: 0.0661 acc_train: 0.9866 acc_val: 0.9711\n",
      "Epoch: 0079 loss_train: 0.0650 acc_train: 0.9874 acc_val: 0.9711\n",
      "Epoch: 0080 loss_train: 0.0639 acc_train: 0.9874 acc_val: 0.9711\n",
      "Epoch: 0081 loss_train: 0.0628 acc_train: 0.9874 acc_val: 0.9711\n",
      "Epoch: 0082 loss_train: 0.0618 acc_train: 0.9874 acc_val: 0.9711\n",
      "Epoch: 0083 loss_train: 0.0608 acc_train: 0.9874 acc_val: 0.9711\n",
      "Epoch: 0084 loss_train: 0.0598 acc_train: 0.9874 acc_val: 0.9711\n",
      "Epoch: 0085 loss_train: 0.0589 acc_train: 0.9881 acc_val: 0.9689\n",
      "Epoch: 0086 loss_train: 0.0579 acc_train: 0.9889 acc_val: 0.9667\n",
      "Epoch: 0087 loss_train: 0.0570 acc_train: 0.9889 acc_val: 0.9689\n",
      "Epoch: 0088 loss_train: 0.0561 acc_train: 0.9889 acc_val: 0.9689\n",
      "Epoch: 0089 loss_train: 0.0552 acc_train: 0.9889 acc_val: 0.9689\n",
      "Epoch: 0090 loss_train: 0.0544 acc_train: 0.9896 acc_val: 0.9689\n",
      "Epoch: 0091 loss_train: 0.0535 acc_train: 0.9896 acc_val: 0.9667\n",
      "Epoch: 0092 loss_train: 0.0527 acc_train: 0.9896 acc_val: 0.9667\n",
      "Epoch: 0093 loss_train: 0.0519 acc_train: 0.9896 acc_val: 0.9689\n",
      "Epoch: 0094 loss_train: 0.0511 acc_train: 0.9896 acc_val: 0.9689\n",
      "Epoch: 0095 loss_train: 0.0504 acc_train: 0.9896 acc_val: 0.9689\n",
      "Epoch: 0096 loss_train: 0.0496 acc_train: 0.9896 acc_val: 0.9711\n",
      "Epoch: 0097 loss_train: 0.0489 acc_train: 0.9903 acc_val: 0.9711\n",
      "Epoch: 0098 loss_train: 0.0481 acc_train: 0.9903 acc_val: 0.9711\n",
      "Epoch: 0099 loss_train: 0.0474 acc_train: 0.9903 acc_val: 0.9711\n",
      "Epoch: 0100 loss_train: 0.0467 acc_train: 0.9903 acc_val: 0.9689\n",
      "Epoch: 0101 loss_train: 0.0460 acc_train: 0.9911 acc_val: 0.9689\n",
      "Epoch: 0102 loss_train: 0.0454 acc_train: 0.9926 acc_val: 0.9689\n",
      "Epoch: 0103 loss_train: 0.0447 acc_train: 0.9926 acc_val: 0.9711\n",
      "Epoch: 0104 loss_train: 0.0441 acc_train: 0.9926 acc_val: 0.9711\n",
      "Epoch: 0105 loss_train: 0.0434 acc_train: 0.9926 acc_val: 0.9711\n",
      "Epoch: 0106 loss_train: 0.0428 acc_train: 0.9926 acc_val: 0.9711\n",
      "Epoch: 0107 loss_train: 0.0422 acc_train: 0.9926 acc_val: 0.9711\n",
      "Epoch: 0108 loss_train: 0.0416 acc_train: 0.9926 acc_val: 0.9711\n",
      "Epoch: 0109 loss_train: 0.0410 acc_train: 0.9926 acc_val: 0.9711\n",
      "Epoch: 0110 loss_train: 0.0404 acc_train: 0.9926 acc_val: 0.9711\n",
      "Epoch: 0111 loss_train: 0.0399 acc_train: 0.9926 acc_val: 0.9711\n",
      "Epoch: 0112 loss_train: 0.0393 acc_train: 0.9926 acc_val: 0.9711\n",
      "Epoch: 0113 loss_train: 0.0388 acc_train: 0.9926 acc_val: 0.9711\n",
      "Epoch: 0114 loss_train: 0.0382 acc_train: 0.9926 acc_val: 0.9667\n",
      "Epoch: 0115 loss_train: 0.0377 acc_train: 0.9926 acc_val: 0.9667\n",
      "Epoch: 0116 loss_train: 0.0372 acc_train: 0.9926 acc_val: 0.9667\n",
      "Epoch: 0117 loss_train: 0.0367 acc_train: 0.9926 acc_val: 0.9667\n",
      "Epoch: 0118 loss_train: 0.0362 acc_train: 0.9926 acc_val: 0.9667\n",
      "Epoch: 0119 loss_train: 0.0357 acc_train: 0.9926 acc_val: 0.9667\n",
      "Epoch: 0120 loss_train: 0.0352 acc_train: 0.9926 acc_val: 0.9667\n",
      "Epoch: 0121 loss_train: 0.0347 acc_train: 0.9933 acc_val: 0.9689\n",
      "Epoch: 0122 loss_train: 0.0342 acc_train: 0.9941 acc_val: 0.9689\n",
      "Epoch: 0123 loss_train: 0.0337 acc_train: 0.9948 acc_val: 0.9689\n",
      "Epoch: 0124 loss_train: 0.0333 acc_train: 0.9948 acc_val: 0.9689\n",
      "Epoch: 0125 loss_train: 0.0328 acc_train: 0.9948 acc_val: 0.9689\n",
      "Epoch: 0126 loss_train: 0.0323 acc_train: 0.9955 acc_val: 0.9689\n",
      "Epoch: 0127 loss_train: 0.0319 acc_train: 0.9955 acc_val: 0.9689\n",
      "Epoch: 0128 loss_train: 0.0315 acc_train: 0.9955 acc_val: 0.9689\n",
      "Epoch: 0129 loss_train: 0.0310 acc_train: 0.9963 acc_val: 0.9689\n",
      "Epoch: 0130 loss_train: 0.0305 acc_train: 0.9963 acc_val: 0.9689\n",
      "Epoch: 0131 loss_train: 0.0301 acc_train: 0.9963 acc_val: 0.9689\n",
      "Epoch: 0132 loss_train: 0.0297 acc_train: 0.9963 acc_val: 0.9689\n",
      "Epoch: 0133 loss_train: 0.0293 acc_train: 0.9963 acc_val: 0.9689\n",
      "Epoch: 0134 loss_train: 0.0289 acc_train: 0.9963 acc_val: 0.9689\n",
      "Epoch: 0135 loss_train: 0.0285 acc_train: 0.9963 acc_val: 0.9689\n",
      "Epoch: 0136 loss_train: 0.0281 acc_train: 0.9963 acc_val: 0.9689\n",
      "Epoch: 0137 loss_train: 0.0277 acc_train: 0.9963 acc_val: 0.9689\n",
      "Epoch: 0138 loss_train: 0.0273 acc_train: 0.9963 acc_val: 0.9711\n",
      "Epoch: 0139 loss_train: 0.0269 acc_train: 0.9970 acc_val: 0.9711\n",
      "Epoch: 0140 loss_train: 0.0265 acc_train: 0.9970 acc_val: 0.9711\n",
      "Epoch: 0141 loss_train: 0.0262 acc_train: 0.9978 acc_val: 0.9711\n",
      "Epoch: 0142 loss_train: 0.0258 acc_train: 0.9978 acc_val: 0.9711\n",
      "Epoch: 0143 loss_train: 0.0254 acc_train: 0.9978 acc_val: 0.9733\n",
      "Epoch: 0144 loss_train: 0.0251 acc_train: 0.9978 acc_val: 0.9733\n",
      "Epoch: 0145 loss_train: 0.0247 acc_train: 0.9978 acc_val: 0.9733\n",
      "Epoch: 0146 loss_train: 0.0243 acc_train: 0.9978 acc_val: 0.9733\n",
      "Epoch: 0147 loss_train: 0.0240 acc_train: 0.9978 acc_val: 0.9733\n",
      "Epoch: 0148 loss_train: 0.0237 acc_train: 0.9978 acc_val: 0.9733\n",
      "Epoch: 0149 loss_train: 0.0234 acc_train: 0.9978 acc_val: 0.9733\n",
      "Epoch: 0150 loss_train: 0.0230 acc_train: 0.9978 acc_val: 0.9733\n",
      "Epoch: 0151 loss_train: 0.0227 acc_train: 0.9978 acc_val: 0.9733\n",
      "Epoch: 0152 loss_train: 0.0224 acc_train: 0.9978 acc_val: 0.9733\n",
      "Epoch: 0153 loss_train: 0.0221 acc_train: 0.9978 acc_val: 0.9733\n",
      "Epoch: 0154 loss_train: 0.0218 acc_train: 0.9985 acc_val: 0.9756\n",
      "Epoch: 0155 loss_train: 0.0215 acc_train: 0.9985 acc_val: 0.9756\n",
      "Epoch: 0156 loss_train: 0.0212 acc_train: 0.9985 acc_val: 0.9756\n",
      "Epoch: 0157 loss_train: 0.0209 acc_train: 0.9985 acc_val: 0.9756\n",
      "Epoch: 0158 loss_train: 0.0206 acc_train: 0.9985 acc_val: 0.9756\n",
      "Epoch: 0159 loss_train: 0.0204 acc_train: 0.9985 acc_val: 0.9756\n",
      "Epoch: 0160 loss_train: 0.0201 acc_train: 0.9985 acc_val: 0.9756\n",
      "Epoch: 0161 loss_train: 0.0198 acc_train: 0.9985 acc_val: 0.9756\n",
      "Epoch: 0162 loss_train: 0.0196 acc_train: 0.9993 acc_val: 0.9756\n",
      "Epoch: 0163 loss_train: 0.0193 acc_train: 0.9993 acc_val: 0.9756\n",
      "Epoch: 0164 loss_train: 0.0191 acc_train: 0.9993 acc_val: 0.9756\n",
      "Epoch: 0165 loss_train: 0.0188 acc_train: 0.9993 acc_val: 0.9756\n",
      "Epoch: 0166 loss_train: 0.0186 acc_train: 0.9993 acc_val: 0.9756\n",
      "Epoch: 0167 loss_train: 0.0184 acc_train: 0.9993 acc_val: 0.9756\n",
      "Epoch: 0168 loss_train: 0.0181 acc_train: 0.9993 acc_val: 0.9756\n",
      "Epoch: 0169 loss_train: 0.0179 acc_train: 0.9993 acc_val: 0.9756\n",
      "Epoch: 0170 loss_train: 0.0177 acc_train: 0.9993 acc_val: 0.9756\n",
      "Epoch: 0171 loss_train: 0.0174 acc_train: 0.9993 acc_val: 0.9756\n",
      "Epoch: 0172 loss_train: 0.0172 acc_train: 0.9993 acc_val: 0.9756\n",
      "Epoch: 0173 loss_train: 0.0170 acc_train: 0.9993 acc_val: 0.9756\n",
      "Epoch: 0174 loss_train: 0.0168 acc_train: 0.9993 acc_val: 0.9756\n",
      "Epoch: 0175 loss_train: 0.0166 acc_train: 0.9993 acc_val: 0.9756\n",
      "Epoch: 0176 loss_train: 0.0164 acc_train: 0.9993 acc_val: 0.9756\n",
      "Epoch: 0177 loss_train: 0.0162 acc_train: 0.9993 acc_val: 0.9756\n",
      "Epoch: 0178 loss_train: 0.0160 acc_train: 0.9993 acc_val: 0.9756\n",
      "Epoch: 0179 loss_train: 0.0158 acc_train: 0.9993 acc_val: 0.9756\n",
      "Epoch: 0180 loss_train: 0.0156 acc_train: 0.9993 acc_val: 0.9756\n",
      "Epoch: 0181 loss_train: 0.0155 acc_train: 0.9993 acc_val: 0.9756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0182 loss_train: 0.0153 acc_train: 0.9993 acc_val: 0.9756\n",
      "Epoch: 0183 loss_train: 0.0151 acc_train: 0.9993 acc_val: 0.9756\n",
      "Epoch: 0184 loss_train: 0.0149 acc_train: 0.9993 acc_val: 0.9756\n",
      "Epoch: 0185 loss_train: 0.0148 acc_train: 0.9993 acc_val: 0.9756\n",
      "Epoch: 0186 loss_train: 0.0146 acc_train: 0.9993 acc_val: 0.9756\n",
      "Epoch: 0187 loss_train: 0.0144 acc_train: 0.9993 acc_val: 0.9756\n",
      "Epoch: 0188 loss_train: 0.0143 acc_train: 0.9993 acc_val: 0.9756\n",
      "Epoch: 0189 loss_train: 0.0141 acc_train: 0.9993 acc_val: 0.9756\n",
      "Epoch: 0190 loss_train: 0.0139 acc_train: 0.9993 acc_val: 0.9756\n",
      "Epoch: 0191 loss_train: 0.0138 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0192 loss_train: 0.0136 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0193 loss_train: 0.0135 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0194 loss_train: 0.0133 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0195 loss_train: 0.0132 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0196 loss_train: 0.0131 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0197 loss_train: 0.0129 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0198 loss_train: 0.0128 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0199 loss_train: 0.0127 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0200 loss_train: 0.0125 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0201 loss_train: 0.0124 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0202 loss_train: 0.0123 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0203 loss_train: 0.0122 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0204 loss_train: 0.0120 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0205 loss_train: 0.0119 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0206 loss_train: 0.0118 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0207 loss_train: 0.0117 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0208 loss_train: 0.0116 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0209 loss_train: 0.0115 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0210 loss_train: 0.0113 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0211 loss_train: 0.0112 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0212 loss_train: 0.0111 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0213 loss_train: 0.0110 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0214 loss_train: 0.0109 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0215 loss_train: 0.0108 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0216 loss_train: 0.0107 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0217 loss_train: 0.0106 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0218 loss_train: 0.0105 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0219 loss_train: 0.0104 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0220 loss_train: 0.0103 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0221 loss_train: 0.0102 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0222 loss_train: 0.0101 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0223 loss_train: 0.0101 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0224 loss_train: 0.0100 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0225 loss_train: 0.0099 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0226 loss_train: 0.0098 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0227 loss_train: 0.0097 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0228 loss_train: 0.0096 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0229 loss_train: 0.0095 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0230 loss_train: 0.0095 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0231 loss_train: 0.0094 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0232 loss_train: 0.0093 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0233 loss_train: 0.0092 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0234 loss_train: 0.0091 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0235 loss_train: 0.0091 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0236 loss_train: 0.0090 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0237 loss_train: 0.0089 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0238 loss_train: 0.0089 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0239 loss_train: 0.0088 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0240 loss_train: 0.0087 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0241 loss_train: 0.0086 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0242 loss_train: 0.0086 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0243 loss_train: 0.0085 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0244 loss_train: 0.0084 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0245 loss_train: 0.0084 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0246 loss_train: 0.0083 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0247 loss_train: 0.0082 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0248 loss_train: 0.0082 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0249 loss_train: 0.0081 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0250 loss_train: 0.0081 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0251 loss_train: 0.0080 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0252 loss_train: 0.0079 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0253 loss_train: 0.0079 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0254 loss_train: 0.0078 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0255 loss_train: 0.0078 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0256 loss_train: 0.0077 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0257 loss_train: 0.0077 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0258 loss_train: 0.0076 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0259 loss_train: 0.0076 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0260 loss_train: 0.0075 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0261 loss_train: 0.0074 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0262 loss_train: 0.0074 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0263 loss_train: 0.0073 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0264 loss_train: 0.0073 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0265 loss_train: 0.0072 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0266 loss_train: 0.0072 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0267 loss_train: 0.0071 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0268 loss_train: 0.0071 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0269 loss_train: 0.0070 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0270 loss_train: 0.0070 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0271 loss_train: 0.0070 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0272 loss_train: 0.0069 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0273 loss_train: 0.0069 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0274 loss_train: 0.0068 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0275 loss_train: 0.0068 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0276 loss_train: 0.0067 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0277 loss_train: 0.0067 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0278 loss_train: 0.0066 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0279 loss_train: 0.0066 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0280 loss_train: 0.0066 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0281 loss_train: 0.0065 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0282 loss_train: 0.0065 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0283 loss_train: 0.0064 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0284 loss_train: 0.0064 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0285 loss_train: 0.0064 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0286 loss_train: 0.0063 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0287 loss_train: 0.0063 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0288 loss_train: 0.0062 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0289 loss_train: 0.0062 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0290 loss_train: 0.0062 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0291 loss_train: 0.0061 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0292 loss_train: 0.0061 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0293 loss_train: 0.0061 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0294 loss_train: 0.0060 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0295 loss_train: 0.0060 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0296 loss_train: 0.0060 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0297 loss_train: 0.0059 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0298 loss_train: 0.0059 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0299 loss_train: 0.0058 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0300 loss_train: 0.0058 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0301 loss_train: 0.0058 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0302 loss_train: 0.0058 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0303 loss_train: 0.0057 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0304 loss_train: 0.0057 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0305 loss_train: 0.0057 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0306 loss_train: 0.0056 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0307 loss_train: 0.0056 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0308 loss_train: 0.0056 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0309 loss_train: 0.0055 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0310 loss_train: 0.0055 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0311 loss_train: 0.0055 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0312 loss_train: 0.0054 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0313 loss_train: 0.0054 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0314 loss_train: 0.0054 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0315 loss_train: 0.0054 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0316 loss_train: 0.0053 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0317 loss_train: 0.0053 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0318 loss_train: 0.0053 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0319 loss_train: 0.0052 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0320 loss_train: 0.0052 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0321 loss_train: 0.0052 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0322 loss_train: 0.0052 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0323 loss_train: 0.0051 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0324 loss_train: 0.0051 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0325 loss_train: 0.0051 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0326 loss_train: 0.0051 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0327 loss_train: 0.0050 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0328 loss_train: 0.0050 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0329 loss_train: 0.0050 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0330 loss_train: 0.0050 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0331 loss_train: 0.0049 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0332 loss_train: 0.0049 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0333 loss_train: 0.0049 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0334 loss_train: 0.0049 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0335 loss_train: 0.0048 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0336 loss_train: 0.0048 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0337 loss_train: 0.0048 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0338 loss_train: 0.0048 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0339 loss_train: 0.0048 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0340 loss_train: 0.0047 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0341 loss_train: 0.0047 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0342 loss_train: 0.0047 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0343 loss_train: 0.0047 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0344 loss_train: 0.0046 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0345 loss_train: 0.0046 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0346 loss_train: 0.0046 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0347 loss_train: 0.0046 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0348 loss_train: 0.0046 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0349 loss_train: 0.0045 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0350 loss_train: 0.0045 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0351 loss_train: 0.0045 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0352 loss_train: 0.0044 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0353 loss_train: 0.0044 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0354 loss_train: 0.0044 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0355 loss_train: 0.0043 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0356 loss_train: 0.0042 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0357 loss_train: 0.0042 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0358 loss_train: 0.0041 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0359 loss_train: 0.0041 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0360 loss_train: 0.0040 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0361 loss_train: 0.0040 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0362 loss_train: 0.0039 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0363 loss_train: 0.0039 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0364 loss_train: 0.0038 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0365 loss_train: 0.0038 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0366 loss_train: 0.0038 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0367 loss_train: 0.0037 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0368 loss_train: 0.0037 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0369 loss_train: 0.0037 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0370 loss_train: 0.0036 acc_train: 1.0000 acc_val: 0.9733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0371 loss_train: 0.0036 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0372 loss_train: 0.0036 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0373 loss_train: 0.0036 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0374 loss_train: 0.0036 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0375 loss_train: 0.0036 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0376 loss_train: 0.0035 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0377 loss_train: 0.0035 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0378 loss_train: 0.0035 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0379 loss_train: 0.0035 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0380 loss_train: 0.0035 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0381 loss_train: 0.0034 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0382 loss_train: 0.0034 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0383 loss_train: 0.0034 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0384 loss_train: 0.0034 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0385 loss_train: 0.0033 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0386 loss_train: 0.0033 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0387 loss_train: 0.0033 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0388 loss_train: 0.0033 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0389 loss_train: 0.0033 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0390 loss_train: 0.0033 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0391 loss_train: 0.0032 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0392 loss_train: 0.0032 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0393 loss_train: 0.0032 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0394 loss_train: 0.0032 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0395 loss_train: 0.0032 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0396 loss_train: 0.0032 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0397 loss_train: 0.0031 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0398 loss_train: 0.0031 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0399 loss_train: 0.0031 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0400 loss_train: 0.0031 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0401 loss_train: 0.0031 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0402 loss_train: 0.0031 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0403 loss_train: 0.0031 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0404 loss_train: 0.0031 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0405 loss_train: 0.0031 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0406 loss_train: 0.0031 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0407 loss_train: 0.0030 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0408 loss_train: 0.0030 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0409 loss_train: 0.0030 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0410 loss_train: 0.0030 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0411 loss_train: 0.0030 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0412 loss_train: 0.0029 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0413 loss_train: 0.0029 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0414 loss_train: 0.0029 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0415 loss_train: 0.0029 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0416 loss_train: 0.0029 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0417 loss_train: 0.0029 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0418 loss_train: 0.0029 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0419 loss_train: 0.0029 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0420 loss_train: 0.0029 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0421 loss_train: 0.0029 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0422 loss_train: 0.0028 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0423 loss_train: 0.0028 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0424 loss_train: 0.0028 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0425 loss_train: 0.0028 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0426 loss_train: 0.0028 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0427 loss_train: 0.0028 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0428 loss_train: 0.0028 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0429 loss_train: 0.0028 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0430 loss_train: 0.0027 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0431 loss_train: 0.0027 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0432 loss_train: 0.0027 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0433 loss_train: 0.0027 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0434 loss_train: 0.0027 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0435 loss_train: 0.0027 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0436 loss_train: 0.0027 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0437 loss_train: 0.0027 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0438 loss_train: 0.0027 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0439 loss_train: 0.0027 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0440 loss_train: 0.0027 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0441 loss_train: 0.0026 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0442 loss_train: 0.0026 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0443 loss_train: 0.0026 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0444 loss_train: 0.0026 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0445 loss_train: 0.0026 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0446 loss_train: 0.0026 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0447 loss_train: 0.0026 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0448 loss_train: 0.0026 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0449 loss_train: 0.0026 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0450 loss_train: 0.0026 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0451 loss_train: 0.0026 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0452 loss_train: 0.0026 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0453 loss_train: 0.0026 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0454 loss_train: 0.0026 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0455 loss_train: 0.0025 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0456 loss_train: 0.0025 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0457 loss_train: 0.0025 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0458 loss_train: 0.0025 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0459 loss_train: 0.0025 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0460 loss_train: 0.0025 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0461 loss_train: 0.0025 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0462 loss_train: 0.0025 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0463 loss_train: 0.0025 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0464 loss_train: 0.0025 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0465 loss_train: 0.0025 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0466 loss_train: 0.0025 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0467 loss_train: 0.0025 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0468 loss_train: 0.0025 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0469 loss_train: 0.0025 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0470 loss_train: 0.0025 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0471 loss_train: 0.0025 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0472 loss_train: 0.0024 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0473 loss_train: 0.0024 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0474 loss_train: 0.0024 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0475 loss_train: 0.0024 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0476 loss_train: 0.0024 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0477 loss_train: 0.0024 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0478 loss_train: 0.0024 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0479 loss_train: 0.0024 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0480 loss_train: 0.0024 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0481 loss_train: 0.0024 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0482 loss_train: 0.0024 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0483 loss_train: 0.0024 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0484 loss_train: 0.0024 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0485 loss_train: 0.0024 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0486 loss_train: 0.0024 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0487 loss_train: 0.0024 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0488 loss_train: 0.0024 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0489 loss_train: 0.0023 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0490 loss_train: 0.0023 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0491 loss_train: 0.0023 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0492 loss_train: 0.0023 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0493 loss_train: 0.0023 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0494 loss_train: 0.0023 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0495 loss_train: 0.0023 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0496 loss_train: 0.0023 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0497 loss_train: 0.0023 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0498 loss_train: 0.0023 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0499 loss_train: 0.0023 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0500 loss_train: 0.0023 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0501 loss_train: 0.0023 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0502 loss_train: 0.0023 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0503 loss_train: 0.0023 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0504 loss_train: 0.0023 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0505 loss_train: 0.0023 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0506 loss_train: 0.0023 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0507 loss_train: 0.0022 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0508 loss_train: 0.0022 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0509 loss_train: 0.0022 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0510 loss_train: 0.0022 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0511 loss_train: 0.0022 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0512 loss_train: 0.0022 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0513 loss_train: 0.0022 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0514 loss_train: 0.0022 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0515 loss_train: 0.0022 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0516 loss_train: 0.0022 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0517 loss_train: 0.0022 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0518 loss_train: 0.0022 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0519 loss_train: 0.0022 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0520 loss_train: 0.0022 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0521 loss_train: 0.0022 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0522 loss_train: 0.0022 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0523 loss_train: 0.0022 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0524 loss_train: 0.0022 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0525 loss_train: 0.0022 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0526 loss_train: 0.0022 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0527 loss_train: 0.0022 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0528 loss_train: 0.0022 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0529 loss_train: 0.0022 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0530 loss_train: 0.0022 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0531 loss_train: 0.0021 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0532 loss_train: 0.0022 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0533 loss_train: 0.0022 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0534 loss_train: 0.0021 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0535 loss_train: 0.0021 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0536 loss_train: 0.0021 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0537 loss_train: 0.0021 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0538 loss_train: 0.0021 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0539 loss_train: 0.0021 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0540 loss_train: 0.0021 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0541 loss_train: 0.0021 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0542 loss_train: 0.0021 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0543 loss_train: 0.0021 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0544 loss_train: 0.0021 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0545 loss_train: 0.0021 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0546 loss_train: 0.0021 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0547 loss_train: 0.0021 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0548 loss_train: 0.0021 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0549 loss_train: 0.0021 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0550 loss_train: 0.0021 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0551 loss_train: 0.0021 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0552 loss_train: 0.0021 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0553 loss_train: 0.0021 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0554 loss_train: 0.0021 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0555 loss_train: 0.0021 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0556 loss_train: 0.0021 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0557 loss_train: 0.0020 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0558 loss_train: 0.0020 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0559 loss_train: 0.0020 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0560 loss_train: 0.0020 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0561 loss_train: 0.0020 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0562 loss_train: 0.0020 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0563 loss_train: 0.0020 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0564 loss_train: 0.0020 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0565 loss_train: 0.0020 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0566 loss_train: 0.0020 acc_train: 1.0000 acc_val: 0.9733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0567 loss_train: 0.0020 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0568 loss_train: 0.0020 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0569 loss_train: 0.0020 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0570 loss_train: 0.0020 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0571 loss_train: 0.0020 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0572 loss_train: 0.0020 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0573 loss_train: 0.0020 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0574 loss_train: 0.0020 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0575 loss_train: 0.0020 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0576 loss_train: 0.0020 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0577 loss_train: 0.0020 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0578 loss_train: 0.0020 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0579 loss_train: 0.0019 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0580 loss_train: 0.0020 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0581 loss_train: 0.0019 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0582 loss_train: 0.0019 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0583 loss_train: 0.0019 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0584 loss_train: 0.0019 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0585 loss_train: 0.0019 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0586 loss_train: 0.0019 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0587 loss_train: 0.0019 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0588 loss_train: 0.0019 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0589 loss_train: 0.0019 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0590 loss_train: 0.0019 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0591 loss_train: 0.0019 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0592 loss_train: 0.0019 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0593 loss_train: 0.0019 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0594 loss_train: 0.0019 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0595 loss_train: 0.0019 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0596 loss_train: 0.0019 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0597 loss_train: 0.0019 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0598 loss_train: 0.0019 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0599 loss_train: 0.0019 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0600 loss_train: 0.0019 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0601 loss_train: 0.0019 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0602 loss_train: 0.0019 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0603 loss_train: 0.0019 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0604 loss_train: 0.0019 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0605 loss_train: 0.0018 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0606 loss_train: 0.0018 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0607 loss_train: 0.0018 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0608 loss_train: 0.0018 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0609 loss_train: 0.0018 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0610 loss_train: 0.0018 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0611 loss_train: 0.0018 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0612 loss_train: 0.0018 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0613 loss_train: 0.0018 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0614 loss_train: 0.0018 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0615 loss_train: 0.0018 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0616 loss_train: 0.0018 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0617 loss_train: 0.0018 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0618 loss_train: 0.0018 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0619 loss_train: 0.0018 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0620 loss_train: 0.0018 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0621 loss_train: 0.0018 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0622 loss_train: 0.0018 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0623 loss_train: 0.0018 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0624 loss_train: 0.0018 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0625 loss_train: 0.0018 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0626 loss_train: 0.0018 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0627 loss_train: 0.0018 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0628 loss_train: 0.0018 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0629 loss_train: 0.0018 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0630 loss_train: 0.0018 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0631 loss_train: 0.0018 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0632 loss_train: 0.0018 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0633 loss_train: 0.0018 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0634 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0635 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0636 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0637 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0638 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0639 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0640 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0641 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0642 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0643 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0644 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0645 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0646 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0647 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0648 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0649 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0650 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0651 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0652 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0653 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0654 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0655 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0656 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0657 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 0658 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0659 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0660 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0661 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0662 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0663 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0664 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0665 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0666 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0667 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0668 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0669 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0670 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0671 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0672 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0673 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0674 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0675 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0676 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0677 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0678 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0679 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0680 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0681 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0682 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0683 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0684 loss_train: 0.0017 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0685 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0686 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0687 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0688 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0689 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0690 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0691 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0692 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0693 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0694 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0695 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0696 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0697 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0698 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0699 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0700 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0701 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0702 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0703 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0704 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0705 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0706 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0707 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0708 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0709 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0710 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0711 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0712 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0713 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0714 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0715 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0716 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0717 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0718 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0719 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0720 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0721 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0722 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0723 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0724 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0725 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0726 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0727 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0728 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0729 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0730 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0731 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0732 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0733 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0734 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0735 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0736 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0737 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0738 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0739 loss_train: 0.0015 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0740 loss_train: 0.0016 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0741 loss_train: 0.0015 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0742 loss_train: 0.0015 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0743 loss_train: 0.0015 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0744 loss_train: 0.0015 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0745 loss_train: 0.0015 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0746 loss_train: 0.0015 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0747 loss_train: 0.0015 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0748 loss_train: 0.0015 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0749 loss_train: 0.0015 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0750 loss_train: 0.0015 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0751 loss_train: 0.0015 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0752 loss_train: 0.0015 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0753 loss_train: 0.0015 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0754 loss_train: 0.0015 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0755 loss_train: 0.0015 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0756 loss_train: 0.0015 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0757 loss_train: 0.0015 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0758 loss_train: 0.0015 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0759 loss_train: 0.0015 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0760 loss_train: 0.0015 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0761 loss_train: 0.0015 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0762 loss_train: 0.0015 acc_train: 1.0000 acc_val: 0.9733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0763 loss_train: 0.0015 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0764 loss_train: 0.0015 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0765 loss_train: 0.0015 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0766 loss_train: 0.0015 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0767 loss_train: 0.0015 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0768 loss_train: 0.0015 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0769 loss_train: 0.0015 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0770 loss_train: 0.0015 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0771 loss_train: 0.0015 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0772 loss_train: 0.0015 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0773 loss_train: 0.0015 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0774 loss_train: 0.0015 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0775 loss_train: 0.0015 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0776 loss_train: 0.0015 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0777 loss_train: 0.0015 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0778 loss_train: 0.0015 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0779 loss_train: 0.0015 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0780 loss_train: 0.0014 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0781 loss_train: 0.0014 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0782 loss_train: 0.0014 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0783 loss_train: 0.0014 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0784 loss_train: 0.0014 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0785 loss_train: 0.0014 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0786 loss_train: 0.0014 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0787 loss_train: 0.0014 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0788 loss_train: 0.0014 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0789 loss_train: 0.0014 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0790 loss_train: 0.0014 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0791 loss_train: 0.0014 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0792 loss_train: 0.0014 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0793 loss_train: 0.0014 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0794 loss_train: 0.0014 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0795 loss_train: 0.0014 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0796 loss_train: 0.0014 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0797 loss_train: 0.0014 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0798 loss_train: 0.0014 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0799 loss_train: 0.0014 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0800 loss_train: 0.0013 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0801 loss_train: 0.0013 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0802 loss_train: 0.0013 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0803 loss_train: 0.0013 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0804 loss_train: 0.0013 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0805 loss_train: 0.0013 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0806 loss_train: 0.0013 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0807 loss_train: 0.0013 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0808 loss_train: 0.0013 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0809 loss_train: 0.0013 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0810 loss_train: 0.0013 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0811 loss_train: 0.0013 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0812 loss_train: 0.0013 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0813 loss_train: 0.0013 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0814 loss_train: 0.0013 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0815 loss_train: 0.0013 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0816 loss_train: 0.0013 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0817 loss_train: 0.0013 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0818 loss_train: 0.0013 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0819 loss_train: 0.0013 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0820 loss_train: 0.0013 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0821 loss_train: 0.0013 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0822 loss_train: 0.0013 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0823 loss_train: 0.0013 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0824 loss_train: 0.0013 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0825 loss_train: 0.0013 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0826 loss_train: 0.0013 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0827 loss_train: 0.0013 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0828 loss_train: 0.0013 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0829 loss_train: 0.0013 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0830 loss_train: 0.0013 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0831 loss_train: 0.0013 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0832 loss_train: 0.0013 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0833 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0834 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0835 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0836 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0837 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0838 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0839 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0840 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0841 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0842 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0843 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0844 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0845 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0846 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0847 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0848 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0849 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 0850 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0851 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0852 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0853 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0854 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0855 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0856 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0857 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0858 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0859 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0860 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0861 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0862 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0863 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0864 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0865 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0866 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0867 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0868 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0869 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0870 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0871 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0872 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0873 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0874 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0875 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0876 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0877 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0878 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0879 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0880 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0881 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0882 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0883 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0884 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 0885 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0886 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0887 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0888 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0889 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0890 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0891 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0892 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0893 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0894 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0895 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0896 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0897 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 0898 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0899 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0900 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0901 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0902 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0903 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0904 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0905 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0906 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0907 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0908 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0909 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0910 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0911 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0912 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0913 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0914 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0915 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0916 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0917 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0918 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0919 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0920 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0921 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0922 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0923 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0924 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0925 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0926 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0927 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0928 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0929 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0930 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0931 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0932 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0933 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0934 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0935 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0936 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0937 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0938 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0939 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0940 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0941 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0942 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0943 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0944 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0945 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0946 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0947 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0948 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0949 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0950 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0951 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0952 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0953 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0954 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0955 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0956 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0957 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0958 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0959 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0960 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0961 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0962 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0963 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0964 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0965 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0966 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0967 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0968 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0969 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0970 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0971 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0972 loss_train: 0.0012 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0973 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0974 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0975 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0976 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0977 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0978 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0979 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0980 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0981 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0982 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0983 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0984 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0985 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0986 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0987 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0988 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0989 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0990 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0991 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0992 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0993 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0994 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0995 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0996 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0997 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0998 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 0999 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1000 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1001 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1002 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1003 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1004 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1005 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1006 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1007 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1008 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1009 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1010 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1011 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1012 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1013 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1014 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1015 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1016 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1017 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1018 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1019 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1020 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1021 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1022 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1023 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1024 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1025 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1026 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1027 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1028 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1029 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1030 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1031 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1032 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1033 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1034 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1035 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1036 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1037 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1038 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1039 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1040 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1041 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1042 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1043 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1044 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1045 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1046 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1047 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1048 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1049 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1050 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1051 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1052 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1053 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1054 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1055 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1056 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1057 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1058 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1059 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1060 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1061 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1062 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1063 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1064 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1065 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1066 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1067 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1068 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1069 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1070 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1071 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1072 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1073 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1074 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1075 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1076 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1077 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1078 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1079 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1080 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1081 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1082 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1083 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1084 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1085 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1086 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1087 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1088 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1089 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1090 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1091 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1092 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1093 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1094 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1095 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1096 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1097 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1098 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1099 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1100 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1101 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1102 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1103 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1104 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1105 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1106 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1107 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1108 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1109 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1110 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1111 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1112 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1113 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1114 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1115 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1116 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1117 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1118 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1119 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1120 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1121 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1122 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1123 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1124 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1125 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1126 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1127 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1128 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1129 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1130 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1131 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1132 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1133 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1134 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1135 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1136 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1137 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1138 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1139 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1140 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1141 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1142 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1143 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1144 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1145 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1146 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1147 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1148 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1149 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1150 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1151 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1152 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1153 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1154 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1155 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1156 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1157 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1158 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1159 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1160 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1161 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1162 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1163 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1164 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1165 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1166 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1167 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1168 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1169 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1170 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1171 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1172 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1173 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1174 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1175 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1176 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1177 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1178 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1179 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1180 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1181 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1182 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1183 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1184 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1185 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1186 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1187 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1188 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1189 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1190 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1191 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1192 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1193 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1194 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1195 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1196 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1197 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1198 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1199 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1200 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1201 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1202 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1203 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1204 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1205 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1206 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1207 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1208 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1209 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1210 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1211 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1212 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1213 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1214 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1215 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1216 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1217 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1218 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1219 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1220 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1221 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1222 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1223 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1224 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1225 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1226 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1227 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1228 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1229 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1230 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1231 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1232 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1233 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1234 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1235 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1236 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1237 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1238 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1239 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1240 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1241 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1242 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1243 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1244 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1245 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1246 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1247 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1248 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1249 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1250 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1251 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1252 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1253 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1254 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1255 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1256 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1257 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1258 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1259 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1260 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1261 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1262 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1263 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1264 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1265 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1266 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1267 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1268 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1269 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1270 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1271 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1272 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1273 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1274 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1275 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1276 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1277 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1278 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1279 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1280 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1281 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1282 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1283 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1284 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1285 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1286 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1287 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1288 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1289 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1290 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1291 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1292 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1293 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1294 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1295 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1296 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1297 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1298 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1299 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1300 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1301 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1302 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1303 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1304 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1305 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1306 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1307 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1308 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1309 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1310 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1311 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1312 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1313 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1314 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1315 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1316 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1317 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1318 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1319 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1320 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1321 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1322 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1323 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1324 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1325 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1326 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1327 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1328 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1329 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1330 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1331 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1332 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1333 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1334 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1335 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1336 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1337 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1338 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1339 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1340 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1341 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1342 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1343 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1344 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1345 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1346 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1347 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1348 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1349 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1350 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1351 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1352 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1353 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1354 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1355 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1356 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1357 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1358 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1359 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1360 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1361 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1362 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1363 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1364 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1365 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1366 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1367 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1368 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1369 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1370 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1371 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1372 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1373 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1374 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1375 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1376 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1377 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1378 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1379 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1380 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1381 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1382 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1383 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1384 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1385 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1386 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1387 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1388 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1389 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1390 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1391 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1392 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1393 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1394 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1395 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1396 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1397 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1398 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1399 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1400 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1401 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1402 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1403 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1404 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1405 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1406 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1407 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1408 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1409 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1410 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1411 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1412 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1413 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1414 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1415 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1416 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1417 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1418 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1419 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1420 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1421 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1422 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1423 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1424 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1425 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1426 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1427 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1428 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1429 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1430 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1431 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1432 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1433 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1434 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1435 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1436 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1437 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1438 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1439 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1440 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1441 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1442 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1443 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1444 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1445 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1446 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1447 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1448 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1449 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1450 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1451 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1452 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1453 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1454 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1455 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1456 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1457 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1458 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1459 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1460 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1461 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1462 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1463 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1464 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1465 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1466 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1467 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1468 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1469 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1470 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1471 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1472 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1473 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1474 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1475 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1476 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1477 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1478 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1479 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1480 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1481 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1482 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1483 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1484 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1485 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1486 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1487 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1488 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1489 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1490 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1491 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1492 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1493 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1494 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1495 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1496 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1497 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1498 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1499 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1500 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1501 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1502 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1503 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1504 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1505 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1506 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1507 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1508 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1509 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1510 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1511 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1512 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1513 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1514 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1515 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1516 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1517 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1518 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1519 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1520 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1521 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1522 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1523 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1524 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1525 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1526 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1527 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1528 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1529 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1530 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1531 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1532 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1533 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1534 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1535 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1536 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1537 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1538 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1539 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1540 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1541 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1542 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1543 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1544 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1545 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1546 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1547 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1548 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1549 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1550 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1551 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1552 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1553 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1554 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1555 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1556 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1557 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1558 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1559 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1560 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1561 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1562 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1563 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1564 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1565 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1566 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1567 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1568 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1569 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1570 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1571 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1572 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1573 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1574 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1575 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1576 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1577 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1578 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1579 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1580 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1581 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1582 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1583 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1584 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1585 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1586 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1587 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1588 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1589 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1590 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1591 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1592 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1593 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1594 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1595 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1596 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1597 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1598 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1599 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1600 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1601 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1602 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1603 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1604 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1605 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1606 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1607 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1608 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1609 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1610 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1611 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1612 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1613 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1614 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1615 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1616 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1617 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1618 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1619 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1620 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1621 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1622 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1623 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1624 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1625 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1626 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1627 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1628 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1629 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1630 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1631 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1632 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1633 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1634 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1635 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1636 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1637 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1638 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1639 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1640 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1641 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1642 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1643 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1644 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1645 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1646 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1647 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1648 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1649 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1650 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1651 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1652 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1653 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1654 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1655 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1656 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1657 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1658 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1659 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1660 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1661 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1662 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1663 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1664 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1665 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1666 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1667 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1668 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1669 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1670 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1671 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1672 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1673 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1674 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1675 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1676 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1677 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1678 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1679 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1680 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1681 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1682 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1683 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1684 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1685 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1686 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1687 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1688 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1689 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1690 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1691 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1692 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1693 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1694 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1695 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1696 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1697 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1698 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1699 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1700 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1701 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1702 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1703 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1704 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1705 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1706 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1707 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1708 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1709 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1710 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1711 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1712 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1713 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1714 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1715 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1716 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1717 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1718 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1719 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1720 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1721 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1722 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1723 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1724 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1725 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1726 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1727 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1728 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1729 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1730 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1731 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1732 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1733 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1734 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1735 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1736 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1737 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1738 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1739 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1740 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1741 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1742 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1743 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1744 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1745 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1746 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1747 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1748 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1749 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1750 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1751 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1752 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1753 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1754 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1755 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1756 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1757 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1758 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1759 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1760 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1761 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1762 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1763 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1764 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1765 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1766 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1767 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1768 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1769 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1770 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1771 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1772 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1773 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1774 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1775 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1776 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1777 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1778 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1779 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1780 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1781 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1782 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1783 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1784 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1785 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1786 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1787 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1788 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1789 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1790 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1791 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1792 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1793 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1794 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1795 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1796 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1797 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1798 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1799 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1800 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1801 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1802 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1803 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1804 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1805 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1806 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1807 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1808 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1809 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1810 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1811 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1812 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1813 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1814 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1815 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1816 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1817 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1818 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1819 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1820 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1821 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1822 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1823 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1824 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1825 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1826 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1827 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1828 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1829 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1830 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1831 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1832 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1833 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1834 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1835 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1836 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1837 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1838 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1839 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1840 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1841 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1842 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1843 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1844 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1845 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1846 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1847 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1848 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1849 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1850 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1851 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1852 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1853 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1854 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1855 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1856 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1857 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1858 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1859 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1860 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1861 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1862 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1863 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1864 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1865 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1866 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1867 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1868 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1869 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1870 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1871 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1872 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1873 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1874 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1875 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1876 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1877 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1878 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1879 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1880 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1881 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1882 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1883 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1884 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1885 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1886 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1887 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1888 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1889 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1890 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1891 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1892 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1893 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1894 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1895 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1896 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1897 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1898 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1899 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1900 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1901 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1902 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1903 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1904 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1905 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1906 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1907 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1908 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1909 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1910 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1911 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1912 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1913 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1914 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1915 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1916 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1917 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1918 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1919 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1920 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1921 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1922 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1923 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1924 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1925 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1926 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1927 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1928 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1929 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1930 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1931 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1932 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1933 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1934 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1935 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1936 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1937 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1938 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1939 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1940 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1941 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1942 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1943 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1944 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1945 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1946 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1947 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1948 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1949 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1950 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1951 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1952 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1953 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1954 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1955 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1956 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1957 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1958 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1959 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1960 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 1961 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1962 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1963 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1964 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1965 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1966 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1967 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 1968 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1969 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1970 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1971 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1972 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1973 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1974 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1975 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1976 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1977 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 1978 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1979 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1980 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1981 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1982 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1983 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1984 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1985 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1986 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1987 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1988 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1989 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1990 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1991 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1992 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1993 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1994 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1995 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1996 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1997 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 1998 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 1999 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2000 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2001 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2002 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2003 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2004 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2005 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2006 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2007 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2008 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2009 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2010 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2011 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2012 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2013 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2014 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2015 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2016 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2017 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2018 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2019 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2020 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2021 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2022 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2023 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2024 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2025 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2026 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2027 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2028 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2029 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 2030 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2031 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2032 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 2033 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2034 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 2035 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2036 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2037 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2038 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2039 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2040 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2041 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2042 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 2043 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2044 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2045 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2046 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2047 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2048 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2049 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2050 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2051 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2052 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2053 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2054 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2055 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2056 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2057 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2058 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2059 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2060 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2061 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2062 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2063 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2064 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2065 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2066 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2067 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2068 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2069 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2070 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2071 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2072 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2073 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2074 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2075 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2076 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2077 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2078 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2079 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2080 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2081 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2082 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2083 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2084 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2085 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2086 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2087 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2088 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2089 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2090 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2091 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2092 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2093 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2094 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2095 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2096 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2097 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2098 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2099 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2100 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2101 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2102 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2103 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2104 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2105 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2106 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2107 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2108 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2109 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2110 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2111 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2112 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2113 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2114 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2115 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2116 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2117 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2118 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2119 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2120 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2121 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2122 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2123 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2124 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2125 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2126 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2127 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2128 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2129 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2130 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2131 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2132 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2133 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2134 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2135 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2136 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2137 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2138 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2139 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2140 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2141 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2142 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2143 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2144 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2145 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2146 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2147 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2148 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2149 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2150 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2151 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2152 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2153 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2154 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2155 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2156 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2157 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2158 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2159 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2160 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2161 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2162 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2163 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2164 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9667\n",
      "Epoch: 2165 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2166 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2167 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2168 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2169 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2170 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2171 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2172 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2173 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2174 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 2175 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2176 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2177 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 2178 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2179 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 2180 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2181 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2182 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 2183 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2184 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 2185 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2186 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2187 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2188 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2189 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2190 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2191 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 2192 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2193 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2194 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2195 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2196 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2197 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2198 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2199 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2200 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2201 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2202 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2203 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2204 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2205 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2206 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2207 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2208 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2209 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2210 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2211 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2212 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2213 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2214 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2215 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2216 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2217 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 2218 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2219 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2220 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2221 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2222 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2223 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2224 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2225 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2226 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2227 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 2228 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2229 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2230 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 2231 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2232 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2233 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2234 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2235 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2236 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2237 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2238 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2239 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2240 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2241 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2242 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2243 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2244 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2245 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 2246 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2247 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2248 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2249 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2250 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2251 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2252 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 2253 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2254 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2255 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 2256 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2257 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2258 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2259 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2260 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2261 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2262 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2263 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2264 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2265 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2266 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2267 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2268 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2269 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2270 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2271 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2272 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2273 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2274 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2275 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2276 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2277 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 2278 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2279 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 2280 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2281 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2282 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2283 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2284 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2285 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2286 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2287 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2288 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2289 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2290 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2291 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 2292 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2293 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2294 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 2295 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2296 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2297 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 2298 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 2299 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2300 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2301 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 2302 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2303 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2304 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2305 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2306 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2307 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 2308 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2309 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2310 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9689\n",
      "Epoch: 2311 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2312 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 2313 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2314 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2315 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 2316 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2317 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2318 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2319 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2320 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2321 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2322 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2323 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2324 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2325 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 2326 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2327 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2328 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 2329 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2330 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2331 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2332 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 2333 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2334 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2335 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 2336 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2337 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2338 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2339 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2340 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2341 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2342 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2343 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2344 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2345 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2346 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2347 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2348 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2349 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2350 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2351 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2352 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2353 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2354 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2355 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2356 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2357 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2358 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2359 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2360 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2361 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2362 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2363 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2364 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2365 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2366 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2367 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2368 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2369 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2370 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2371 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2372 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2373 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2374 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2375 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2376 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2377 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2378 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2379 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2380 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2381 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2382 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2383 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2384 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2385 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2386 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2387 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2388 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 2389 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2390 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2391 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2392 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2393 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2394 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2395 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2396 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2397 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2398 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2399 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2400 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2401 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2402 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2403 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2404 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2405 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2406 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2407 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2408 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2409 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2410 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2411 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2412 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2413 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2414 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2415 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2416 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2417 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2418 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2419 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2420 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2421 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2422 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2423 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2424 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2425 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2426 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2427 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2428 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2429 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2430 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2431 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2432 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2433 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2434 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2435 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2436 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2437 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2438 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2439 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2440 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2441 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2442 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2443 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2444 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2445 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2446 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2447 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2448 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2449 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2450 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2451 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2452 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2453 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2454 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2455 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2456 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2457 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2458 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2459 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2460 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2461 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2462 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2463 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2464 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2465 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2466 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2467 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2468 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2469 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2470 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2471 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2472 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2473 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2474 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2475 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2476 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2477 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2478 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2479 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2480 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2481 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2482 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2483 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2484 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2485 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2486 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2487 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2488 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2489 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2490 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2491 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2492 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2493 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2494 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2495 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2496 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2497 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2498 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2499 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2500 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2501 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2502 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2503 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2504 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2505 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2506 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2507 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2508 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2509 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2510 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2511 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2512 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2513 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2514 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2515 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2516 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2517 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2518 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2519 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2520 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2521 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2522 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2523 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2524 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2525 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2526 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2527 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2528 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2529 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2530 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2531 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2532 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2533 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2534 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2535 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2536 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2537 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2538 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2539 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2540 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2541 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2542 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2543 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2544 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2545 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2546 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2547 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2548 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2549 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2550 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2551 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2552 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2553 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2554 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2555 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2556 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2557 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2558 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2559 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2560 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2561 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2562 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2563 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2564 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2565 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2566 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2567 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2568 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2569 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2570 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2571 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2572 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2573 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2574 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2575 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2576 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2577 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2578 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2579 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2580 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2581 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2582 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2583 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2584 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2585 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2586 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2587 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2588 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2589 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2590 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2591 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2592 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2593 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2594 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2595 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2596 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2597 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2598 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2599 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2600 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2601 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2602 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2603 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2604 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2605 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2606 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2607 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2608 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2609 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2610 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2611 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2612 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2613 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2614 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2615 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2616 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2617 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2618 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2619 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2620 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2621 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2622 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2623 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2624 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2625 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2626 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2627 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2628 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2629 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2630 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2631 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2632 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2633 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2634 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2635 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2636 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2637 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2638 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2639 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2640 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2641 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2642 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2643 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2644 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2645 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2646 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2647 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2648 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2649 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2650 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2651 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2652 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2653 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2654 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2655 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2656 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2657 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2658 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2659 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2660 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2661 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2662 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2663 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2664 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2665 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2666 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2667 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2668 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2669 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2670 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2671 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2672 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2673 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2674 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2675 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2676 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2677 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2678 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2679 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2680 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2681 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2682 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2683 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2684 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2685 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2686 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2687 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2688 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2689 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2690 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2691 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2692 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2693 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2694 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2695 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2696 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2697 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2698 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2699 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2700 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2701 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2702 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2703 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2704 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2705 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2706 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2707 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2708 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2709 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2710 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2711 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2712 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2713 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2714 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2715 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2716 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2717 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2718 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2719 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2720 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2721 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2722 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2723 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2724 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2725 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2726 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2727 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2728 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2729 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2730 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2731 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2732 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2733 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2734 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2735 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2736 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2737 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2738 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2739 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2740 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2741 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2742 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2743 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2744 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2745 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2746 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2747 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2748 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2749 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2750 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2751 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2752 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2753 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2754 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2755 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2756 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2757 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2758 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2759 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2760 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2761 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2762 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2763 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2764 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2765 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2766 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2767 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2768 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2769 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2770 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2771 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2772 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2773 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2774 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2775 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2776 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2777 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2778 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2779 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2780 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2781 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2782 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2783 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2784 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2785 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2786 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2787 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2788 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2789 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2790 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2791 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2792 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2793 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2794 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2795 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2796 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2797 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2798 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2799 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2800 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2801 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2802 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2803 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2804 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2805 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2806 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2807 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2808 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 2809 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2810 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2811 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2812 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2813 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2814 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2815 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2816 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2817 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2818 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2819 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2820 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2821 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2822 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2823 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2824 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2825 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2826 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2827 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2828 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2829 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2830 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2831 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2832 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2833 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2834 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2835 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2836 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2837 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2838 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2839 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2840 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2841 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2842 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2843 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2844 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2845 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2846 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2847 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2848 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2849 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2850 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2851 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2852 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2853 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2854 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2855 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2856 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2857 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9711\n",
      "Epoch: 2858 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2859 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2860 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2861 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2862 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2863 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2864 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2865 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2866 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2867 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2868 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2869 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2870 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2871 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2872 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2873 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2874 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2875 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2876 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2877 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2878 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2879 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2880 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2881 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2882 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2883 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2884 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2885 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2886 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2887 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2888 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2889 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2890 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2891 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2892 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2893 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2894 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2895 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2896 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2897 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2898 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2899 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2900 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2901 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2902 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2903 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2904 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2905 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2906 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2907 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2908 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2909 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2910 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2911 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2912 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2913 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2914 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2915 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2916 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2917 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2918 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2919 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2920 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2921 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2922 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2923 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2924 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2925 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2926 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2927 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2928 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2929 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2930 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2931 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2932 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2933 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2934 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2935 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2936 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2937 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2938 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2939 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2940 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2941 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2942 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2943 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2944 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2945 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2946 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2947 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2948 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2949 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2950 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2951 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2952 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2953 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2954 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2955 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2956 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2957 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2958 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2959 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2960 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2961 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2962 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2963 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2964 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2965 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2966 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2967 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2968 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2969 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2970 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2971 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2972 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2973 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2974 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2975 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2976 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2977 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2978 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2979 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2980 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2981 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2982 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2983 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2984 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2985 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2986 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2987 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2988 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2989 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2990 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2991 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2992 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2993 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2994 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2995 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2996 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2997 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2998 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 2999 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3000 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3001 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3002 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3003 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3004 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3005 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3006 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3007 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3008 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3009 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3010 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3011 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3012 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3013 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3014 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3015 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3016 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3017 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3018 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3019 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3020 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3021 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3022 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3023 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3024 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3025 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3026 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3027 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3028 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3029 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3030 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3031 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3032 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3033 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3034 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3035 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3036 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3037 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3038 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3039 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3040 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3041 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3042 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3043 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3044 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3045 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3046 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3047 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3048 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3049 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3050 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3051 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3052 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3053 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3054 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3055 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3056 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3057 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3058 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3059 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3060 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3061 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3062 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3063 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3064 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3065 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3066 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3067 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3068 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3069 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3070 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3071 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3072 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3073 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3074 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3075 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3076 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3077 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3078 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3079 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3080 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3081 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3082 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3083 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3084 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3085 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3086 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3087 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3088 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3089 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3090 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3091 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3092 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3093 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3094 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3095 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3096 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3097 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3098 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3099 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3100 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3101 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3102 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3103 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3104 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3105 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3106 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3107 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3108 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3109 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3110 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3111 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3112 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3113 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3114 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3115 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3116 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3117 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3118 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3119 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3120 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3121 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3122 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3123 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3124 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3125 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3126 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3127 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3128 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3129 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3130 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3131 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3132 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3133 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3134 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3135 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3136 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3137 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3138 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3139 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3140 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3141 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3142 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3143 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3144 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3145 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3146 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3147 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3148 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3149 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3150 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3151 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3152 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3153 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3154 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3155 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3156 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3157 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3158 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3159 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3160 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3161 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3162 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3163 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3164 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3165 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3166 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3167 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3168 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3169 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3170 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3171 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3172 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3173 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3174 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3175 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3176 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3177 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3178 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3179 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3180 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3181 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3182 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3183 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3184 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3185 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3186 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3187 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3188 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3189 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3190 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3191 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3192 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3193 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3194 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3195 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3196 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3197 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3198 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3199 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3200 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3201 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3202 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3203 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3204 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3205 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3206 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3207 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3208 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3209 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3210 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3211 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3212 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3213 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3214 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3215 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3216 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3217 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3218 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3219 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3220 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3221 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3222 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3223 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3224 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3225 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3226 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3227 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3228 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3229 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3230 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3231 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3232 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3233 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3234 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3235 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3236 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3237 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3238 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3239 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3240 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3241 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3242 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3243 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3244 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3245 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3246 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3247 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3248 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3249 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3250 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3251 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3252 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3253 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3254 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3255 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3256 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3257 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3258 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3259 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3260 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3261 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3262 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3263 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3264 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3265 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3266 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3267 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3268 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3269 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3270 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3271 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3272 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3273 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3274 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3275 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3276 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3277 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3278 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3279 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3280 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3281 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3282 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3283 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3284 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3285 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3286 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3287 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3288 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3289 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3290 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3291 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3292 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3293 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3294 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3295 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3296 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3297 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3298 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3299 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3300 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3301 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3302 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3303 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3304 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3305 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3306 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3307 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3308 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3309 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3310 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3311 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3312 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3313 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3314 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3315 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3316 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3317 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3318 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3319 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3320 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3321 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3322 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3323 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3324 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3325 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3326 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3327 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3328 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3329 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3330 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3331 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3332 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3333 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3334 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3335 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3336 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3337 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3338 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3339 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3340 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3341 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3342 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3343 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3344 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3345 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3346 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3347 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3348 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3349 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3350 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3351 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3352 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3353 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3354 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3355 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3356 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3357 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3358 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3359 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3360 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3361 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3362 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3363 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3364 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3365 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3366 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3367 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3368 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3369 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3370 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3371 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3372 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3373 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3374 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3375 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3376 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3377 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3378 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3379 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3380 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3381 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3382 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3383 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3384 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3385 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3386 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3387 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3388 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3389 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3390 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3391 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3392 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3393 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3394 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3395 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3396 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3397 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3398 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3399 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3400 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3401 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3402 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3403 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3404 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3405 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3406 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3407 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3408 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3409 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3410 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3411 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3412 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3413 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3414 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3415 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3416 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3417 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3418 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3419 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3420 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3421 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3422 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3423 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3424 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3425 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3426 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3427 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3428 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3429 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3430 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3431 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3432 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3433 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3434 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3435 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3436 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3437 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3438 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3439 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3440 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3441 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3442 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3443 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3444 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3445 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3446 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3447 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3448 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3449 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3450 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3451 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3452 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3453 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3454 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3455 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3456 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3457 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3458 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3459 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3460 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3461 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3462 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3463 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3464 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3465 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3466 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3467 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3468 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3469 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3470 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3471 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3472 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3473 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3474 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3475 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3476 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3477 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3478 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3479 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3480 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3481 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3482 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3483 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3484 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3485 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3486 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3487 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3488 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3489 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3490 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3491 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3492 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3493 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3494 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3495 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3496 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3497 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3498 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3499 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3500 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3501 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3502 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3503 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3504 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3505 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3506 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3507 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3508 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3509 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3510 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3511 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3512 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3513 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3514 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3515 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3516 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3517 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3518 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3519 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3520 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3521 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3522 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3523 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3524 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3525 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3526 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3527 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3528 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3529 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3530 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3531 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3532 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3533 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3534 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3535 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3536 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3537 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3538 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3539 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3540 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3541 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3542 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3543 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3544 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3545 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3546 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3547 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3548 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3549 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3550 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3551 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3552 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3553 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3554 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3555 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3556 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3557 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3558 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3559 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3560 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3561 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3562 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3563 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3564 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3565 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3566 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3567 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3568 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3569 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3570 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3571 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3572 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3573 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3574 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3575 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3576 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3577 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3578 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3579 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3580 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3581 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3582 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3583 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3584 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3585 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3586 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3587 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3588 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3589 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3590 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3591 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3592 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3593 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3594 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3595 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3596 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3597 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3598 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3599 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3600 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3601 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3602 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3603 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3604 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3605 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3606 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3607 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3608 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3609 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3610 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3611 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3612 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3613 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3614 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3615 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3616 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3617 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3618 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3619 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3620 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3621 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3622 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3623 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3624 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3625 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3626 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3627 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3628 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3629 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3630 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3631 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3632 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3633 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3634 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3635 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3636 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3637 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3638 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3639 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3640 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3641 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3642 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3643 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3644 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3645 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3646 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3647 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3648 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3649 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3650 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3651 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3652 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3653 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3654 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3655 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3656 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3657 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3658 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3659 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3660 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3661 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3662 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3663 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3664 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3665 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3666 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3667 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3668 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3669 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3670 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3671 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3672 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3673 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3674 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3675 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3676 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3677 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3678 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3679 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3680 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3681 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3682 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3683 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3684 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3685 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3686 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3687 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3688 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3689 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3690 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3691 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3692 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3693 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3694 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3695 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3696 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3697 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3698 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3699 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3700 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3701 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3702 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3703 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3704 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3705 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3706 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3707 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3708 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3709 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3710 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3711 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3712 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3713 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3714 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3715 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3716 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3717 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3718 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3719 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3720 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3721 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3722 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3723 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3724 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3725 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3726 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3727 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3728 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3729 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3730 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3731 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3732 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3733 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3734 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3735 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3736 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3737 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3738 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3739 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3740 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3741 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3742 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3743 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3744 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3745 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3746 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3747 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3748 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3749 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3750 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3751 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3752 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3753 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3754 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3755 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3756 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3757 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3758 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3759 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3760 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3761 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3762 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3763 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3764 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3765 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3766 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3767 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3768 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3769 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3770 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3771 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3772 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3773 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3774 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3775 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3776 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3777 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3778 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3779 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3780 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3781 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3782 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3783 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3784 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3785 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3786 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3787 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3788 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3789 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3790 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3791 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3792 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3793 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3794 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3795 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3796 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3797 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3798 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3799 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3800 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3801 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3802 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3803 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3804 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3805 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3806 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3807 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3808 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3809 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3810 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3811 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3812 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3813 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3814 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3815 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3816 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3817 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3818 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3819 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3820 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3821 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3822 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3823 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3824 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3825 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3826 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3827 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3828 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3829 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3830 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3831 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3832 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3833 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3834 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3835 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3836 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3837 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3838 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3839 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3840 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3841 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3842 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3843 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3844 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3845 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3846 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3847 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3848 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3849 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3850 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3851 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3852 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3853 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3854 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3855 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3856 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3857 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3858 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3859 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3860 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3861 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3862 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3863 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3864 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3865 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3866 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3867 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3868 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3869 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3870 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3871 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3872 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3873 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3874 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3875 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3876 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3877 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3878 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3879 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3880 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3881 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3882 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3883 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3884 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3885 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3886 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3887 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3888 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3889 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3890 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3891 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3892 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3893 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3894 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3895 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3896 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3897 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3898 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3899 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3900 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3901 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3902 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3903 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3904 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3905 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3906 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3907 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3908 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3909 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3910 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3911 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3912 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3913 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3914 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3915 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3916 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3917 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3918 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3919 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3920 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3921 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3922 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3923 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3924 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3925 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 3926 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3927 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3928 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3929 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3930 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3931 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3932 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3933 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3934 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3935 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3936 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3937 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3938 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3939 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3940 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3941 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3942 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3943 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3944 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3945 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3946 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3947 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3948 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3949 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3950 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3951 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3952 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3953 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3954 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3955 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3956 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3957 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3958 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3959 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3960 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3961 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3962 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3963 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3964 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3965 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3966 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3967 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3968 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3969 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3970 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3971 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3972 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3973 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3974 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3975 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3976 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3977 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3978 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3979 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3980 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 3981 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3982 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3983 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3984 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3985 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3986 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3987 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3988 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3989 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3990 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 3991 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3992 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3993 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3994 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 3995 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3996 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3997 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3998 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 3999 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4000 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4001 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4002 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4003 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4004 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4005 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4006 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4007 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4008 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4009 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4010 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4011 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4012 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4013 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4014 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4015 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4016 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4017 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4018 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4019 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4020 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4021 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4022 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4023 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4024 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4025 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4026 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4027 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4028 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4029 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4030 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4031 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4032 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4033 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4034 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4035 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4036 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 4037 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4038 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4039 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4040 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4041 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4042 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4043 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4044 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4045 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4046 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 4047 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4048 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4049 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4050 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4051 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4052 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4053 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4054 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4055 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4056 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4057 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4058 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4059 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4060 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4061 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 4062 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4063 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 4064 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4065 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4066 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 4067 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4068 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 4069 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4070 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4071 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4072 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4073 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 4074 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4075 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4076 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4077 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4078 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 4079 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4080 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4081 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4082 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4083 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 4084 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4085 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4086 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4087 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4088 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4089 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4090 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4091 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4092 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4093 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4094 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4095 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4096 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4097 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4098 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4099 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4100 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4101 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4102 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4103 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4104 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4105 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4106 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 4107 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4108 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 4109 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4110 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4111 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 4112 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4113 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 4114 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4115 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4116 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4117 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4118 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4119 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4120 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4121 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4122 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4123 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4124 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4125 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4126 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4127 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4128 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4129 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4130 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4131 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4132 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4133 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4134 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4135 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4136 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4137 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4138 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4139 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 4140 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4141 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 4142 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4143 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4144 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 4145 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4146 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 4147 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4148 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4149 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 4150 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4151 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4152 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4153 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4154 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 4155 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4156 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4157 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4158 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4159 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4160 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4161 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4162 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4163 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4164 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4165 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4166 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4167 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 4168 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4169 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4170 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4171 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4172 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 4173 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4174 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4175 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4176 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4177 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4178 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4179 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4180 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4181 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 4182 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4183 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4184 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4185 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4186 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4187 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4188 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4189 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4190 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4191 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 4192 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4193 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4194 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4195 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4196 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4197 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4198 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4199 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4200 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4201 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4202 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4203 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4204 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4205 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4206 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 4207 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4208 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4209 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4210 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4211 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4212 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4213 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4214 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4215 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4216 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4217 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4218 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4219 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4220 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4221 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4222 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4223 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4224 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4225 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4226 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4227 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4228 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4229 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4230 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4231 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4232 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4233 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4234 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4235 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4236 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4237 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4238 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4239 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4240 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4241 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 4242 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4243 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4244 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4245 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4246 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 4247 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4248 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4249 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4250 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4251 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 4252 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4253 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4254 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4255 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4256 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4257 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4258 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4259 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4260 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4261 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4262 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4263 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4264 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4265 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4266 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 4267 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4268 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4269 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4270 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4271 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 4272 loss_train: 0.0011 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4273 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4274 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 4275 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4276 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 4277 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4278 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4279 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4280 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4281 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4282 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4283 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4284 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4285 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 4286 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4287 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4288 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4289 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4290 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4291 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4292 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4293 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4294 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4295 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4296 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4297 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4298 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4299 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4300 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4301 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4302 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4303 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4304 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4305 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4306 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4307 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4308 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4309 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4310 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4311 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4312 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4313 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4314 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4315 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4316 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4317 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4318 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4319 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4320 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4321 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4322 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4323 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4324 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4325 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4326 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4327 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4328 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4329 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4330 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4331 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4332 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4333 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4334 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4335 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4336 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4337 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4338 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4339 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4340 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4341 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4342 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4343 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4344 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4345 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4346 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4347 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4348 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4349 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4350 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4351 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4352 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4353 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4354 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4355 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4356 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4357 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4358 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4359 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4360 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4361 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4362 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4363 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4364 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4365 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4366 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4367 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4368 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4369 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4370 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4371 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4372 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4373 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4374 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4375 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4376 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4377 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4378 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4379 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4380 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4381 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4382 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4383 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4384 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4385 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4386 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4387 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4388 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4389 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4390 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4391 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4392 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4393 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4394 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4395 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4396 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4397 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4398 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4399 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 4400 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4401 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4402 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4403 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4404 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4405 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4406 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4407 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9733\n",
      "Epoch: 4408 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4409 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4410 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4411 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4412 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4413 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4414 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4415 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4416 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4417 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4418 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4419 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4420 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4421 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4422 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4423 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4424 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4425 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4426 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4427 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4428 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4429 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4430 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4431 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4432 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4433 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4434 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4435 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4436 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4437 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4438 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4439 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4440 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4441 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4442 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4443 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4444 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4445 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4446 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4447 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4448 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4449 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4450 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4451 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4452 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4453 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4454 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4455 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4456 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4457 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4458 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4459 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4460 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4461 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4462 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4463 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4464 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4465 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4466 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4467 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4468 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4469 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4470 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4471 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4472 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4473 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4474 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4475 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4476 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4477 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4478 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4479 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4480 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4481 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4482 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4483 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4484 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4485 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4486 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4487 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4488 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4489 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4490 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4491 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4492 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4493 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4494 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4495 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4496 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4497 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4498 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4499 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4500 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4501 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4502 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4503 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4504 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4505 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4506 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4507 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4508 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4509 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4510 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4511 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4512 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4513 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4514 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4515 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4516 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4517 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4518 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4519 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4520 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4521 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4522 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4523 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4524 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4525 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4526 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4527 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4528 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4529 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4530 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4531 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4532 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4533 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4534 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4535 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4536 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4537 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4538 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4539 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4540 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4541 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4542 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4543 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4544 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4545 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4546 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4547 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4548 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4549 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4550 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4551 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4552 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4553 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4554 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4555 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4556 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4557 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4558 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4559 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4560 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4561 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4562 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4563 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4564 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4565 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4566 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4567 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4568 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4569 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4570 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4571 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4572 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4573 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4574 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4575 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4576 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4577 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4578 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4579 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4580 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4581 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4582 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4583 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4584 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4585 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4586 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4587 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4588 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4589 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4590 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4591 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4592 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4593 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4594 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4595 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4596 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4597 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4598 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4599 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4600 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4601 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4602 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4603 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4604 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4605 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4606 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4607 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4608 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4609 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4610 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4611 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4612 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4613 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4614 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4615 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4616 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4617 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4618 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4619 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4620 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4621 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4622 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4623 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4624 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4625 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4626 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4627 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4628 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4629 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4630 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4631 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4632 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4633 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4634 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4635 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4636 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4637 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4638 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4639 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4640 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4641 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4642 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4643 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4644 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4645 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4646 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4647 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4648 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4649 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4650 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4651 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4652 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4653 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4654 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4655 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4656 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4657 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4658 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4659 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4660 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4661 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4662 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4663 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4664 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4665 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4666 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4667 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4668 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4669 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4670 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4671 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4672 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4673 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4674 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4675 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4676 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4677 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4678 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4679 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4680 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4681 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4682 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4683 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4684 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4685 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4686 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4687 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4688 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4689 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4690 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4691 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4692 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4693 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4694 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4695 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4696 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4697 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4698 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4699 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4700 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4701 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4702 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4703 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4704 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4705 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4706 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4707 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4708 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4709 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4710 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4711 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4712 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4713 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4714 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4715 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4716 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4717 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4718 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4719 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4720 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4721 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4722 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4723 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4724 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4725 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4726 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4727 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4728 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4729 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4730 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4731 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4732 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4733 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4734 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4735 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4736 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4737 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4738 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4739 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4740 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4741 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4742 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4743 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4744 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4745 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4746 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4747 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4748 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4749 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4750 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4751 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4752 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4753 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4754 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4755 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4756 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4757 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4758 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4759 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4760 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4761 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4762 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4763 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4764 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4765 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4766 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4767 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4768 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4769 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4770 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4771 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4772 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4773 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4774 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4775 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4776 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4777 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4778 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4779 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4780 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4781 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4782 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4783 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4784 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4785 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4786 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4787 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4788 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4789 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4790 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4791 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4792 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4793 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4794 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4795 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4796 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4797 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4798 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4799 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4800 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4801 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4802 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4803 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4804 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4805 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4806 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4807 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4808 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4809 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4810 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4811 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4812 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4813 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4814 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4815 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4816 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4817 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4818 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4819 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4820 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4821 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4822 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4823 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4824 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4825 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4826 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4827 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4828 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4829 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4830 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4831 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4832 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4833 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4834 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4835 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4836 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4837 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4838 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4839 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4840 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4841 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4842 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4843 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4844 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4845 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4846 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4847 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4848 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4849 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4850 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4851 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4852 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4853 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4854 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4855 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4856 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4857 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4858 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4859 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4860 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4861 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4862 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4863 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4864 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4865 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4866 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4867 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4868 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4869 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4870 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4871 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4872 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4873 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4874 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4875 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4876 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4877 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4878 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4879 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4880 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4881 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4882 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4883 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4884 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4885 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4886 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4887 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4888 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4889 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4890 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4891 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4892 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4893 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4894 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4895 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4896 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4897 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4898 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4899 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4900 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4901 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4902 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4903 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4904 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4905 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4906 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4907 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4908 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4909 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4910 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4911 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4912 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4913 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4914 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4915 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4916 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4917 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4918 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4919 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4920 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4921 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4922 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4923 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4924 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4925 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4926 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4927 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4928 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4929 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4930 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4931 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4932 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4933 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4934 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4935 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4936 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4937 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4938 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4939 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4940 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4941 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4942 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4943 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4944 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4945 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4946 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4947 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4948 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4949 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4950 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4951 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4952 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4953 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4954 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4955 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4956 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4957 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4958 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4959 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4960 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4961 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4962 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4963 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4964 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4965 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4966 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4967 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4968 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4969 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4970 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4971 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4972 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4973 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4974 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4975 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4976 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4977 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4978 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4979 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4980 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4981 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4982 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4983 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4984 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4985 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4986 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4987 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4988 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4989 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4990 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4991 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 4992 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4993 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4994 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4995 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4996 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4997 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4998 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9756\n",
      "Epoch: 4999 loss_train: 0.0010 acc_train: 1.0000 acc_val: 0.9778\n",
      "Epoch: 5000 loss_train: 0.0009 acc_train: 1.0000 acc_val: 0.9778\n",
      "Optimization Finished!\n",
      "Total time elapsed: 11.1464s\n"
     ]
    }
   ],
   "source": [
    "# Train model,2head\n",
    "t_total = time.time()\n",
    "for epoch in range(5000):\n",
    "    train(epoch,model)\n",
    "print(\"Optimization Finished!\")\n",
    "print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove the inner cross feature in x1-x20,x21-x-40,x41-x64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchFM(nn.Module):\n",
    "    def __init__(self, classes=None, Feature_number=None, embedding=None):\n",
    "        super().__init__()\n",
    "        # Initially we fill V with random values sampled from Gaussian distribution\n",
    "        # NB: use nn.Parameter to compute gradients\n",
    "        self.classes = classes\n",
    "        self.V = nn.Parameter(torch.randn(classes, Feature_number, embedding),requires_grad=True)\n",
    "        self.lin = nn.Linear(Feature_number, classes)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # all\n",
    "        out_1 = torch.matmul(x,self.V).pow(2).sum(2, keepdim=True).view(self.classes,x.shape[0]).t()\n",
    "        out_2 = torch.matmul(x.pow(2), self.V.pow(2)).sum(2, keepdim=True).view(self.classes,x.shape[0]).t() \n",
    "        out_inter1 = 0.5*(out_1 - out_2)\n",
    "        # x1-x20\n",
    "        out_3 = torch.matmul(x[:,:20],self.V[:,:20,:]).pow(2).sum(2, keepdim=True).view(self.classes,x.shape[0]).t()\n",
    "        out_4 = torch.matmul(x[:,:20].pow(2), self.V[:,:20,:].pow(2)).sum(2, keepdim=True).view(self.classes,x.shape[0]).t() \n",
    "        out_inter2 = 0.5*(out_4 - out_3)\n",
    "        \n",
    "        # x21-x40\n",
    "        out_5 = torch.matmul(x[:,20:40],self.V[:,20:40,:]).pow(2).sum(2, keepdim=True).view(self.classes,x.shape[0]).t()\n",
    "        out_6 = torch.matmul(x[:,20:40].pow(2), self.V[:,20:40,:].pow(2)).sum(2, keepdim=True).view(self.classes,x.shape[0]).t() \n",
    "        out_inter3 = 0.5*(out_6 - out_5)\n",
    "        \n",
    "        # x41-x64\n",
    "        out_7 = torch.matmul(x[:,40:],self.V[:,40:,:]).pow(2).sum(2, keepdim=True).view(self.classes,x.shape[0]).t()\n",
    "        out_8 = torch.matmul(x[:,40:].pow(2), self.V[:,40:,:].pow(2)).sum(2, keepdim=True).view(self.classes,x.shape[0]).t() \n",
    "        out_inter4 = 0.5*(out_8 - out_7)\n",
    "        \n",
    "        out_inter = out_inter1 - out_inter2 - out_inter3 - out_inter4\n",
    "        out_lin = self.lin(x)\n",
    "        out = out_inter + out_lin\n",
    "        out = F.dropout(out, 0.2, training=self.training)\n",
    "        \n",
    "        return F.log_softmax(out, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TorchFM(classes=10, Feature_number=64, embedding=15)\n",
    "optimizer = optim.Adam(model.parameters(), \n",
    "                       lr=0.1, \n",
    "                       weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss_train: 39752.5742 acc_train: 0.0772 acc_val: 0.2156\n",
      "Epoch: 0002 loss_train: 24190.6973 acc_train: 0.1737 acc_val: 0.3022\n",
      "Epoch: 0003 loss_train: 22577.2500 acc_train: 0.2992 acc_val: 0.4911\n",
      "Epoch: 0004 loss_train: 11854.3516 acc_train: 0.4729 acc_val: 0.7200\n",
      "Epoch: 0005 loss_train: 7379.9102 acc_train: 0.6080 acc_val: 0.7489\n",
      "Epoch: 0006 loss_train: 6763.9683 acc_train: 0.6162 acc_val: 0.8000\n",
      "Epoch: 0007 loss_train: 4759.5371 acc_train: 0.6607 acc_val: 0.8222\n",
      "Epoch: 0008 loss_train: 3251.8589 acc_train: 0.7171 acc_val: 0.8378\n",
      "Epoch: 0009 loss_train: 2257.0649 acc_train: 0.7431 acc_val: 0.8244\n",
      "Epoch: 0010 loss_train: 1880.7400 acc_train: 0.7350 acc_val: 0.8311\n",
      "Epoch: 0011 loss_train: 1511.7991 acc_train: 0.7483 acc_val: 0.8578\n",
      "Epoch: 0012 loss_train: 1063.7356 acc_train: 0.7832 acc_val: 0.8622\n",
      "Epoch: 0013 loss_train: 1080.7880 acc_train: 0.7751 acc_val: 0.8667\n",
      "Epoch: 0014 loss_train: 1093.0037 acc_train: 0.7639 acc_val: 0.8511\n",
      "Epoch: 0015 loss_train: 1173.6045 acc_train: 0.7669 acc_val: 0.8622\n",
      "Epoch: 0016 loss_train: 1077.9611 acc_train: 0.7788 acc_val: 0.8756\n",
      "Epoch: 0017 loss_train: 969.1478 acc_train: 0.7929 acc_val: 0.8911\n",
      "Epoch: 0018 loss_train: 738.7675 acc_train: 0.8070 acc_val: 0.9133\n",
      "Epoch: 0019 loss_train: 655.7543 acc_train: 0.8166 acc_val: 0.9156\n",
      "Epoch: 0020 loss_train: 696.7108 acc_train: 0.7988 acc_val: 0.9133\n",
      "Epoch: 0021 loss_train: 692.3425 acc_train: 0.8159 acc_val: 0.9200\n",
      "Epoch: 0022 loss_train: 623.6286 acc_train: 0.8330 acc_val: 0.9311\n",
      "Epoch: 0023 loss_train: 539.1056 acc_train: 0.8263 acc_val: 0.9467\n",
      "Epoch: 0024 loss_train: 539.2668 acc_train: 0.8337 acc_val: 0.9533\n",
      "Epoch: 0025 loss_train: 426.4169 acc_train: 0.8478 acc_val: 0.9511\n",
      "Epoch: 0026 loss_train: 440.8556 acc_train: 0.8344 acc_val: 0.9422\n",
      "Epoch: 0027 loss_train: 421.4635 acc_train: 0.8434 acc_val: 0.9333\n",
      "Epoch: 0028 loss_train: 389.2841 acc_train: 0.8382 acc_val: 0.9333\n",
      "Epoch: 0029 loss_train: 355.5476 acc_train: 0.8404 acc_val: 0.9378\n",
      "Epoch: 0030 loss_train: 268.2654 acc_train: 0.8500 acc_val: 0.9422\n",
      "Epoch: 0031 loss_train: 287.6694 acc_train: 0.8530 acc_val: 0.9400\n",
      "Epoch: 0032 loss_train: 252.1711 acc_train: 0.8560 acc_val: 0.9378\n",
      "Epoch: 0033 loss_train: 288.5871 acc_train: 0.8441 acc_val: 0.9400\n",
      "Epoch: 0034 loss_train: 242.7416 acc_train: 0.8693 acc_val: 0.9378\n",
      "Epoch: 0035 loss_train: 188.6392 acc_train: 0.8671 acc_val: 0.9356\n",
      "Epoch: 0036 loss_train: 198.4949 acc_train: 0.8567 acc_val: 0.9422\n",
      "Epoch: 0037 loss_train: 176.8257 acc_train: 0.8619 acc_val: 0.9422\n",
      "Epoch: 0038 loss_train: 207.2023 acc_train: 0.8708 acc_val: 0.9556\n",
      "Epoch: 0039 loss_train: 134.1868 acc_train: 0.8627 acc_val: 0.9600\n",
      "Epoch: 0040 loss_train: 136.3637 acc_train: 0.8701 acc_val: 0.9622\n",
      "Epoch: 0041 loss_train: 144.2569 acc_train: 0.8679 acc_val: 0.9667\n",
      "Epoch: 0042 loss_train: 91.7465 acc_train: 0.8738 acc_val: 0.9622\n",
      "Epoch: 0043 loss_train: 85.0626 acc_train: 0.8627 acc_val: 0.9578\n",
      "Epoch: 0044 loss_train: 108.8532 acc_train: 0.8716 acc_val: 0.9511\n",
      "Epoch: 0045 loss_train: 94.8997 acc_train: 0.8760 acc_val: 0.9556\n",
      "Epoch: 0046 loss_train: 119.0435 acc_train: 0.8790 acc_val: 0.9578\n",
      "Epoch: 0047 loss_train: 85.8638 acc_train: 0.8820 acc_val: 0.9600\n",
      "Epoch: 0048 loss_train: 107.2743 acc_train: 0.8597 acc_val: 0.9578\n",
      "Epoch: 0049 loss_train: 74.8505 acc_train: 0.8679 acc_val: 0.9533\n",
      "Epoch: 0050 loss_train: 62.6858 acc_train: 0.8812 acc_val: 0.9556\n",
      "Epoch: 0051 loss_train: 54.8227 acc_train: 0.8641 acc_val: 0.9622\n",
      "Epoch: 0052 loss_train: 54.9333 acc_train: 0.8664 acc_val: 0.9667\n",
      "Epoch: 0053 loss_train: 40.3647 acc_train: 0.8745 acc_val: 0.9644\n",
      "Epoch: 0054 loss_train: 40.8274 acc_train: 0.8641 acc_val: 0.9644\n",
      "Epoch: 0055 loss_train: 37.1459 acc_train: 0.8745 acc_val: 0.9644\n",
      "Epoch: 0056 loss_train: 37.6866 acc_train: 0.8671 acc_val: 0.9600\n",
      "Epoch: 0057 loss_train: 28.8982 acc_train: 0.8775 acc_val: 0.9600\n",
      "Epoch: 0058 loss_train: 37.6377 acc_train: 0.8812 acc_val: 0.9600\n",
      "Epoch: 0059 loss_train: 34.8969 acc_train: 0.8649 acc_val: 0.9578\n",
      "Epoch: 0060 loss_train: 12.8077 acc_train: 0.8716 acc_val: 0.9600\n",
      "Epoch: 0061 loss_train: 45.9230 acc_train: 0.8708 acc_val: 0.9622\n",
      "Epoch: 0062 loss_train: 37.7124 acc_train: 0.8864 acc_val: 0.9622\n",
      "Epoch: 0063 loss_train: 32.1163 acc_train: 0.8909 acc_val: 0.9622\n",
      "Epoch: 0064 loss_train: 33.6985 acc_train: 0.8909 acc_val: 0.9622\n",
      "Epoch: 0065 loss_train: 35.9211 acc_train: 0.8842 acc_val: 0.9622\n",
      "Epoch: 0066 loss_train: 15.8570 acc_train: 0.8812 acc_val: 0.9622\n",
      "Epoch: 0067 loss_train: 35.9651 acc_train: 0.8820 acc_val: 0.9644\n",
      "Epoch: 0068 loss_train: 17.5426 acc_train: 0.8768 acc_val: 0.9644\n",
      "Epoch: 0069 loss_train: 16.2852 acc_train: 0.8723 acc_val: 0.9644\n",
      "Epoch: 0070 loss_train: 38.3214 acc_train: 0.8872 acc_val: 0.9667\n",
      "Epoch: 0071 loss_train: 14.1318 acc_train: 0.8946 acc_val: 0.9644\n",
      "Epoch: 0072 loss_train: 16.9433 acc_train: 0.8886 acc_val: 0.9644\n",
      "Epoch: 0073 loss_train: 27.0431 acc_train: 0.8879 acc_val: 0.9622\n",
      "Epoch: 0074 loss_train: 17.3783 acc_train: 0.8842 acc_val: 0.9600\n",
      "Epoch: 0075 loss_train: 23.4286 acc_train: 0.8812 acc_val: 0.9600\n",
      "Epoch: 0076 loss_train: 23.6533 acc_train: 0.8864 acc_val: 0.9622\n",
      "Epoch: 0077 loss_train: 11.8573 acc_train: 0.8820 acc_val: 0.9622\n",
      "Epoch: 0078 loss_train: 19.5672 acc_train: 0.8827 acc_val: 0.9578\n",
      "Epoch: 0079 loss_train: 11.5492 acc_train: 0.8760 acc_val: 0.9578\n",
      "Epoch: 0080 loss_train: 12.2227 acc_train: 0.8901 acc_val: 0.9600\n",
      "Epoch: 0081 loss_train: 12.9973 acc_train: 0.8864 acc_val: 0.9600\n",
      "Epoch: 0082 loss_train: 16.4993 acc_train: 0.8782 acc_val: 0.9644\n",
      "Epoch: 0083 loss_train: 9.1465 acc_train: 0.8768 acc_val: 0.9644\n",
      "Epoch: 0084 loss_train: 9.6454 acc_train: 0.8909 acc_val: 0.9600\n",
      "Epoch: 0085 loss_train: 12.7688 acc_train: 0.8775 acc_val: 0.9600\n",
      "Epoch: 0086 loss_train: 8.1947 acc_train: 0.8701 acc_val: 0.9622\n",
      "Epoch: 0087 loss_train: 3.9386 acc_train: 0.8909 acc_val: 0.9578\n",
      "Epoch: 0088 loss_train: 4.5697 acc_train: 0.8938 acc_val: 0.9578\n",
      "Epoch: 0089 loss_train: 5.3909 acc_train: 0.8990 acc_val: 0.9600\n",
      "Epoch: 0090 loss_train: 4.9966 acc_train: 0.8834 acc_val: 0.9644\n",
      "Epoch: 0091 loss_train: 4.3192 acc_train: 0.8641 acc_val: 0.9622\n",
      "Epoch: 0092 loss_train: 7.5512 acc_train: 0.8990 acc_val: 0.9578\n",
      "Epoch: 0093 loss_train: 3.5792 acc_train: 0.8849 acc_val: 0.9600\n",
      "Epoch: 0094 loss_train: 3.3248 acc_train: 0.8738 acc_val: 0.9578\n",
      "Epoch: 0095 loss_train: 4.8285 acc_train: 0.9005 acc_val: 0.9578\n",
      "Epoch: 0096 loss_train: 15.0433 acc_train: 0.8723 acc_val: 0.9578\n",
      "Epoch: 0097 loss_train: 3.4822 acc_train: 0.8886 acc_val: 0.9533\n",
      "Epoch: 0098 loss_train: 5.5280 acc_train: 0.8872 acc_val: 0.9556\n",
      "Epoch: 0099 loss_train: 3.7634 acc_train: 0.8857 acc_val: 0.9578\n",
      "Epoch: 0100 loss_train: 2.4841 acc_train: 0.8827 acc_val: 0.9578\n",
      "Epoch: 0101 loss_train: 5.7320 acc_train: 0.8857 acc_val: 0.9578\n",
      "Epoch: 0102 loss_train: 4.2649 acc_train: 0.8827 acc_val: 0.9578\n",
      "Epoch: 0103 loss_train: 0.7941 acc_train: 0.8738 acc_val: 0.9600\n",
      "Epoch: 0104 loss_train: 2.9081 acc_train: 0.8924 acc_val: 0.9644\n",
      "Epoch: 0105 loss_train: 2.4531 acc_train: 0.8842 acc_val: 0.9644\n",
      "Epoch: 0106 loss_train: 10.6796 acc_train: 0.8842 acc_val: 0.9644\n",
      "Epoch: 0107 loss_train: 0.6425 acc_train: 0.8953 acc_val: 0.9644\n",
      "Epoch: 0108 loss_train: 3.5513 acc_train: 0.8901 acc_val: 0.9644\n",
      "Epoch: 0109 loss_train: 0.2658 acc_train: 0.8931 acc_val: 0.9644\n",
      "Epoch: 0110 loss_train: 0.6901 acc_train: 0.8775 acc_val: 0.9644\n",
      "Epoch: 0111 loss_train: 5.8869 acc_train: 0.8812 acc_val: 0.9644\n",
      "Epoch: 0112 loss_train: 3.8775 acc_train: 0.8894 acc_val: 0.9644\n",
      "Epoch: 0113 loss_train: 2.6021 acc_train: 0.8983 acc_val: 0.9644\n",
      "Epoch: 0114 loss_train: 2.1236 acc_train: 0.9005 acc_val: 0.9667\n",
      "Epoch: 0115 loss_train: 3.6434 acc_train: 0.8820 acc_val: 0.9667\n",
      "Epoch: 0116 loss_train: 5.1740 acc_train: 0.8864 acc_val: 0.9667\n",
      "Epoch: 0117 loss_train: 1.4866 acc_train: 0.8938 acc_val: 0.9667\n",
      "Epoch: 0118 loss_train: 2.2285 acc_train: 0.9035 acc_val: 0.9644\n",
      "Epoch: 0119 loss_train: 1.5565 acc_train: 0.9020 acc_val: 0.9600\n",
      "Epoch: 0120 loss_train: 1.7819 acc_train: 0.8946 acc_val: 0.9578\n",
      "Epoch: 0121 loss_train: 6.1029 acc_train: 0.8782 acc_val: 0.9622\n",
      "Epoch: 0122 loss_train: 1.8308 acc_train: 0.8976 acc_val: 0.9689\n",
      "Epoch: 0123 loss_train: 1.8462 acc_train: 0.8953 acc_val: 0.9689\n",
      "Epoch: 0124 loss_train: 2.8314 acc_train: 0.8976 acc_val: 0.9667\n",
      "Epoch: 0125 loss_train: 4.6577 acc_train: 0.8864 acc_val: 0.9667\n",
      "Epoch: 0126 loss_train: 0.4355 acc_train: 0.8916 acc_val: 0.9622\n",
      "Epoch: 0127 loss_train: 0.6238 acc_train: 0.8953 acc_val: 0.9600\n",
      "Epoch: 0128 loss_train: 3.1541 acc_train: 0.8834 acc_val: 0.9622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0129 loss_train: 1.4548 acc_train: 0.9057 acc_val: 0.9622\n",
      "Epoch: 0130 loss_train: 1.1680 acc_train: 0.8916 acc_val: 0.9644\n",
      "Epoch: 0131 loss_train: 0.1887 acc_train: 0.8842 acc_val: 0.9644\n",
      "Epoch: 0132 loss_train: 1.8085 acc_train: 0.8909 acc_val: 0.9644\n",
      "Epoch: 0133 loss_train: 0.9169 acc_train: 0.8879 acc_val: 0.9644\n",
      "Epoch: 0134 loss_train: 0.5302 acc_train: 0.9027 acc_val: 0.9667\n",
      "Epoch: 0135 loss_train: 2.9162 acc_train: 0.8976 acc_val: 0.9644\n",
      "Epoch: 0136 loss_train: 0.8959 acc_train: 0.8864 acc_val: 0.9622\n",
      "Epoch: 0137 loss_train: 0.5558 acc_train: 0.8894 acc_val: 0.9622\n",
      "Epoch: 0138 loss_train: 0.2043 acc_train: 0.8961 acc_val: 0.9622\n",
      "Epoch: 0139 loss_train: 0.3849 acc_train: 0.8812 acc_val: 0.9622\n",
      "Epoch: 0140 loss_train: 1.7812 acc_train: 0.8849 acc_val: 0.9622\n",
      "Epoch: 0141 loss_train: 0.8754 acc_train: 0.8842 acc_val: 0.9600\n",
      "Epoch: 0142 loss_train: 1.1317 acc_train: 0.8916 acc_val: 0.9644\n",
      "Epoch: 0143 loss_train: 0.4962 acc_train: 0.8953 acc_val: 0.9622\n",
      "Epoch: 0144 loss_train: 0.3979 acc_train: 0.8983 acc_val: 0.9600\n",
      "Epoch: 0145 loss_train: 0.9262 acc_train: 0.8931 acc_val: 0.9600\n",
      "Epoch: 0146 loss_train: 0.2351 acc_train: 0.8834 acc_val: 0.9600\n",
      "Epoch: 0147 loss_train: 0.2935 acc_train: 0.8953 acc_val: 0.9600\n",
      "Epoch: 0148 loss_train: 1.2468 acc_train: 0.8827 acc_val: 0.9600\n",
      "Epoch: 0149 loss_train: 0.2070 acc_train: 0.8879 acc_val: 0.9600\n",
      "Epoch: 0150 loss_train: 2.0137 acc_train: 0.8886 acc_val: 0.9600\n",
      "Epoch: 0151 loss_train: 0.2419 acc_train: 0.8716 acc_val: 0.9622\n",
      "Epoch: 0152 loss_train: 0.3593 acc_train: 0.9035 acc_val: 0.9622\n",
      "Epoch: 0153 loss_train: 0.3180 acc_train: 0.8916 acc_val: 0.9622\n",
      "Epoch: 0154 loss_train: 1.3645 acc_train: 0.8820 acc_val: 0.9622\n",
      "Epoch: 0155 loss_train: 0.1806 acc_train: 0.8998 acc_val: 0.9622\n",
      "Epoch: 0156 loss_train: 0.1636 acc_train: 0.8976 acc_val: 0.9622\n",
      "Epoch: 0157 loss_train: 3.3723 acc_train: 0.8909 acc_val: 0.9622\n",
      "Epoch: 0158 loss_train: 0.5576 acc_train: 0.9020 acc_val: 0.9622\n",
      "Epoch: 0159 loss_train: 0.2543 acc_train: 0.8701 acc_val: 0.9578\n",
      "Epoch: 0160 loss_train: 4.5635 acc_train: 0.8857 acc_val: 0.9600\n",
      "Epoch: 0161 loss_train: 0.4993 acc_train: 0.8961 acc_val: 0.9622\n",
      "Epoch: 0162 loss_train: 1.0007 acc_train: 0.8953 acc_val: 0.9622\n",
      "Epoch: 0163 loss_train: 0.6688 acc_train: 0.8916 acc_val: 0.9667\n",
      "Epoch: 0164 loss_train: 2.5616 acc_train: 0.8886 acc_val: 0.9667\n",
      "Epoch: 0165 loss_train: 0.4186 acc_train: 0.8894 acc_val: 0.9667\n",
      "Epoch: 0166 loss_train: 0.1840 acc_train: 0.8946 acc_val: 0.9622\n",
      "Epoch: 0167 loss_train: 0.2014 acc_train: 0.8857 acc_val: 0.9622\n",
      "Epoch: 0168 loss_train: 0.7484 acc_train: 0.8864 acc_val: 0.9622\n",
      "Epoch: 0169 loss_train: 0.6159 acc_train: 0.8886 acc_val: 0.9622\n",
      "Epoch: 0170 loss_train: 0.3150 acc_train: 0.9124 acc_val: 0.9667\n",
      "Epoch: 0171 loss_train: 0.2893 acc_train: 0.8805 acc_val: 0.9667\n",
      "Epoch: 0172 loss_train: 0.1881 acc_train: 0.8812 acc_val: 0.9667\n",
      "Epoch: 0173 loss_train: 0.3474 acc_train: 0.8931 acc_val: 0.9667\n",
      "Epoch: 0174 loss_train: 0.1940 acc_train: 0.8924 acc_val: 0.9667\n",
      "Epoch: 0175 loss_train: 0.1772 acc_train: 0.8983 acc_val: 0.9667\n",
      "Epoch: 0176 loss_train: 0.3525 acc_train: 0.8842 acc_val: 0.9667\n",
      "Epoch: 0177 loss_train: 0.2012 acc_train: 0.8864 acc_val: 0.9622\n",
      "Epoch: 0178 loss_train: 0.1794 acc_train: 0.8886 acc_val: 0.9622\n",
      "Epoch: 0179 loss_train: 0.1734 acc_train: 0.9050 acc_val: 0.9622\n",
      "Epoch: 0180 loss_train: 0.1890 acc_train: 0.8857 acc_val: 0.9600\n",
      "Epoch: 0181 loss_train: 0.3397 acc_train: 0.9050 acc_val: 0.9600\n",
      "Epoch: 0182 loss_train: 1.0457 acc_train: 0.8842 acc_val: 0.9600\n",
      "Epoch: 0183 loss_train: 0.1914 acc_train: 0.8983 acc_val: 0.9622\n",
      "Epoch: 0184 loss_train: 0.1701 acc_train: 0.8931 acc_val: 0.9622\n",
      "Epoch: 0185 loss_train: 0.3090 acc_train: 0.8990 acc_val: 0.9622\n",
      "Epoch: 0186 loss_train: 0.1819 acc_train: 0.8901 acc_val: 0.9622\n",
      "Epoch: 0187 loss_train: 0.2241 acc_train: 0.8931 acc_val: 0.9622\n",
      "Epoch: 0188 loss_train: 0.1990 acc_train: 0.8834 acc_val: 0.9622\n",
      "Epoch: 0189 loss_train: 0.2056 acc_train: 0.8820 acc_val: 0.9622\n",
      "Epoch: 0190 loss_train: 0.1758 acc_train: 0.8961 acc_val: 0.9622\n",
      "Epoch: 0191 loss_train: 0.1906 acc_train: 0.8872 acc_val: 0.9622\n",
      "Epoch: 0192 loss_train: 0.3519 acc_train: 0.8901 acc_val: 0.9622\n",
      "Epoch: 0193 loss_train: 0.1887 acc_train: 0.8909 acc_val: 0.9622\n",
      "Epoch: 0194 loss_train: 0.1760 acc_train: 0.8909 acc_val: 0.9600\n",
      "Epoch: 0195 loss_train: 0.1759 acc_train: 0.8946 acc_val: 0.9600\n",
      "Epoch: 0196 loss_train: 0.5884 acc_train: 0.8708 acc_val: 0.9600\n",
      "Epoch: 0197 loss_train: 0.1942 acc_train: 0.8864 acc_val: 0.9600\n",
      "Epoch: 0198 loss_train: 0.1816 acc_train: 0.8909 acc_val: 0.9600\n",
      "Epoch: 0199 loss_train: 0.2004 acc_train: 0.8931 acc_val: 0.9600\n",
      "Epoch: 0200 loss_train: 0.2002 acc_train: 0.8849 acc_val: 0.9600\n",
      "Epoch: 0201 loss_train: 0.2071 acc_train: 0.8782 acc_val: 0.9600\n",
      "Epoch: 0202 loss_train: 0.1674 acc_train: 0.8968 acc_val: 0.9600\n",
      "Epoch: 0203 loss_train: 0.1991 acc_train: 0.8857 acc_val: 0.9600\n",
      "Epoch: 0204 loss_train: 0.2781 acc_train: 0.8990 acc_val: 0.9600\n",
      "Epoch: 0205 loss_train: 0.1934 acc_train: 0.8849 acc_val: 0.9600\n",
      "Epoch: 0206 loss_train: 0.1718 acc_train: 0.8931 acc_val: 0.9600\n",
      "Epoch: 0207 loss_train: 0.1785 acc_train: 0.8924 acc_val: 0.9600\n",
      "Epoch: 0208 loss_train: 0.1777 acc_train: 0.9005 acc_val: 0.9600\n",
      "Epoch: 0209 loss_train: 0.3431 acc_train: 0.8842 acc_val: 0.9600\n",
      "Epoch: 0210 loss_train: 0.1732 acc_train: 0.8983 acc_val: 0.9600\n",
      "Epoch: 0211 loss_train: 0.2022 acc_train: 0.8820 acc_val: 0.9622\n",
      "Epoch: 0212 loss_train: 0.1890 acc_train: 0.8901 acc_val: 0.9622\n",
      "Epoch: 0213 loss_train: 0.1741 acc_train: 0.8901 acc_val: 0.9622\n",
      "Epoch: 0214 loss_train: 0.1905 acc_train: 0.8864 acc_val: 0.9622\n",
      "Epoch: 0215 loss_train: 0.1876 acc_train: 0.8961 acc_val: 0.9622\n",
      "Epoch: 0216 loss_train: 0.1775 acc_train: 0.8953 acc_val: 0.9622\n",
      "Epoch: 0217 loss_train: 0.2201 acc_train: 0.8931 acc_val: 0.9622\n",
      "Epoch: 0218 loss_train: 0.1910 acc_train: 0.8894 acc_val: 0.9622\n",
      "Epoch: 0219 loss_train: 0.1870 acc_train: 0.8938 acc_val: 0.9622\n",
      "Epoch: 0220 loss_train: 0.2028 acc_train: 0.8842 acc_val: 0.9622\n",
      "Epoch: 0221 loss_train: 0.2369 acc_train: 0.8961 acc_val: 0.9622\n",
      "Epoch: 0222 loss_train: 0.1791 acc_train: 0.8983 acc_val: 0.9622\n",
      "Epoch: 0223 loss_train: 0.1949 acc_train: 0.8812 acc_val: 0.9622\n",
      "Epoch: 0224 loss_train: 0.2020 acc_train: 0.8857 acc_val: 0.9622\n",
      "Epoch: 0225 loss_train: 0.2064 acc_train: 0.8924 acc_val: 0.9622\n",
      "Epoch: 0226 loss_train: 0.1692 acc_train: 0.9005 acc_val: 0.9622\n",
      "Epoch: 0227 loss_train: 0.1822 acc_train: 0.9035 acc_val: 0.9600\n",
      "Epoch: 0228 loss_train: 0.1990 acc_train: 0.9050 acc_val: 0.9600\n",
      "Epoch: 0229 loss_train: 0.1624 acc_train: 0.8938 acc_val: 0.9600\n",
      "Epoch: 0230 loss_train: 0.1906 acc_train: 0.8924 acc_val: 0.9600\n",
      "Epoch: 0231 loss_train: 0.1975 acc_train: 0.8901 acc_val: 0.9600\n",
      "Epoch: 0232 loss_train: 0.1815 acc_train: 0.8968 acc_val: 0.9600\n",
      "Epoch: 0233 loss_train: 0.1830 acc_train: 0.8916 acc_val: 0.9600\n",
      "Epoch: 0234 loss_train: 0.1948 acc_train: 0.8827 acc_val: 0.9600\n",
      "Epoch: 0235 loss_train: 0.1917 acc_train: 0.8886 acc_val: 0.9600\n",
      "Epoch: 0236 loss_train: 0.1936 acc_train: 0.8879 acc_val: 0.9600\n",
      "Epoch: 0237 loss_train: 0.1898 acc_train: 0.8782 acc_val: 0.9600\n",
      "Epoch: 0238 loss_train: 0.1928 acc_train: 0.8909 acc_val: 0.9600\n",
      "Epoch: 0239 loss_train: 0.1747 acc_train: 0.8998 acc_val: 0.9600\n",
      "Epoch: 0240 loss_train: 0.1884 acc_train: 0.8857 acc_val: 0.9600\n",
      "Epoch: 0241 loss_train: 0.1937 acc_train: 0.8745 acc_val: 0.9600\n",
      "Epoch: 0242 loss_train: 0.1941 acc_train: 0.8894 acc_val: 0.9600\n",
      "Epoch: 0243 loss_train: 0.1888 acc_train: 0.8901 acc_val: 0.9600\n",
      "Epoch: 0244 loss_train: 0.2090 acc_train: 0.8731 acc_val: 0.9600\n",
      "Epoch: 0245 loss_train: 0.2200 acc_train: 0.8849 acc_val: 0.9600\n",
      "Epoch: 0246 loss_train: 0.2498 acc_train: 0.8968 acc_val: 0.9600\n",
      "Epoch: 0247 loss_train: 0.1975 acc_train: 0.8834 acc_val: 0.9600\n",
      "Epoch: 0248 loss_train: 0.1941 acc_train: 0.8842 acc_val: 0.9600\n",
      "Epoch: 0249 loss_train: 0.1823 acc_train: 0.8931 acc_val: 0.9600\n",
      "Epoch: 0250 loss_train: 0.1928 acc_train: 0.8894 acc_val: 0.9600\n",
      "Epoch: 0251 loss_train: 0.1951 acc_train: 0.8842 acc_val: 0.9600\n",
      "Epoch: 0252 loss_train: 0.1767 acc_train: 0.9035 acc_val: 0.9600\n",
      "Epoch: 0253 loss_train: 0.1790 acc_train: 0.8916 acc_val: 0.9600\n",
      "Epoch: 0254 loss_train: 0.1863 acc_train: 0.8931 acc_val: 0.9600\n",
      "Epoch: 0255 loss_train: 0.1783 acc_train: 0.8983 acc_val: 0.9600\n",
      "Epoch: 0256 loss_train: 0.2201 acc_train: 0.8857 acc_val: 0.9600\n",
      "Epoch: 0257 loss_train: 0.2052 acc_train: 0.8797 acc_val: 0.9600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0258 loss_train: 0.1960 acc_train: 0.8775 acc_val: 0.9600\n",
      "Epoch: 0259 loss_train: 0.1816 acc_train: 0.8916 acc_val: 0.9600\n",
      "Epoch: 0260 loss_train: 0.1943 acc_train: 0.8916 acc_val: 0.9600\n",
      "Epoch: 0261 loss_train: 0.1824 acc_train: 0.8849 acc_val: 0.9600\n",
      "Epoch: 0262 loss_train: 0.1905 acc_train: 0.8901 acc_val: 0.9600\n",
      "Epoch: 0263 loss_train: 0.1946 acc_train: 0.8886 acc_val: 0.9600\n",
      "Epoch: 0264 loss_train: 0.1983 acc_train: 0.8879 acc_val: 0.9600\n",
      "Epoch: 0265 loss_train: 0.1877 acc_train: 0.8953 acc_val: 0.9600\n",
      "Epoch: 0266 loss_train: 0.1932 acc_train: 0.8872 acc_val: 0.9600\n",
      "Epoch: 0267 loss_train: 0.1895 acc_train: 0.8857 acc_val: 0.9600\n",
      "Epoch: 0268 loss_train: 0.1737 acc_train: 0.8976 acc_val: 0.9600\n",
      "Epoch: 0269 loss_train: 0.1927 acc_train: 0.8812 acc_val: 0.9600\n",
      "Epoch: 0270 loss_train: 0.1783 acc_train: 0.8857 acc_val: 0.9600\n",
      "Epoch: 0271 loss_train: 0.1886 acc_train: 0.8886 acc_val: 0.9600\n",
      "Epoch: 0272 loss_train: 0.1770 acc_train: 0.9050 acc_val: 0.9600\n",
      "Epoch: 0273 loss_train: 0.1817 acc_train: 0.8857 acc_val: 0.9600\n",
      "Epoch: 0274 loss_train: 0.1763 acc_train: 0.8946 acc_val: 0.9600\n",
      "Epoch: 0275 loss_train: 0.1580 acc_train: 0.9027 acc_val: 0.9600\n",
      "Epoch: 0276 loss_train: 0.2093 acc_train: 0.8782 acc_val: 0.9600\n",
      "Epoch: 0277 loss_train: 0.2038 acc_train: 0.8686 acc_val: 0.9600\n",
      "Epoch: 0278 loss_train: 0.2282 acc_train: 0.8842 acc_val: 0.9600\n",
      "Epoch: 0279 loss_train: 0.1815 acc_train: 0.8909 acc_val: 0.9600\n",
      "Epoch: 0280 loss_train: 0.1801 acc_train: 0.9020 acc_val: 0.9600\n",
      "Epoch: 0281 loss_train: 0.1831 acc_train: 0.8864 acc_val: 0.9600\n",
      "Epoch: 0282 loss_train: 0.1905 acc_train: 0.8938 acc_val: 0.9600\n",
      "Epoch: 0283 loss_train: 0.1825 acc_train: 0.8924 acc_val: 0.9600\n",
      "Epoch: 0284 loss_train: 0.1811 acc_train: 0.8924 acc_val: 0.9600\n",
      "Epoch: 0285 loss_train: 0.1786 acc_train: 0.8946 acc_val: 0.9600\n",
      "Epoch: 0286 loss_train: 0.1888 acc_train: 0.8909 acc_val: 0.9600\n",
      "Epoch: 0287 loss_train: 0.1748 acc_train: 0.8976 acc_val: 0.9600\n",
      "Epoch: 0288 loss_train: 0.1741 acc_train: 0.9057 acc_val: 0.9600\n",
      "Epoch: 0289 loss_train: 0.1827 acc_train: 0.8872 acc_val: 0.9600\n",
      "Epoch: 0290 loss_train: 0.1626 acc_train: 0.9169 acc_val: 0.9600\n",
      "Epoch: 0291 loss_train: 0.1985 acc_train: 0.8894 acc_val: 0.9600\n",
      "Epoch: 0292 loss_train: 0.2105 acc_train: 0.8820 acc_val: 0.9600\n",
      "Epoch: 0293 loss_train: 0.1914 acc_train: 0.8745 acc_val: 0.9600\n",
      "Epoch: 0294 loss_train: 0.1822 acc_train: 0.8998 acc_val: 0.9600\n",
      "Epoch: 0295 loss_train: 0.1982 acc_train: 0.8797 acc_val: 0.9600\n",
      "Epoch: 0296 loss_train: 0.1907 acc_train: 0.8834 acc_val: 0.9600\n",
      "Epoch: 0297 loss_train: 0.1732 acc_train: 0.8976 acc_val: 0.9600\n",
      "Epoch: 0298 loss_train: 0.1842 acc_train: 0.8827 acc_val: 0.9600\n",
      "Epoch: 0299 loss_train: 0.1973 acc_train: 0.8931 acc_val: 0.9600\n",
      "Epoch: 0300 loss_train: 0.1964 acc_train: 0.8827 acc_val: 0.9600\n",
      "Epoch: 0301 loss_train: 0.1778 acc_train: 0.8976 acc_val: 0.9600\n",
      "Epoch: 0302 loss_train: 0.1913 acc_train: 0.8805 acc_val: 0.9600\n",
      "Epoch: 0303 loss_train: 0.1979 acc_train: 0.8827 acc_val: 0.9600\n",
      "Epoch: 0304 loss_train: 0.1823 acc_train: 0.8938 acc_val: 0.9600\n",
      "Epoch: 0305 loss_train: 0.1683 acc_train: 0.8976 acc_val: 0.9600\n",
      "Epoch: 0306 loss_train: 0.2003 acc_train: 0.8805 acc_val: 0.9600\n",
      "Epoch: 0307 loss_train: 0.1690 acc_train: 0.9042 acc_val: 0.9600\n",
      "Epoch: 0308 loss_train: 0.1963 acc_train: 0.8745 acc_val: 0.9600\n",
      "Epoch: 0309 loss_train: 0.1670 acc_train: 0.8938 acc_val: 0.9600\n",
      "Epoch: 0310 loss_train: 0.1858 acc_train: 0.8857 acc_val: 0.9600\n",
      "Epoch: 0311 loss_train: 0.1663 acc_train: 0.9027 acc_val: 0.9600\n",
      "Epoch: 0312 loss_train: 0.1848 acc_train: 0.8953 acc_val: 0.9600\n",
      "Epoch: 0313 loss_train: 0.1858 acc_train: 0.9005 acc_val: 0.9600\n",
      "Epoch: 0314 loss_train: 0.1772 acc_train: 0.8968 acc_val: 0.9600\n",
      "Epoch: 0315 loss_train: 0.1703 acc_train: 0.8961 acc_val: 0.9600\n",
      "Epoch: 0316 loss_train: 0.1888 acc_train: 0.8916 acc_val: 0.9600\n",
      "Epoch: 0317 loss_train: 0.1990 acc_train: 0.8849 acc_val: 0.9600\n",
      "Epoch: 0318 loss_train: 0.1773 acc_train: 0.8961 acc_val: 0.9600\n",
      "Epoch: 0319 loss_train: 0.1792 acc_train: 0.8924 acc_val: 0.9600\n",
      "Epoch: 0320 loss_train: 0.1841 acc_train: 0.8886 acc_val: 0.9600\n",
      "Epoch: 0321 loss_train: 0.2178 acc_train: 0.8679 acc_val: 0.9600\n",
      "Epoch: 0322 loss_train: 0.1803 acc_train: 0.9005 acc_val: 0.9600\n",
      "Epoch: 0323 loss_train: 0.1934 acc_train: 0.8894 acc_val: 0.9600\n",
      "Epoch: 0324 loss_train: 0.1733 acc_train: 0.8968 acc_val: 0.9600\n",
      "Epoch: 0325 loss_train: 0.1764 acc_train: 0.8909 acc_val: 0.9600\n",
      "Epoch: 0326 loss_train: 0.1840 acc_train: 0.8924 acc_val: 0.9600\n",
      "Epoch: 0327 loss_train: 0.2007 acc_train: 0.8827 acc_val: 0.9600\n",
      "Epoch: 0328 loss_train: 0.1646 acc_train: 0.8976 acc_val: 0.9600\n",
      "Epoch: 0329 loss_train: 0.1966 acc_train: 0.8901 acc_val: 0.9600\n",
      "Epoch: 0330 loss_train: 0.1864 acc_train: 0.8924 acc_val: 0.9600\n",
      "Epoch: 0331 loss_train: 0.1826 acc_train: 0.8938 acc_val: 0.9600\n",
      "Epoch: 0332 loss_train: 0.1745 acc_train: 0.8983 acc_val: 0.9600\n",
      "Epoch: 0333 loss_train: 0.1854 acc_train: 0.8864 acc_val: 0.9600\n",
      "Epoch: 0334 loss_train: 0.2023 acc_train: 0.8782 acc_val: 0.9600\n",
      "Epoch: 0335 loss_train: 0.1725 acc_train: 0.8946 acc_val: 0.9600\n",
      "Epoch: 0336 loss_train: 0.1904 acc_train: 0.8901 acc_val: 0.9600\n",
      "Epoch: 0337 loss_train: 0.1871 acc_train: 0.8983 acc_val: 0.9600\n",
      "Epoch: 0338 loss_train: 0.1860 acc_train: 0.8812 acc_val: 0.9600\n",
      "Epoch: 0339 loss_train: 0.1823 acc_train: 0.8946 acc_val: 0.9600\n",
      "Epoch: 0340 loss_train: 0.1917 acc_train: 0.8938 acc_val: 0.9600\n",
      "Epoch: 0341 loss_train: 0.1763 acc_train: 0.9057 acc_val: 0.9600\n",
      "Epoch: 0342 loss_train: 0.1708 acc_train: 0.9072 acc_val: 0.9600\n",
      "Epoch: 0343 loss_train: 0.1816 acc_train: 0.8924 acc_val: 0.9600\n",
      "Epoch: 0344 loss_train: 0.1756 acc_train: 0.8909 acc_val: 0.9600\n",
      "Epoch: 0345 loss_train: 0.1670 acc_train: 0.9065 acc_val: 0.9600\n",
      "Epoch: 0346 loss_train: 0.1831 acc_train: 0.8827 acc_val: 0.9600\n",
      "Epoch: 0347 loss_train: 0.1922 acc_train: 0.8857 acc_val: 0.9600\n",
      "Epoch: 0348 loss_train: 0.2003 acc_train: 0.8827 acc_val: 0.9600\n",
      "Epoch: 0349 loss_train: 0.1923 acc_train: 0.8894 acc_val: 0.9600\n",
      "Epoch: 0350 loss_train: 0.1676 acc_train: 0.9020 acc_val: 0.9600\n",
      "Epoch: 0351 loss_train: 0.1885 acc_train: 0.8872 acc_val: 0.9600\n",
      "Epoch: 0352 loss_train: 0.2012 acc_train: 0.8790 acc_val: 0.9600\n",
      "Epoch: 0353 loss_train: 0.1873 acc_train: 0.8961 acc_val: 0.9600\n",
      "Epoch: 0354 loss_train: 0.1742 acc_train: 0.8916 acc_val: 0.9600\n",
      "Epoch: 0355 loss_train: 0.1782 acc_train: 0.8901 acc_val: 0.9600\n",
      "Epoch: 0356 loss_train: 0.2033 acc_train: 0.8775 acc_val: 0.9600\n",
      "Epoch: 0357 loss_train: 0.1919 acc_train: 0.8916 acc_val: 0.9600\n",
      "Epoch: 0358 loss_train: 0.1784 acc_train: 0.8946 acc_val: 0.9600\n",
      "Epoch: 0359 loss_train: 0.1748 acc_train: 0.8886 acc_val: 0.9600\n",
      "Epoch: 0360 loss_train: 0.1804 acc_train: 0.8901 acc_val: 0.9600\n",
      "Epoch: 0361 loss_train: 0.1954 acc_train: 0.8842 acc_val: 0.9600\n",
      "Epoch: 0362 loss_train: 0.1901 acc_train: 0.8946 acc_val: 0.9600\n",
      "Epoch: 0363 loss_train: 0.1969 acc_train: 0.8775 acc_val: 0.9600\n",
      "Epoch: 0364 loss_train: 0.1923 acc_train: 0.8805 acc_val: 0.9600\n",
      "Epoch: 0365 loss_train: 0.1572 acc_train: 0.9065 acc_val: 0.9600\n",
      "Epoch: 0366 loss_train: 0.1785 acc_train: 0.9042 acc_val: 0.9600\n",
      "Epoch: 0367 loss_train: 0.1613 acc_train: 0.9057 acc_val: 0.9600\n",
      "Epoch: 0368 loss_train: 0.1782 acc_train: 0.8976 acc_val: 0.9600\n",
      "Epoch: 0369 loss_train: 0.1826 acc_train: 0.8879 acc_val: 0.9600\n",
      "Epoch: 0370 loss_train: 0.1844 acc_train: 0.9042 acc_val: 0.9600\n",
      "Epoch: 0371 loss_train: 0.1799 acc_train: 0.8872 acc_val: 0.9600\n",
      "Epoch: 0372 loss_train: 0.1806 acc_train: 0.8879 acc_val: 0.9600\n",
      "Epoch: 0373 loss_train: 0.1689 acc_train: 0.9057 acc_val: 0.9600\n",
      "Epoch: 0374 loss_train: 0.2078 acc_train: 0.8731 acc_val: 0.9600\n",
      "Epoch: 0375 loss_train: 0.1879 acc_train: 0.9020 acc_val: 0.9600\n",
      "Epoch: 0376 loss_train: 0.2014 acc_train: 0.8894 acc_val: 0.9600\n",
      "Epoch: 0377 loss_train: 0.2029 acc_train: 0.8790 acc_val: 0.9600\n",
      "Epoch: 0378 loss_train: 0.1928 acc_train: 0.8857 acc_val: 0.9600\n",
      "Epoch: 0379 loss_train: 0.1795 acc_train: 0.8924 acc_val: 0.9600\n",
      "Epoch: 0380 loss_train: 0.2067 acc_train: 0.8716 acc_val: 0.9600\n",
      "Epoch: 0381 loss_train: 0.1950 acc_train: 0.8931 acc_val: 0.9600\n",
      "Epoch: 0382 loss_train: 0.1813 acc_train: 0.8976 acc_val: 0.9600\n",
      "Epoch: 0383 loss_train: 0.1887 acc_train: 0.8842 acc_val: 0.9600\n",
      "Epoch: 0384 loss_train: 0.1841 acc_train: 0.8946 acc_val: 0.9600\n",
      "Epoch: 0385 loss_train: 0.1920 acc_train: 0.8768 acc_val: 0.9600\n",
      "Epoch: 0386 loss_train: 0.1842 acc_train: 0.8946 acc_val: 0.9600\n",
      "Epoch: 0387 loss_train: 0.2021 acc_train: 0.8827 acc_val: 0.9600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0388 loss_train: 0.1706 acc_train: 0.8931 acc_val: 0.9600\n",
      "Epoch: 0389 loss_train: 0.1858 acc_train: 0.8938 acc_val: 0.9600\n",
      "Epoch: 0390 loss_train: 0.1811 acc_train: 0.8901 acc_val: 0.9600\n",
      "Epoch: 0391 loss_train: 0.1793 acc_train: 0.8879 acc_val: 0.9600\n",
      "Epoch: 0392 loss_train: 0.1708 acc_train: 0.8968 acc_val: 0.9600\n",
      "Epoch: 0393 loss_train: 0.1765 acc_train: 0.8968 acc_val: 0.9600\n",
      "Epoch: 0394 loss_train: 0.1768 acc_train: 0.9005 acc_val: 0.9600\n",
      "Epoch: 0395 loss_train: 0.1640 acc_train: 0.9020 acc_val: 0.9600\n",
      "Epoch: 0396 loss_train: 0.1870 acc_train: 0.8872 acc_val: 0.9600\n",
      "Epoch: 0397 loss_train: 0.1759 acc_train: 0.8953 acc_val: 0.9600\n",
      "Epoch: 0398 loss_train: 0.1717 acc_train: 0.8924 acc_val: 0.9600\n",
      "Epoch: 0399 loss_train: 0.1814 acc_train: 0.9057 acc_val: 0.9600\n",
      "Epoch: 0400 loss_train: 0.1738 acc_train: 0.8983 acc_val: 0.9600\n",
      "Epoch: 0401 loss_train: 0.1816 acc_train: 0.8953 acc_val: 0.9600\n",
      "Epoch: 0402 loss_train: 0.1658 acc_train: 0.8946 acc_val: 0.9600\n",
      "Epoch: 0403 loss_train: 0.1825 acc_train: 0.8924 acc_val: 0.9600\n",
      "Epoch: 0404 loss_train: 0.1810 acc_train: 0.8968 acc_val: 0.9600\n",
      "Epoch: 0405 loss_train: 0.1986 acc_train: 0.8753 acc_val: 0.9600\n",
      "Epoch: 0406 loss_train: 0.1994 acc_train: 0.8864 acc_val: 0.9600\n",
      "Epoch: 0407 loss_train: 0.1948 acc_train: 0.8909 acc_val: 0.9600\n",
      "Epoch: 0408 loss_train: 0.1867 acc_train: 0.8849 acc_val: 0.9600\n",
      "Epoch: 0409 loss_train: 0.1788 acc_train: 0.8901 acc_val: 0.9600\n",
      "Epoch: 0410 loss_train: 0.1764 acc_train: 0.8976 acc_val: 0.9600\n",
      "Epoch: 0411 loss_train: 0.1721 acc_train: 0.8946 acc_val: 0.9600\n",
      "Epoch: 0412 loss_train: 0.1743 acc_train: 0.9005 acc_val: 0.9600\n",
      "Epoch: 0413 loss_train: 0.1738 acc_train: 0.8961 acc_val: 0.9600\n",
      "Epoch: 0414 loss_train: 0.1931 acc_train: 0.8872 acc_val: 0.9600\n",
      "Epoch: 0415 loss_train: 0.1853 acc_train: 0.8916 acc_val: 0.9600\n",
      "Epoch: 0416 loss_train: 0.1794 acc_train: 0.8909 acc_val: 0.9600\n",
      "Epoch: 0417 loss_train: 0.1799 acc_train: 0.8879 acc_val: 0.9600\n",
      "Epoch: 0418 loss_train: 0.1857 acc_train: 0.8946 acc_val: 0.9600\n",
      "Epoch: 0419 loss_train: 0.1915 acc_train: 0.8760 acc_val: 0.9600\n",
      "Epoch: 0420 loss_train: 0.1909 acc_train: 0.8916 acc_val: 0.9600\n",
      "Epoch: 0421 loss_train: 0.1900 acc_train: 0.8864 acc_val: 0.9600\n",
      "Epoch: 0422 loss_train: 0.1902 acc_train: 0.8931 acc_val: 0.9600\n",
      "Epoch: 0423 loss_train: 0.1592 acc_train: 0.9027 acc_val: 0.9600\n",
      "Epoch: 0424 loss_train: 0.1777 acc_train: 0.9020 acc_val: 0.9600\n",
      "Epoch: 0425 loss_train: 0.1813 acc_train: 0.8946 acc_val: 0.9600\n",
      "Epoch: 0426 loss_train: 0.1694 acc_train: 0.8961 acc_val: 0.9600\n",
      "Epoch: 0427 loss_train: 0.1762 acc_train: 0.9020 acc_val: 0.9600\n",
      "Epoch: 0428 loss_train: 0.1927 acc_train: 0.8812 acc_val: 0.9600\n",
      "Epoch: 0429 loss_train: 0.2051 acc_train: 0.8790 acc_val: 0.9600\n",
      "Epoch: 0430 loss_train: 0.1874 acc_train: 0.8916 acc_val: 0.9600\n",
      "Epoch: 0431 loss_train: 0.1749 acc_train: 0.8961 acc_val: 0.9600\n",
      "Epoch: 0432 loss_train: 0.2002 acc_train: 0.8775 acc_val: 0.9600\n",
      "Epoch: 0433 loss_train: 0.1851 acc_train: 0.8834 acc_val: 0.9600\n",
      "Epoch: 0434 loss_train: 0.1689 acc_train: 0.8983 acc_val: 0.9600\n",
      "Epoch: 0435 loss_train: 0.2031 acc_train: 0.8716 acc_val: 0.9600\n",
      "Epoch: 0436 loss_train: 0.1918 acc_train: 0.8886 acc_val: 0.9600\n",
      "Epoch: 0437 loss_train: 0.1812 acc_train: 0.8886 acc_val: 0.9600\n",
      "Epoch: 0438 loss_train: 0.1825 acc_train: 0.8924 acc_val: 0.9600\n",
      "Epoch: 0439 loss_train: 0.1913 acc_train: 0.8753 acc_val: 0.9600\n",
      "Epoch: 0440 loss_train: 0.1677 acc_train: 0.9102 acc_val: 0.9600\n",
      "Epoch: 0441 loss_train: 0.1977 acc_train: 0.8753 acc_val: 0.9600\n",
      "Epoch: 0442 loss_train: 0.1880 acc_train: 0.8797 acc_val: 0.9600\n",
      "Epoch: 0443 loss_train: 0.2021 acc_train: 0.8894 acc_val: 0.9600\n",
      "Epoch: 0444 loss_train: 0.1963 acc_train: 0.8827 acc_val: 0.9600\n",
      "Epoch: 0445 loss_train: 0.1855 acc_train: 0.8879 acc_val: 0.9600\n",
      "Epoch: 0446 loss_train: 0.1792 acc_train: 0.8909 acc_val: 0.9600\n",
      "Epoch: 0447 loss_train: 0.1997 acc_train: 0.8820 acc_val: 0.9600\n",
      "Epoch: 0448 loss_train: 0.1823 acc_train: 0.9013 acc_val: 0.9600\n",
      "Epoch: 0449 loss_train: 0.1866 acc_train: 0.8857 acc_val: 0.9600\n",
      "Epoch: 0450 loss_train: 0.1868 acc_train: 0.8961 acc_val: 0.9600\n",
      "Epoch: 0451 loss_train: 0.1810 acc_train: 0.8953 acc_val: 0.9600\n",
      "Epoch: 0452 loss_train: 0.1742 acc_train: 0.8953 acc_val: 0.9600\n",
      "Epoch: 0453 loss_train: 0.1748 acc_train: 0.8976 acc_val: 0.9600\n",
      "Epoch: 0454 loss_train: 0.2049 acc_train: 0.8938 acc_val: 0.9600\n",
      "Epoch: 0455 loss_train: 0.1906 acc_train: 0.8834 acc_val: 0.9600\n",
      "Epoch: 0456 loss_train: 0.1960 acc_train: 0.8842 acc_val: 0.9600\n",
      "Epoch: 0457 loss_train: 0.1834 acc_train: 0.8901 acc_val: 0.9600\n",
      "Epoch: 0458 loss_train: 0.1765 acc_train: 0.8953 acc_val: 0.9600\n",
      "Epoch: 0459 loss_train: 0.1982 acc_train: 0.8931 acc_val: 0.9600\n",
      "Epoch: 0460 loss_train: 0.1901 acc_train: 0.8842 acc_val: 0.9600\n",
      "Epoch: 0461 loss_train: 0.1766 acc_train: 0.9013 acc_val: 0.9600\n",
      "Epoch: 0462 loss_train: 0.2027 acc_train: 0.8938 acc_val: 0.9600\n",
      "Epoch: 0463 loss_train: 0.1766 acc_train: 0.8879 acc_val: 0.9600\n",
      "Epoch: 0464 loss_train: 0.2057 acc_train: 0.8790 acc_val: 0.9600\n",
      "Epoch: 0465 loss_train: 0.1750 acc_train: 0.8976 acc_val: 0.9600\n",
      "Epoch: 0466 loss_train: 0.1872 acc_train: 0.8924 acc_val: 0.9600\n",
      "Epoch: 0467 loss_train: 0.1728 acc_train: 0.9035 acc_val: 0.9600\n",
      "Epoch: 0468 loss_train: 0.1601 acc_train: 0.8998 acc_val: 0.9600\n",
      "Epoch: 0469 loss_train: 0.1956 acc_train: 0.8745 acc_val: 0.9600\n",
      "Epoch: 0470 loss_train: 0.1753 acc_train: 0.8976 acc_val: 0.9600\n",
      "Epoch: 0471 loss_train: 0.2104 acc_train: 0.8753 acc_val: 0.9600\n",
      "Epoch: 0472 loss_train: 0.1970 acc_train: 0.8924 acc_val: 0.9600\n",
      "Epoch: 0473 loss_train: 0.1716 acc_train: 0.8946 acc_val: 0.9600\n",
      "Epoch: 0474 loss_train: 0.1851 acc_train: 0.8842 acc_val: 0.9600\n",
      "Epoch: 0475 loss_train: 0.1818 acc_train: 0.8909 acc_val: 0.9600\n",
      "Epoch: 0476 loss_train: 0.1736 acc_train: 0.9013 acc_val: 0.9600\n",
      "Epoch: 0477 loss_train: 0.1692 acc_train: 0.9042 acc_val: 0.9600\n",
      "Epoch: 0478 loss_train: 0.1939 acc_train: 0.8849 acc_val: 0.9600\n",
      "Epoch: 0479 loss_train: 0.1808 acc_train: 0.8953 acc_val: 0.9600\n",
      "Epoch: 0480 loss_train: 0.1865 acc_train: 0.8924 acc_val: 0.9600\n",
      "Epoch: 0481 loss_train: 0.1866 acc_train: 0.8938 acc_val: 0.9600\n",
      "Epoch: 0482 loss_train: 0.1940 acc_train: 0.8946 acc_val: 0.9600\n",
      "Epoch: 0483 loss_train: 0.1746 acc_train: 0.8998 acc_val: 0.9600\n",
      "Epoch: 0484 loss_train: 0.1900 acc_train: 0.8916 acc_val: 0.9600\n",
      "Epoch: 0485 loss_train: 0.2024 acc_train: 0.8701 acc_val: 0.9600\n",
      "Epoch: 0486 loss_train: 0.1899 acc_train: 0.8946 acc_val: 0.9600\n",
      "Epoch: 0487 loss_train: 0.1971 acc_train: 0.8782 acc_val: 0.9600\n",
      "Epoch: 0488 loss_train: 0.1706 acc_train: 0.8976 acc_val: 0.9600\n",
      "Epoch: 0489 loss_train: 0.1844 acc_train: 0.8901 acc_val: 0.9600\n",
      "Epoch: 0490 loss_train: 0.1771 acc_train: 0.8931 acc_val: 0.9600\n",
      "Epoch: 0491 loss_train: 0.1949 acc_train: 0.8938 acc_val: 0.9600\n",
      "Epoch: 0492 loss_train: 0.1711 acc_train: 0.8961 acc_val: 0.9600\n",
      "Epoch: 0493 loss_train: 0.1711 acc_train: 0.8998 acc_val: 0.9600\n",
      "Epoch: 0494 loss_train: 0.1827 acc_train: 0.8961 acc_val: 0.9600\n",
      "Epoch: 0495 loss_train: 0.1829 acc_train: 0.8938 acc_val: 0.9600\n",
      "Epoch: 0496 loss_train: 0.2000 acc_train: 0.8745 acc_val: 0.9600\n",
      "Epoch: 0497 loss_train: 0.1676 acc_train: 0.9005 acc_val: 0.9600\n",
      "Epoch: 0498 loss_train: 0.1891 acc_train: 0.8909 acc_val: 0.9600\n",
      "Epoch: 0499 loss_train: 0.1976 acc_train: 0.8872 acc_val: 0.9600\n",
      "Epoch: 0500 loss_train: 0.1871 acc_train: 0.8834 acc_val: 0.9600\n",
      "Epoch: 0501 loss_train: 0.1664 acc_train: 0.9065 acc_val: 0.9600\n",
      "Epoch: 0502 loss_train: 0.2003 acc_train: 0.8805 acc_val: 0.9600\n",
      "Epoch: 0503 loss_train: 0.1962 acc_train: 0.8782 acc_val: 0.9600\n",
      "Epoch: 0504 loss_train: 0.2055 acc_train: 0.8805 acc_val: 0.9600\n",
      "Epoch: 0505 loss_train: 0.1737 acc_train: 0.8924 acc_val: 0.9600\n",
      "Epoch: 0506 loss_train: 0.1832 acc_train: 0.8842 acc_val: 0.9600\n",
      "Epoch: 0507 loss_train: 0.1881 acc_train: 0.8901 acc_val: 0.9600\n",
      "Epoch: 0508 loss_train: 0.1746 acc_train: 0.8976 acc_val: 0.9600\n",
      "Epoch: 0509 loss_train: 0.1787 acc_train: 0.8916 acc_val: 0.9600\n",
      "Epoch: 0510 loss_train: 0.1894 acc_train: 0.8864 acc_val: 0.9600\n",
      "Epoch: 0511 loss_train: 0.1960 acc_train: 0.8849 acc_val: 0.9600\n",
      "Epoch: 0512 loss_train: 0.1941 acc_train: 0.8864 acc_val: 0.9600\n",
      "Epoch: 0513 loss_train: 0.1691 acc_train: 0.9013 acc_val: 0.9600\n",
      "Epoch: 0514 loss_train: 0.1929 acc_train: 0.8894 acc_val: 0.9600\n",
      "Epoch: 0515 loss_train: 0.1799 acc_train: 0.8827 acc_val: 0.9600\n",
      "Epoch: 0516 loss_train: 0.2017 acc_train: 0.8805 acc_val: 0.9600\n",
      "Epoch: 0517 loss_train: 0.1761 acc_train: 0.8968 acc_val: 0.9600\n",
      "Epoch: 0518 loss_train: 0.1767 acc_train: 0.8924 acc_val: 0.9600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0519 loss_train: 0.1964 acc_train: 0.8894 acc_val: 0.9600\n",
      "Epoch: 0520 loss_train: 0.1832 acc_train: 0.8931 acc_val: 0.9600\n",
      "Epoch: 0521 loss_train: 0.1762 acc_train: 0.8998 acc_val: 0.9600\n",
      "Epoch: 0522 loss_train: 0.1902 acc_train: 0.8894 acc_val: 0.9600\n",
      "Epoch: 0523 loss_train: 0.1660 acc_train: 0.9072 acc_val: 0.9600\n",
      "Epoch: 0524 loss_train: 0.1758 acc_train: 0.8938 acc_val: 0.9600\n",
      "Epoch: 0525 loss_train: 0.1767 acc_train: 0.9005 acc_val: 0.9600\n",
      "Epoch: 0526 loss_train: 0.1704 acc_train: 0.8931 acc_val: 0.9600\n",
      "Epoch: 0527 loss_train: 0.1891 acc_train: 0.9013 acc_val: 0.9600\n",
      "Epoch: 0528 loss_train: 0.1987 acc_train: 0.8872 acc_val: 0.9600\n",
      "Epoch: 0529 loss_train: 0.1756 acc_train: 0.9057 acc_val: 0.9600\n",
      "Epoch: 0530 loss_train: 0.1909 acc_train: 0.8872 acc_val: 0.9600\n",
      "Epoch: 0531 loss_train: 0.1901 acc_train: 0.8775 acc_val: 0.9600\n",
      "Epoch: 0532 loss_train: 0.1681 acc_train: 0.8953 acc_val: 0.9600\n",
      "Epoch: 0533 loss_train: 0.1863 acc_train: 0.8968 acc_val: 0.9600\n",
      "Epoch: 0534 loss_train: 0.1672 acc_train: 0.9065 acc_val: 0.9600\n",
      "Epoch: 0535 loss_train: 0.1689 acc_train: 0.9042 acc_val: 0.9600\n",
      "Epoch: 0536 loss_train: 0.1997 acc_train: 0.8820 acc_val: 0.9600\n",
      "Epoch: 0537 loss_train: 0.2065 acc_train: 0.8679 acc_val: 0.9600\n",
      "Epoch: 0538 loss_train: 0.2200 acc_train: 0.8723 acc_val: 0.9600\n",
      "Epoch: 0539 loss_train: 0.1681 acc_train: 0.8938 acc_val: 0.9600\n",
      "Epoch: 0540 loss_train: 0.1776 acc_train: 0.9027 acc_val: 0.9600\n",
      "Epoch: 0541 loss_train: 0.1833 acc_train: 0.8968 acc_val: 0.9600\n",
      "Epoch: 0542 loss_train: 0.2101 acc_train: 0.8894 acc_val: 0.9600\n",
      "Epoch: 0543 loss_train: 0.1845 acc_train: 0.8886 acc_val: 0.9600\n",
      "Epoch: 0544 loss_train: 0.1947 acc_train: 0.8864 acc_val: 0.9600\n",
      "Epoch: 0545 loss_train: 0.1709 acc_train: 0.8990 acc_val: 0.9600\n",
      "Epoch: 0546 loss_train: 0.1814 acc_train: 0.8983 acc_val: 0.9600\n",
      "Epoch: 0547 loss_train: 0.1955 acc_train: 0.8901 acc_val: 0.9600\n",
      "Epoch: 0548 loss_train: 0.1945 acc_train: 0.8872 acc_val: 0.9600\n",
      "Epoch: 0549 loss_train: 0.1848 acc_train: 0.8864 acc_val: 0.9600\n",
      "Epoch: 0550 loss_train: 0.1964 acc_train: 0.8805 acc_val: 0.9600\n",
      "Epoch: 0551 loss_train: 0.1846 acc_train: 0.8842 acc_val: 0.9600\n",
      "Epoch: 0552 loss_train: 0.2022 acc_train: 0.8760 acc_val: 0.9600\n",
      "Epoch: 0553 loss_train: 0.1969 acc_train: 0.8775 acc_val: 0.9600\n",
      "Epoch: 0554 loss_train: 0.1701 acc_train: 0.8968 acc_val: 0.9600\n",
      "Epoch: 0555 loss_train: 0.1647 acc_train: 0.8968 acc_val: 0.9600\n",
      "Epoch: 0556 loss_train: 0.2031 acc_train: 0.8879 acc_val: 0.9600\n",
      "Epoch: 0557 loss_train: 0.1743 acc_train: 0.8946 acc_val: 0.9600\n",
      "Epoch: 0558 loss_train: 0.2089 acc_train: 0.8805 acc_val: 0.9600\n",
      "Epoch: 0559 loss_train: 0.2032 acc_train: 0.8857 acc_val: 0.9600\n",
      "Epoch: 0560 loss_train: 0.1693 acc_train: 0.8976 acc_val: 0.9600\n",
      "Epoch: 0561 loss_train: 0.1671 acc_train: 0.9050 acc_val: 0.9600\n",
      "Epoch: 0562 loss_train: 0.1626 acc_train: 0.8990 acc_val: 0.9600\n",
      "Epoch: 0563 loss_train: 0.1832 acc_train: 0.8834 acc_val: 0.9600\n",
      "Epoch: 0564 loss_train: 0.1861 acc_train: 0.8738 acc_val: 0.9600\n",
      "Epoch: 0565 loss_train: 0.1798 acc_train: 0.8938 acc_val: 0.9600\n",
      "Epoch: 0566 loss_train: 0.1676 acc_train: 0.8931 acc_val: 0.9600\n",
      "Epoch: 0567 loss_train: 0.2012 acc_train: 0.8820 acc_val: 0.9600\n",
      "Epoch: 0568 loss_train: 0.1788 acc_train: 0.9050 acc_val: 0.9600\n",
      "Epoch: 0569 loss_train: 0.1780 acc_train: 0.8946 acc_val: 0.9600\n",
      "Epoch: 0570 loss_train: 0.1945 acc_train: 0.8931 acc_val: 0.9600\n",
      "Epoch: 0571 loss_train: 0.1913 acc_train: 0.8820 acc_val: 0.9600\n",
      "Epoch: 0572 loss_train: 0.1717 acc_train: 0.8968 acc_val: 0.9600\n",
      "Epoch: 0573 loss_train: 0.1791 acc_train: 0.8946 acc_val: 0.9600\n",
      "Epoch: 0574 loss_train: 0.1760 acc_train: 0.8924 acc_val: 0.9600\n",
      "Epoch: 0575 loss_train: 0.1952 acc_train: 0.8812 acc_val: 0.9600\n",
      "Epoch: 0576 loss_train: 0.1891 acc_train: 0.8864 acc_val: 0.9600\n",
      "Epoch: 0577 loss_train: 0.2032 acc_train: 0.8842 acc_val: 0.9600\n",
      "Epoch: 0578 loss_train: 0.1714 acc_train: 0.9027 acc_val: 0.9600\n",
      "Epoch: 0579 loss_train: 0.1744 acc_train: 0.9013 acc_val: 0.9600\n",
      "Epoch: 0580 loss_train: 0.1919 acc_train: 0.8857 acc_val: 0.9600\n",
      "Epoch: 0581 loss_train: 0.1758 acc_train: 0.8968 acc_val: 0.9600\n",
      "Epoch: 0582 loss_train: 0.1863 acc_train: 0.8886 acc_val: 0.9600\n",
      "Epoch: 0583 loss_train: 0.1733 acc_train: 0.8998 acc_val: 0.9600\n",
      "Epoch: 0584 loss_train: 0.1787 acc_train: 0.8990 acc_val: 0.9600\n",
      "Epoch: 0585 loss_train: 0.1875 acc_train: 0.8872 acc_val: 0.9600\n",
      "Epoch: 0586 loss_train: 0.1969 acc_train: 0.8827 acc_val: 0.9600\n",
      "Epoch: 0587 loss_train: 0.2083 acc_train: 0.8790 acc_val: 0.9600\n",
      "Epoch: 0588 loss_train: 0.1873 acc_train: 0.8864 acc_val: 0.9600\n",
      "Epoch: 0589 loss_train: 0.1877 acc_train: 0.8886 acc_val: 0.9600\n",
      "Epoch: 0590 loss_train: 0.2065 acc_train: 0.8768 acc_val: 0.9600\n",
      "Epoch: 0591 loss_train: 0.1763 acc_train: 0.9020 acc_val: 0.9600\n",
      "Epoch: 0592 loss_train: 0.1617 acc_train: 0.8983 acc_val: 0.9600\n",
      "Epoch: 0593 loss_train: 0.1768 acc_train: 0.8931 acc_val: 0.9600\n",
      "Epoch: 0594 loss_train: 0.1772 acc_train: 0.8916 acc_val: 0.9600\n",
      "Epoch: 0595 loss_train: 0.1833 acc_train: 0.8976 acc_val: 0.9600\n",
      "Epoch: 0596 loss_train: 0.1791 acc_train: 0.8946 acc_val: 0.9600\n",
      "Epoch: 0597 loss_train: 0.1830 acc_train: 0.8990 acc_val: 0.9600\n",
      "Epoch: 0598 loss_train: 0.1964 acc_train: 0.8857 acc_val: 0.9600\n",
      "Epoch: 0599 loss_train: 0.1917 acc_train: 0.8842 acc_val: 0.9600\n",
      "Epoch: 0600 loss_train: 0.1760 acc_train: 0.8990 acc_val: 0.9600\n",
      "Epoch: 0601 loss_train: 0.1564 acc_train: 0.9146 acc_val: 0.9600\n",
      "Epoch: 0602 loss_train: 0.2005 acc_train: 0.8834 acc_val: 0.9600\n",
      "Epoch: 0603 loss_train: 0.1801 acc_train: 0.8916 acc_val: 0.9600\n",
      "Epoch: 0604 loss_train: 0.1833 acc_train: 0.8909 acc_val: 0.9600\n",
      "Epoch: 0605 loss_train: 0.1846 acc_train: 0.8901 acc_val: 0.9600\n",
      "Epoch: 0606 loss_train: 0.1961 acc_train: 0.8745 acc_val: 0.9600\n",
      "Epoch: 0607 loss_train: 0.1876 acc_train: 0.8938 acc_val: 0.9600\n",
      "Epoch: 0608 loss_train: 0.1885 acc_train: 0.8976 acc_val: 0.9600\n",
      "Epoch: 0609 loss_train: 0.1898 acc_train: 0.8931 acc_val: 0.9600\n",
      "Epoch: 0610 loss_train: 0.1882 acc_train: 0.8820 acc_val: 0.9600\n",
      "Epoch: 0611 loss_train: 0.1921 acc_train: 0.8834 acc_val: 0.9600\n",
      "Epoch: 0612 loss_train: 0.2005 acc_train: 0.8842 acc_val: 0.9600\n",
      "Epoch: 0613 loss_train: 0.1919 acc_train: 0.8797 acc_val: 0.9600\n",
      "Epoch: 0614 loss_train: 0.1961 acc_train: 0.8775 acc_val: 0.9600\n",
      "Epoch: 0615 loss_train: 0.1908 acc_train: 0.8886 acc_val: 0.9600\n",
      "Epoch: 0616 loss_train: 0.1783 acc_train: 0.8931 acc_val: 0.9600\n",
      "Epoch: 0617 loss_train: 0.1993 acc_train: 0.8760 acc_val: 0.9600\n",
      "Epoch: 0618 loss_train: 0.1747 acc_train: 0.8998 acc_val: 0.9600\n",
      "Epoch: 0619 loss_train: 0.1921 acc_train: 0.8864 acc_val: 0.9600\n",
      "Epoch: 0620 loss_train: 0.1819 acc_train: 0.8857 acc_val: 0.9600\n",
      "Epoch: 0621 loss_train: 0.1969 acc_train: 0.8820 acc_val: 0.9600\n",
      "Epoch: 0622 loss_train: 0.2004 acc_train: 0.8790 acc_val: 0.9600\n",
      "Epoch: 0623 loss_train: 0.1969 acc_train: 0.8909 acc_val: 0.9600\n",
      "Epoch: 0624 loss_train: 0.1949 acc_train: 0.8820 acc_val: 0.9600\n",
      "Epoch: 0625 loss_train: 0.1659 acc_train: 0.8990 acc_val: 0.9600\n",
      "Epoch: 0626 loss_train: 0.1695 acc_train: 0.9094 acc_val: 0.9600\n",
      "Epoch: 0627 loss_train: 0.1821 acc_train: 0.8886 acc_val: 0.9600\n",
      "Epoch: 0628 loss_train: 0.1789 acc_train: 0.8953 acc_val: 0.9600\n",
      "Epoch: 0629 loss_train: 0.1882 acc_train: 0.8953 acc_val: 0.9600\n",
      "Epoch: 0630 loss_train: 0.2025 acc_train: 0.8827 acc_val: 0.9600\n",
      "Epoch: 0631 loss_train: 0.1929 acc_train: 0.8983 acc_val: 0.9600\n",
      "Epoch: 0632 loss_train: 0.1805 acc_train: 0.8916 acc_val: 0.9600\n",
      "Epoch: 0633 loss_train: 0.1598 acc_train: 0.9072 acc_val: 0.9600\n",
      "Epoch: 0634 loss_train: 0.1745 acc_train: 0.8938 acc_val: 0.9600\n",
      "Epoch: 0635 loss_train: 0.1866 acc_train: 0.8938 acc_val: 0.9600\n",
      "Epoch: 0636 loss_train: 0.1699 acc_train: 0.8946 acc_val: 0.9600\n",
      "Epoch: 0637 loss_train: 0.1849 acc_train: 0.9005 acc_val: 0.9600\n",
      "Epoch: 0638 loss_train: 0.1643 acc_train: 0.9013 acc_val: 0.9600\n",
      "Epoch: 0639 loss_train: 0.2065 acc_train: 0.8827 acc_val: 0.9600\n",
      "Epoch: 0640 loss_train: 0.1840 acc_train: 0.8901 acc_val: 0.9600\n",
      "Epoch: 0641 loss_train: 0.1838 acc_train: 0.8894 acc_val: 0.9600\n",
      "Epoch: 0642 loss_train: 0.1889 acc_train: 0.8894 acc_val: 0.9600\n",
      "Epoch: 0643 loss_train: 0.2049 acc_train: 0.8842 acc_val: 0.9600\n",
      "Epoch: 0644 loss_train: 0.1830 acc_train: 0.8864 acc_val: 0.9600\n",
      "Epoch: 0645 loss_train: 0.1810 acc_train: 0.8983 acc_val: 0.9600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0646 loss_train: 0.1636 acc_train: 0.9042 acc_val: 0.9600\n",
      "Epoch: 0647 loss_train: 0.1814 acc_train: 0.8968 acc_val: 0.9600\n",
      "Epoch: 0648 loss_train: 0.1887 acc_train: 0.8909 acc_val: 0.9600\n",
      "Epoch: 0649 loss_train: 0.1716 acc_train: 0.9005 acc_val: 0.9600\n",
      "Epoch: 0650 loss_train: 0.2162 acc_train: 0.8760 acc_val: 0.9600\n",
      "Epoch: 0651 loss_train: 0.1909 acc_train: 0.8834 acc_val: 0.9600\n",
      "Epoch: 0652 loss_train: 0.1731 acc_train: 0.8931 acc_val: 0.9600\n",
      "Epoch: 0653 loss_train: 0.2010 acc_train: 0.8812 acc_val: 0.9600\n",
      "Epoch: 0654 loss_train: 0.1927 acc_train: 0.8946 acc_val: 0.9600\n",
      "Epoch: 0655 loss_train: 0.1728 acc_train: 0.8946 acc_val: 0.9600\n",
      "Epoch: 0656 loss_train: 0.2017 acc_train: 0.8723 acc_val: 0.9600\n",
      "Epoch: 0657 loss_train: 0.1832 acc_train: 0.8879 acc_val: 0.9600\n",
      "Epoch: 0658 loss_train: 0.1739 acc_train: 0.8976 acc_val: 0.9600\n",
      "Epoch: 0659 loss_train: 0.1807 acc_train: 0.8864 acc_val: 0.9600\n",
      "Epoch: 0660 loss_train: 0.1700 acc_train: 0.9042 acc_val: 0.9600\n",
      "Epoch: 0661 loss_train: 0.1774 acc_train: 0.8916 acc_val: 0.9600\n",
      "Epoch: 0662 loss_train: 0.1864 acc_train: 0.8946 acc_val: 0.9600\n",
      "Epoch: 0663 loss_train: 0.1774 acc_train: 0.8886 acc_val: 0.9600\n",
      "Epoch: 0664 loss_train: 0.1883 acc_train: 0.8827 acc_val: 0.9600\n",
      "Epoch: 0665 loss_train: 0.1944 acc_train: 0.8827 acc_val: 0.9600\n",
      "Epoch: 0666 loss_train: 0.1945 acc_train: 0.8857 acc_val: 0.9600\n",
      "Epoch: 0667 loss_train: 0.1798 acc_train: 0.8916 acc_val: 0.9600\n",
      "Epoch: 0668 loss_train: 0.1817 acc_train: 0.8961 acc_val: 0.9600\n",
      "Epoch: 0669 loss_train: 0.1829 acc_train: 0.8797 acc_val: 0.9600\n",
      "Epoch: 0670 loss_train: 0.1732 acc_train: 0.9065 acc_val: 0.9600\n",
      "Epoch: 0671 loss_train: 0.1766 acc_train: 0.8864 acc_val: 0.9600\n",
      "Epoch: 0672 loss_train: 0.1819 acc_train: 0.8953 acc_val: 0.9600\n",
      "Epoch: 0673 loss_train: 0.1888 acc_train: 0.8938 acc_val: 0.9600\n",
      "Epoch: 0674 loss_train: 0.1933 acc_train: 0.8812 acc_val: 0.9600\n",
      "Epoch: 0675 loss_train: 0.1832 acc_train: 0.8924 acc_val: 0.9600\n",
      "Epoch: 0676 loss_train: 0.1793 acc_train: 0.8931 acc_val: 0.9600\n",
      "Epoch: 0677 loss_train: 0.1990 acc_train: 0.8805 acc_val: 0.9600\n",
      "Epoch: 0678 loss_train: 0.1757 acc_train: 0.8857 acc_val: 0.9600\n",
      "Epoch: 0679 loss_train: 0.1753 acc_train: 0.8938 acc_val: 0.9600\n",
      "Epoch: 0680 loss_train: 0.1972 acc_train: 0.8782 acc_val: 0.9600\n",
      "Epoch: 0681 loss_train: 0.1911 acc_train: 0.8782 acc_val: 0.9600\n",
      "Epoch: 0682 loss_train: 0.1853 acc_train: 0.8909 acc_val: 0.9600\n",
      "Epoch: 0683 loss_train: 0.1750 acc_train: 0.8946 acc_val: 0.9600\n",
      "Epoch: 0684 loss_train: 0.1823 acc_train: 0.8946 acc_val: 0.9600\n",
      "Epoch: 0685 loss_train: 0.1971 acc_train: 0.8716 acc_val: 0.9600\n",
      "Epoch: 0686 loss_train: 0.1772 acc_train: 0.8931 acc_val: 0.9600\n",
      "Epoch: 0687 loss_train: 0.1873 acc_train: 0.9013 acc_val: 0.9600\n",
      "Epoch: 0688 loss_train: 0.1834 acc_train: 0.8849 acc_val: 0.9600\n",
      "Epoch: 0689 loss_train: 0.1774 acc_train: 0.8931 acc_val: 0.9600\n",
      "Epoch: 0690 loss_train: 0.2032 acc_train: 0.8671 acc_val: 0.9600\n",
      "Epoch: 0691 loss_train: 0.1648 acc_train: 0.9027 acc_val: 0.9600\n",
      "Epoch: 0692 loss_train: 0.2024 acc_train: 0.8812 acc_val: 0.9600\n",
      "Epoch: 0693 loss_train: 0.1781 acc_train: 0.8946 acc_val: 0.9600\n",
      "Epoch: 0694 loss_train: 0.1844 acc_train: 0.8849 acc_val: 0.9600\n",
      "Epoch: 0695 loss_train: 0.1646 acc_train: 0.9035 acc_val: 0.9600\n",
      "Epoch: 0696 loss_train: 0.1790 acc_train: 0.8916 acc_val: 0.9600\n",
      "Epoch: 0697 loss_train: 0.1727 acc_train: 0.9065 acc_val: 0.9600\n",
      "Epoch: 0698 loss_train: 0.2006 acc_train: 0.8879 acc_val: 0.9600\n",
      "Epoch: 0699 loss_train: 0.1711 acc_train: 0.8998 acc_val: 0.9600\n",
      "Epoch: 0700 loss_train: 0.1845 acc_train: 0.8953 acc_val: 0.9600\n",
      "Epoch: 0701 loss_train: 0.1931 acc_train: 0.8931 acc_val: 0.9600\n",
      "Epoch: 0702 loss_train: 0.1986 acc_train: 0.8768 acc_val: 0.9600\n",
      "Epoch: 0703 loss_train: 0.1862 acc_train: 0.8879 acc_val: 0.9600\n",
      "Epoch: 0704 loss_train: 0.1904 acc_train: 0.8849 acc_val: 0.9600\n",
      "Epoch: 0705 loss_train: 0.1972 acc_train: 0.8760 acc_val: 0.9600\n",
      "Epoch: 0706 loss_train: 0.1889 acc_train: 0.8812 acc_val: 0.9600\n",
      "Epoch: 0707 loss_train: 0.1638 acc_train: 0.9050 acc_val: 0.9600\n",
      "Epoch: 0708 loss_train: 0.1644 acc_train: 0.9065 acc_val: 0.9600\n",
      "Epoch: 0709 loss_train: 0.1726 acc_train: 0.8976 acc_val: 0.9600\n",
      "Epoch: 0710 loss_train: 0.2030 acc_train: 0.8760 acc_val: 0.9600\n",
      "Epoch: 0711 loss_train: 0.1752 acc_train: 0.8983 acc_val: 0.9600\n",
      "Epoch: 0712 loss_train: 0.1838 acc_train: 0.8857 acc_val: 0.9600\n",
      "Epoch: 0713 loss_train: 0.1873 acc_train: 0.8916 acc_val: 0.9600\n",
      "Epoch: 0714 loss_train: 0.1905 acc_train: 0.8827 acc_val: 0.9600\n",
      "Epoch: 0715 loss_train: 0.1905 acc_train: 0.8864 acc_val: 0.9600\n",
      "Epoch: 0716 loss_train: 0.1898 acc_train: 0.8916 acc_val: 0.9600\n",
      "Epoch: 0717 loss_train: 0.1655 acc_train: 0.8968 acc_val: 0.9600\n",
      "Epoch: 0718 loss_train: 0.1875 acc_train: 0.8916 acc_val: 0.9600\n",
      "Epoch: 0719 loss_train: 0.2005 acc_train: 0.8782 acc_val: 0.9600\n",
      "Epoch: 0720 loss_train: 0.1960 acc_train: 0.8879 acc_val: 0.9600\n",
      "Epoch: 0721 loss_train: 0.1780 acc_train: 0.9050 acc_val: 0.9600\n",
      "Epoch: 0722 loss_train: 0.1812 acc_train: 0.8946 acc_val: 0.9600\n",
      "Epoch: 0723 loss_train: 0.1894 acc_train: 0.8820 acc_val: 0.9600\n",
      "Epoch: 0724 loss_train: 0.1712 acc_train: 0.9020 acc_val: 0.9600\n",
      "Epoch: 0725 loss_train: 0.1811 acc_train: 0.8842 acc_val: 0.9600\n",
      "Epoch: 0726 loss_train: 0.1821 acc_train: 0.8961 acc_val: 0.9600\n",
      "Epoch: 0727 loss_train: 0.2153 acc_train: 0.8760 acc_val: 0.9600\n",
      "Epoch: 0728 loss_train: 0.1840 acc_train: 0.8961 acc_val: 0.9600\n",
      "Epoch: 0729 loss_train: 0.1897 acc_train: 0.8879 acc_val: 0.9600\n",
      "Epoch: 0730 loss_train: 0.1805 acc_train: 0.8953 acc_val: 0.9600\n",
      "Epoch: 0731 loss_train: 0.1806 acc_train: 0.8894 acc_val: 0.9600\n",
      "Epoch: 0732 loss_train: 0.1800 acc_train: 0.9027 acc_val: 0.9600\n",
      "Epoch: 0733 loss_train: 0.1987 acc_train: 0.8849 acc_val: 0.9600\n",
      "Epoch: 0734 loss_train: 0.1794 acc_train: 0.8931 acc_val: 0.9600\n",
      "Epoch: 0735 loss_train: 0.1882 acc_train: 0.8857 acc_val: 0.9600\n",
      "Epoch: 0736 loss_train: 0.1923 acc_train: 0.8864 acc_val: 0.9600\n",
      "Epoch: 0737 loss_train: 0.1930 acc_train: 0.8797 acc_val: 0.9600\n",
      "Epoch: 0738 loss_train: 0.1778 acc_train: 0.8909 acc_val: 0.9600\n",
      "Epoch: 0739 loss_train: 0.1943 acc_train: 0.8864 acc_val: 0.9600\n",
      "Epoch: 0740 loss_train: 0.1671 acc_train: 0.8968 acc_val: 0.9600\n",
      "Epoch: 0741 loss_train: 0.1860 acc_train: 0.9035 acc_val: 0.9600\n",
      "Epoch: 0742 loss_train: 0.1867 acc_train: 0.8857 acc_val: 0.9600\n",
      "Epoch: 0743 loss_train: 0.1702 acc_train: 0.9124 acc_val: 0.9600\n",
      "Epoch: 0744 loss_train: 0.1784 acc_train: 0.8886 acc_val: 0.9600\n",
      "Epoch: 0745 loss_train: 0.1846 acc_train: 0.8879 acc_val: 0.9600\n",
      "Epoch: 0746 loss_train: 0.1848 acc_train: 0.8849 acc_val: 0.9600\n",
      "Epoch: 0747 loss_train: 0.1804 acc_train: 0.8901 acc_val: 0.9600\n",
      "Epoch: 0748 loss_train: 0.1905 acc_train: 0.8886 acc_val: 0.9600\n",
      "Epoch: 0749 loss_train: 0.2016 acc_train: 0.8812 acc_val: 0.9600\n",
      "Epoch: 0750 loss_train: 0.1982 acc_train: 0.8768 acc_val: 0.9600\n",
      "Epoch: 0751 loss_train: 0.1927 acc_train: 0.8849 acc_val: 0.9600\n",
      "Epoch: 0752 loss_train: 0.1814 acc_train: 0.9005 acc_val: 0.9600\n",
      "Epoch: 0753 loss_train: 0.1670 acc_train: 0.9027 acc_val: 0.9600\n",
      "Epoch: 0754 loss_train: 0.1908 acc_train: 0.8931 acc_val: 0.9600\n",
      "Epoch: 0755 loss_train: 0.1893 acc_train: 0.8857 acc_val: 0.9600\n",
      "Epoch: 0756 loss_train: 0.1838 acc_train: 0.8953 acc_val: 0.9600\n",
      "Epoch: 0757 loss_train: 0.1959 acc_train: 0.8842 acc_val: 0.9600\n",
      "Epoch: 0758 loss_train: 0.1860 acc_train: 0.8916 acc_val: 0.9600\n",
      "Epoch: 0759 loss_train: 0.1806 acc_train: 0.8894 acc_val: 0.9600\n",
      "Epoch: 0760 loss_train: 0.1871 acc_train: 0.8872 acc_val: 0.9600\n",
      "Epoch: 0761 loss_train: 0.1974 acc_train: 0.8857 acc_val: 0.9600\n",
      "Epoch: 0762 loss_train: 0.1670 acc_train: 0.8961 acc_val: 0.9600\n",
      "Epoch: 0763 loss_train: 0.1787 acc_train: 0.8894 acc_val: 0.9600\n",
      "Epoch: 0764 loss_train: 0.1873 acc_train: 0.8946 acc_val: 0.9600\n",
      "Epoch: 0765 loss_train: 0.1954 acc_train: 0.8916 acc_val: 0.9600\n",
      "Epoch: 0766 loss_train: 0.1855 acc_train: 0.8961 acc_val: 0.9600\n",
      "Epoch: 0767 loss_train: 0.1858 acc_train: 0.8953 acc_val: 0.9600\n",
      "Epoch: 0768 loss_train: 0.1726 acc_train: 0.9057 acc_val: 0.9600\n",
      "Epoch: 0769 loss_train: 0.1921 acc_train: 0.8924 acc_val: 0.9600\n",
      "Epoch: 0770 loss_train: 0.1802 acc_train: 0.8894 acc_val: 0.9600\n",
      "Epoch: 0771 loss_train: 0.1813 acc_train: 0.8946 acc_val: 0.9600\n",
      "Epoch: 0772 loss_train: 0.1830 acc_train: 0.8953 acc_val: 0.9600\n",
      "Epoch: 0773 loss_train: 0.1799 acc_train: 0.8901 acc_val: 0.9600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0774 loss_train: 0.1943 acc_train: 0.8834 acc_val: 0.9600\n",
      "Epoch: 0775 loss_train: 0.1762 acc_train: 0.8886 acc_val: 0.9600\n",
      "Epoch: 0776 loss_train: 0.1782 acc_train: 0.8961 acc_val: 0.9600\n",
      "Epoch: 0777 loss_train: 0.1996 acc_train: 0.8842 acc_val: 0.9600\n",
      "Epoch: 0778 loss_train: 0.1969 acc_train: 0.8812 acc_val: 0.9600\n",
      "Epoch: 0779 loss_train: 0.1750 acc_train: 0.8998 acc_val: 0.9600\n",
      "Epoch: 0780 loss_train: 0.1802 acc_train: 0.8849 acc_val: 0.9600\n",
      "Epoch: 0781 loss_train: 0.1806 acc_train: 0.8938 acc_val: 0.9600\n",
      "Epoch: 0782 loss_train: 0.1762 acc_train: 0.8990 acc_val: 0.9600\n",
      "Epoch: 0783 loss_train: 0.1962 acc_train: 0.8834 acc_val: 0.9600\n",
      "Epoch: 0784 loss_train: 0.1765 acc_train: 0.8938 acc_val: 0.9600\n",
      "Epoch: 0785 loss_train: 0.1881 acc_train: 0.9050 acc_val: 0.9600\n",
      "Epoch: 0786 loss_train: 0.1708 acc_train: 0.9027 acc_val: 0.9600\n",
      "Epoch: 0787 loss_train: 0.1934 acc_train: 0.8924 acc_val: 0.9600\n",
      "Epoch: 0788 loss_train: 0.1947 acc_train: 0.8864 acc_val: 0.9600\n",
      "Epoch: 0789 loss_train: 0.1725 acc_train: 0.8961 acc_val: 0.9600\n",
      "Epoch: 0790 loss_train: 0.1951 acc_train: 0.8886 acc_val: 0.9600\n",
      "Epoch: 0791 loss_train: 0.1791 acc_train: 0.9013 acc_val: 0.9600\n",
      "Epoch: 0792 loss_train: 0.1867 acc_train: 0.8842 acc_val: 0.9600\n",
      "Epoch: 0793 loss_train: 0.1824 acc_train: 0.8968 acc_val: 0.9600\n",
      "Epoch: 0794 loss_train: 0.2026 acc_train: 0.8731 acc_val: 0.9600\n",
      "Epoch: 0795 loss_train: 0.1975 acc_train: 0.8812 acc_val: 0.9600\n",
      "Epoch: 0796 loss_train: 0.1826 acc_train: 0.8968 acc_val: 0.9600\n",
      "Epoch: 0797 loss_train: 0.2044 acc_train: 0.8738 acc_val: 0.9600\n",
      "Epoch: 0798 loss_train: 0.1736 acc_train: 0.8946 acc_val: 0.9600\n",
      "Epoch: 0799 loss_train: 0.1991 acc_train: 0.8812 acc_val: 0.9600\n",
      "Epoch: 0800 loss_train: 0.1882 acc_train: 0.8894 acc_val: 0.9600\n",
      "Epoch: 0801 loss_train: 0.1904 acc_train: 0.8886 acc_val: 0.9600\n",
      "Epoch: 0802 loss_train: 0.1974 acc_train: 0.8924 acc_val: 0.9600\n",
      "Epoch: 0803 loss_train: 0.1922 acc_train: 0.8834 acc_val: 0.9600\n",
      "Epoch: 0804 loss_train: 0.1897 acc_train: 0.8857 acc_val: 0.9600\n",
      "Epoch: 0805 loss_train: 0.1964 acc_train: 0.8849 acc_val: 0.9600\n",
      "Epoch: 0806 loss_train: 0.1727 acc_train: 0.8931 acc_val: 0.9600\n",
      "Epoch: 0807 loss_train: 0.2026 acc_train: 0.8834 acc_val: 0.9600\n",
      "Epoch: 0808 loss_train: 0.1887 acc_train: 0.8924 acc_val: 0.9600\n",
      "Epoch: 0809 loss_train: 0.2065 acc_train: 0.8753 acc_val: 0.9600\n",
      "Epoch: 0810 loss_train: 0.1779 acc_train: 0.8976 acc_val: 0.9600\n",
      "Epoch: 0811 loss_train: 0.1868 acc_train: 0.8961 acc_val: 0.9600\n",
      "Epoch: 0812 loss_train: 0.2006 acc_train: 0.8834 acc_val: 0.9600\n",
      "Epoch: 0813 loss_train: 0.1841 acc_train: 0.8872 acc_val: 0.9600\n",
      "Epoch: 0814 loss_train: 0.1837 acc_train: 0.8901 acc_val: 0.9600\n",
      "Epoch: 0815 loss_train: 0.2147 acc_train: 0.8671 acc_val: 0.9600\n",
      "Epoch: 0816 loss_train: 0.1859 acc_train: 0.8894 acc_val: 0.9600\n",
      "Epoch: 0817 loss_train: 0.1697 acc_train: 0.8946 acc_val: 0.9600\n",
      "Epoch: 0818 loss_train: 0.1836 acc_train: 0.8924 acc_val: 0.9600\n",
      "Epoch: 0819 loss_train: 0.1845 acc_train: 0.8909 acc_val: 0.9600\n",
      "Epoch: 0820 loss_train: 0.1918 acc_train: 0.8864 acc_val: 0.9600\n",
      "Epoch: 0821 loss_train: 0.1848 acc_train: 0.8968 acc_val: 0.9600\n",
      "Epoch: 0822 loss_train: 0.1849 acc_train: 0.8879 acc_val: 0.9600\n",
      "Epoch: 0823 loss_train: 0.1725 acc_train: 0.8938 acc_val: 0.9600\n",
      "Epoch: 0824 loss_train: 0.2034 acc_train: 0.8797 acc_val: 0.9600\n",
      "Epoch: 0825 loss_train: 0.1794 acc_train: 0.8990 acc_val: 0.9600\n",
      "Epoch: 0826 loss_train: 0.2007 acc_train: 0.8768 acc_val: 0.9600\n",
      "Epoch: 0827 loss_train: 0.1658 acc_train: 0.8938 acc_val: 0.9600\n",
      "Epoch: 0828 loss_train: 0.1759 acc_train: 0.8998 acc_val: 0.9600\n",
      "Epoch: 0829 loss_train: 0.2084 acc_train: 0.8812 acc_val: 0.9600\n",
      "Epoch: 0830 loss_train: 0.1905 acc_train: 0.8938 acc_val: 0.9600\n",
      "Epoch: 0831 loss_train: 0.1954 acc_train: 0.8820 acc_val: 0.9600\n",
      "Epoch: 0832 loss_train: 0.2012 acc_train: 0.8909 acc_val: 0.9600\n",
      "Epoch: 0833 loss_train: 0.1760 acc_train: 0.8924 acc_val: 0.9600\n",
      "Epoch: 0834 loss_train: 0.1797 acc_train: 0.8886 acc_val: 0.9600\n",
      "Epoch: 0835 loss_train: 0.1814 acc_train: 0.8834 acc_val: 0.9600\n",
      "Epoch: 0836 loss_train: 0.1695 acc_train: 0.8946 acc_val: 0.9600\n",
      "Epoch: 0837 loss_train: 0.1930 acc_train: 0.8872 acc_val: 0.9600\n",
      "Epoch: 0838 loss_train: 0.1795 acc_train: 0.8953 acc_val: 0.9600\n",
      "Epoch: 0839 loss_train: 0.1878 acc_train: 0.8879 acc_val: 0.9600\n",
      "Epoch: 0840 loss_train: 0.1950 acc_train: 0.8805 acc_val: 0.9600\n",
      "Epoch: 0841 loss_train: 0.1980 acc_train: 0.8938 acc_val: 0.9600\n",
      "Epoch: 0842 loss_train: 0.1689 acc_train: 0.9005 acc_val: 0.9600\n",
      "Epoch: 0843 loss_train: 0.1902 acc_train: 0.8901 acc_val: 0.9600\n",
      "Epoch: 0844 loss_train: 0.1855 acc_train: 0.8968 acc_val: 0.9600\n",
      "Epoch: 0845 loss_train: 0.1795 acc_train: 0.8938 acc_val: 0.9600\n",
      "Epoch: 0846 loss_train: 0.1872 acc_train: 0.8886 acc_val: 0.9600\n",
      "Epoch: 0847 loss_train: 0.1726 acc_train: 0.9050 acc_val: 0.9600\n",
      "Epoch: 0848 loss_train: 0.1732 acc_train: 0.9102 acc_val: 0.9600\n",
      "Epoch: 0849 loss_train: 0.1893 acc_train: 0.8901 acc_val: 0.9600\n",
      "Epoch: 0850 loss_train: 0.1902 acc_train: 0.8901 acc_val: 0.9600\n",
      "Epoch: 0851 loss_train: 0.1742 acc_train: 0.8990 acc_val: 0.9600\n",
      "Epoch: 0852 loss_train: 0.1906 acc_train: 0.8775 acc_val: 0.9600\n",
      "Epoch: 0853 loss_train: 0.1915 acc_train: 0.8909 acc_val: 0.9600\n",
      "Epoch: 0854 loss_train: 0.2035 acc_train: 0.8857 acc_val: 0.9600\n",
      "Epoch: 0855 loss_train: 0.1929 acc_train: 0.8827 acc_val: 0.9600\n",
      "Epoch: 0856 loss_train: 0.1911 acc_train: 0.8879 acc_val: 0.9600\n",
      "Epoch: 0857 loss_train: 0.1900 acc_train: 0.8894 acc_val: 0.9600\n",
      "Epoch: 0858 loss_train: 0.1963 acc_train: 0.8745 acc_val: 0.9600\n",
      "Epoch: 0859 loss_train: 0.1853 acc_train: 0.8976 acc_val: 0.9600\n",
      "Epoch: 0860 loss_train: 0.1991 acc_train: 0.8827 acc_val: 0.9600\n",
      "Epoch: 0861 loss_train: 0.1628 acc_train: 0.9065 acc_val: 0.9600\n",
      "Epoch: 0862 loss_train: 0.1785 acc_train: 0.8931 acc_val: 0.9600\n",
      "Epoch: 0863 loss_train: 0.1861 acc_train: 0.8849 acc_val: 0.9600\n",
      "Epoch: 0864 loss_train: 0.1789 acc_train: 0.8879 acc_val: 0.9600\n",
      "Epoch: 0865 loss_train: 0.1811 acc_train: 0.8849 acc_val: 0.9600\n",
      "Epoch: 0866 loss_train: 0.1919 acc_train: 0.8842 acc_val: 0.9600\n",
      "Epoch: 0867 loss_train: 0.1771 acc_train: 0.8857 acc_val: 0.9600\n",
      "Epoch: 0868 loss_train: 0.1720 acc_train: 0.8983 acc_val: 0.9600\n",
      "Epoch: 0869 loss_train: 0.1863 acc_train: 0.8976 acc_val: 0.9600\n",
      "Epoch: 0870 loss_train: 0.1949 acc_train: 0.8820 acc_val: 0.9600\n",
      "Epoch: 0871 loss_train: 0.1872 acc_train: 0.8842 acc_val: 0.9600\n",
      "Epoch: 0872 loss_train: 0.1768 acc_train: 0.8983 acc_val: 0.9600\n",
      "Epoch: 0873 loss_train: 0.1749 acc_train: 0.8961 acc_val: 0.9600\n",
      "Epoch: 0874 loss_train: 0.2025 acc_train: 0.8842 acc_val: 0.9600\n",
      "Epoch: 0875 loss_train: 0.1867 acc_train: 0.8901 acc_val: 0.9600\n",
      "Epoch: 0876 loss_train: 0.1686 acc_train: 0.9013 acc_val: 0.9600\n",
      "Epoch: 0877 loss_train: 0.1901 acc_train: 0.8968 acc_val: 0.9600\n",
      "Epoch: 0878 loss_train: 0.1682 acc_train: 0.9065 acc_val: 0.9600\n",
      "Epoch: 0879 loss_train: 0.1908 acc_train: 0.8953 acc_val: 0.9600\n",
      "Epoch: 0880 loss_train: 0.1844 acc_train: 0.9005 acc_val: 0.9600\n",
      "Epoch: 0881 loss_train: 0.1843 acc_train: 0.8924 acc_val: 0.9600\n",
      "Epoch: 0882 loss_train: 0.1709 acc_train: 0.9005 acc_val: 0.9600\n",
      "Epoch: 0883 loss_train: 0.1718 acc_train: 0.9035 acc_val: 0.9600\n",
      "Epoch: 0884 loss_train: 0.1757 acc_train: 0.8961 acc_val: 0.9600\n",
      "Epoch: 0885 loss_train: 0.2027 acc_train: 0.8827 acc_val: 0.9600\n",
      "Epoch: 0886 loss_train: 0.2156 acc_train: 0.8634 acc_val: 0.9600\n",
      "Epoch: 0887 loss_train: 0.1990 acc_train: 0.8812 acc_val: 0.9600\n",
      "Epoch: 0888 loss_train: 0.1855 acc_train: 0.8842 acc_val: 0.9600\n",
      "Epoch: 0889 loss_train: 0.1987 acc_train: 0.8782 acc_val: 0.9600\n",
      "Epoch: 0890 loss_train: 0.1902 acc_train: 0.8872 acc_val: 0.9600\n",
      "Epoch: 0891 loss_train: 0.1752 acc_train: 0.8953 acc_val: 0.9600\n",
      "Epoch: 0892 loss_train: 0.1687 acc_train: 0.8998 acc_val: 0.9600\n",
      "Epoch: 0893 loss_train: 0.1976 acc_train: 0.8842 acc_val: 0.9600\n",
      "Epoch: 0894 loss_train: 0.1973 acc_train: 0.8834 acc_val: 0.9600\n",
      "Epoch: 0895 loss_train: 0.2056 acc_train: 0.8723 acc_val: 0.9600\n",
      "Epoch: 0896 loss_train: 0.1731 acc_train: 0.8946 acc_val: 0.9600\n",
      "Epoch: 0897 loss_train: 0.1790 acc_train: 0.8961 acc_val: 0.9600\n",
      "Epoch: 0898 loss_train: 0.1896 acc_train: 0.8894 acc_val: 0.9600\n",
      "Epoch: 0899 loss_train: 0.1879 acc_train: 0.8938 acc_val: 0.9600\n",
      "Epoch: 0900 loss_train: 0.1929 acc_train: 0.8931 acc_val: 0.9600\n",
      "Epoch: 0901 loss_train: 0.1963 acc_train: 0.8901 acc_val: 0.9600\n",
      "Epoch: 0902 loss_train: 0.1737 acc_train: 0.9027 acc_val: 0.9600\n",
      "Epoch: 0903 loss_train: 0.1786 acc_train: 0.8961 acc_val: 0.9600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0904 loss_train: 0.1697 acc_train: 0.9020 acc_val: 0.9600\n",
      "Epoch: 0905 loss_train: 0.1753 acc_train: 0.8990 acc_val: 0.9600\n",
      "Epoch: 0906 loss_train: 0.1840 acc_train: 0.9005 acc_val: 0.9600\n",
      "Epoch: 0907 loss_train: 0.1943 acc_train: 0.8886 acc_val: 0.9600\n",
      "Epoch: 0908 loss_train: 0.1760 acc_train: 0.8983 acc_val: 0.9600\n",
      "Epoch: 0909 loss_train: 0.1836 acc_train: 0.8916 acc_val: 0.9600\n",
      "Epoch: 0910 loss_train: 0.1827 acc_train: 0.8938 acc_val: 0.9600\n",
      "Epoch: 0911 loss_train: 0.1704 acc_train: 0.8990 acc_val: 0.9600\n",
      "Epoch: 0912 loss_train: 0.1853 acc_train: 0.8953 acc_val: 0.9600\n",
      "Epoch: 0913 loss_train: 0.1773 acc_train: 0.8924 acc_val: 0.9600\n",
      "Epoch: 0914 loss_train: 0.1876 acc_train: 0.8901 acc_val: 0.9600\n",
      "Epoch: 0915 loss_train: 0.1846 acc_train: 0.8931 acc_val: 0.9600\n",
      "Epoch: 0916 loss_train: 0.2086 acc_train: 0.8790 acc_val: 0.9600\n",
      "Epoch: 0917 loss_train: 0.1853 acc_train: 0.8946 acc_val: 0.9600\n",
      "Epoch: 0918 loss_train: 0.1845 acc_train: 0.8931 acc_val: 0.9600\n",
      "Epoch: 0919 loss_train: 0.1818 acc_train: 0.8879 acc_val: 0.9600\n",
      "Epoch: 0920 loss_train: 0.1898 acc_train: 0.8849 acc_val: 0.9600\n",
      "Epoch: 0921 loss_train: 0.1862 acc_train: 0.8961 acc_val: 0.9600\n",
      "Epoch: 0922 loss_train: 0.1769 acc_train: 0.8968 acc_val: 0.9600\n",
      "Epoch: 0923 loss_train: 0.1972 acc_train: 0.8886 acc_val: 0.9600\n",
      "Epoch: 0924 loss_train: 0.1802 acc_train: 0.8924 acc_val: 0.9600\n",
      "Epoch: 0925 loss_train: 0.1990 acc_train: 0.8894 acc_val: 0.9600\n",
      "Epoch: 0926 loss_train: 0.1736 acc_train: 0.8894 acc_val: 0.9600\n",
      "Epoch: 0927 loss_train: 0.2038 acc_train: 0.8812 acc_val: 0.9600\n",
      "Epoch: 0928 loss_train: 0.1844 acc_train: 0.8901 acc_val: 0.9600\n",
      "Epoch: 0929 loss_train: 0.1889 acc_train: 0.8849 acc_val: 0.9600\n",
      "Epoch: 0930 loss_train: 0.1666 acc_train: 0.8990 acc_val: 0.9600\n",
      "Epoch: 0931 loss_train: 0.1758 acc_train: 0.8968 acc_val: 0.9600\n",
      "Epoch: 0932 loss_train: 0.1878 acc_train: 0.8834 acc_val: 0.9600\n",
      "Epoch: 0933 loss_train: 0.1737 acc_train: 0.9087 acc_val: 0.9600\n",
      "Epoch: 0934 loss_train: 0.2056 acc_train: 0.8782 acc_val: 0.9600\n",
      "Epoch: 0935 loss_train: 0.1781 acc_train: 0.8857 acc_val: 0.9600\n",
      "Epoch: 0936 loss_train: 0.1873 acc_train: 0.8938 acc_val: 0.9600\n",
      "Epoch: 0937 loss_train: 0.1798 acc_train: 0.8976 acc_val: 0.9600\n",
      "Epoch: 0938 loss_train: 0.1865 acc_train: 0.8849 acc_val: 0.9600\n",
      "Epoch: 0939 loss_train: 0.1932 acc_train: 0.8909 acc_val: 0.9600\n",
      "Epoch: 0940 loss_train: 0.1871 acc_train: 0.8864 acc_val: 0.9600\n",
      "Epoch: 0941 loss_train: 0.1980 acc_train: 0.8857 acc_val: 0.9600\n",
      "Epoch: 0942 loss_train: 0.1960 acc_train: 0.8812 acc_val: 0.9600\n",
      "Epoch: 0943 loss_train: 0.1805 acc_train: 0.9027 acc_val: 0.9600\n",
      "Epoch: 0944 loss_train: 0.1896 acc_train: 0.8931 acc_val: 0.9600\n",
      "Epoch: 0945 loss_train: 0.1914 acc_train: 0.8834 acc_val: 0.9600\n",
      "Epoch: 0946 loss_train: 0.1891 acc_train: 0.8775 acc_val: 0.9600\n",
      "Epoch: 0947 loss_train: 0.2051 acc_train: 0.8797 acc_val: 0.9600\n",
      "Epoch: 0948 loss_train: 0.2037 acc_train: 0.8879 acc_val: 0.9600\n",
      "Epoch: 0949 loss_train: 0.2045 acc_train: 0.8886 acc_val: 0.9600\n",
      "Epoch: 0950 loss_train: 0.1990 acc_train: 0.8805 acc_val: 0.9600\n",
      "Epoch: 0951 loss_train: 0.1787 acc_train: 0.8998 acc_val: 0.9600\n",
      "Epoch: 0952 loss_train: 0.1947 acc_train: 0.8872 acc_val: 0.9600\n",
      "Epoch: 0953 loss_train: 0.1827 acc_train: 0.8864 acc_val: 0.9600\n",
      "Epoch: 0954 loss_train: 0.1883 acc_train: 0.8909 acc_val: 0.9600\n",
      "Epoch: 0955 loss_train: 0.2003 acc_train: 0.8834 acc_val: 0.9600\n",
      "Epoch: 0956 loss_train: 0.1734 acc_train: 0.8990 acc_val: 0.9600\n",
      "Epoch: 0957 loss_train: 0.1936 acc_train: 0.8849 acc_val: 0.9600\n",
      "Epoch: 0958 loss_train: 0.1894 acc_train: 0.8790 acc_val: 0.9600\n",
      "Epoch: 0959 loss_train: 0.1898 acc_train: 0.8879 acc_val: 0.9600\n",
      "Epoch: 0960 loss_train: 0.1812 acc_train: 0.8946 acc_val: 0.9600\n",
      "Epoch: 0961 loss_train: 0.1834 acc_train: 0.8931 acc_val: 0.9600\n",
      "Epoch: 0962 loss_train: 0.1724 acc_train: 0.8983 acc_val: 0.9600\n",
      "Epoch: 0963 loss_train: 0.1806 acc_train: 0.8931 acc_val: 0.9600\n",
      "Epoch: 0964 loss_train: 0.1857 acc_train: 0.8901 acc_val: 0.9600\n",
      "Epoch: 0965 loss_train: 0.1777 acc_train: 0.8976 acc_val: 0.9600\n",
      "Epoch: 0966 loss_train: 0.1789 acc_train: 0.8968 acc_val: 0.9600\n",
      "Epoch: 0967 loss_train: 0.1619 acc_train: 0.8968 acc_val: 0.9600\n",
      "Epoch: 0968 loss_train: 0.1717 acc_train: 0.8983 acc_val: 0.9600\n",
      "Epoch: 0969 loss_train: 0.1682 acc_train: 0.9005 acc_val: 0.9600\n",
      "Epoch: 0970 loss_train: 0.1872 acc_train: 0.9005 acc_val: 0.9600\n",
      "Epoch: 0971 loss_train: 0.1864 acc_train: 0.8938 acc_val: 0.9600\n",
      "Epoch: 0972 loss_train: 0.1942 acc_train: 0.8938 acc_val: 0.9600\n",
      "Epoch: 0973 loss_train: 0.1874 acc_train: 0.8924 acc_val: 0.9600\n",
      "Epoch: 0974 loss_train: 0.2115 acc_train: 0.8738 acc_val: 0.9600\n",
      "Epoch: 0975 loss_train: 0.1848 acc_train: 0.8924 acc_val: 0.9600\n",
      "Epoch: 0976 loss_train: 0.1752 acc_train: 0.9013 acc_val: 0.9600\n",
      "Epoch: 0977 loss_train: 0.2068 acc_train: 0.8738 acc_val: 0.9600\n",
      "Epoch: 0978 loss_train: 0.2122 acc_train: 0.8738 acc_val: 0.9600\n",
      "Epoch: 0979 loss_train: 0.2039 acc_train: 0.8842 acc_val: 0.9600\n",
      "Epoch: 0980 loss_train: 0.1817 acc_train: 0.8946 acc_val: 0.9600\n",
      "Epoch: 0981 loss_train: 0.1753 acc_train: 0.8953 acc_val: 0.9600\n",
      "Epoch: 0982 loss_train: 0.1806 acc_train: 0.8857 acc_val: 0.9600\n",
      "Epoch: 0983 loss_train: 0.1877 acc_train: 0.8872 acc_val: 0.9600\n",
      "Epoch: 0984 loss_train: 0.2007 acc_train: 0.8894 acc_val: 0.9600\n",
      "Epoch: 0985 loss_train: 0.1786 acc_train: 0.8961 acc_val: 0.9600\n",
      "Epoch: 0986 loss_train: 0.1953 acc_train: 0.8849 acc_val: 0.9600\n",
      "Epoch: 0987 loss_train: 0.1831 acc_train: 0.8931 acc_val: 0.9600\n",
      "Epoch: 0988 loss_train: 0.1897 acc_train: 0.8864 acc_val: 0.9600\n",
      "Epoch: 0989 loss_train: 0.1768 acc_train: 0.8946 acc_val: 0.9600\n",
      "Epoch: 0990 loss_train: 0.1748 acc_train: 0.9027 acc_val: 0.9600\n",
      "Epoch: 0991 loss_train: 0.1701 acc_train: 0.8976 acc_val: 0.9600\n",
      "Epoch: 0992 loss_train: 0.1942 acc_train: 0.8805 acc_val: 0.9600\n",
      "Epoch: 0993 loss_train: 0.2106 acc_train: 0.8760 acc_val: 0.9600\n",
      "Epoch: 0994 loss_train: 0.1952 acc_train: 0.8968 acc_val: 0.9600\n",
      "Epoch: 0995 loss_train: 0.1781 acc_train: 0.8976 acc_val: 0.9600\n",
      "Epoch: 0996 loss_train: 0.1774 acc_train: 0.8924 acc_val: 0.9600\n",
      "Epoch: 0997 loss_train: 0.1724 acc_train: 0.8976 acc_val: 0.9600\n",
      "Epoch: 0998 loss_train: 0.2040 acc_train: 0.8805 acc_val: 0.9600\n",
      "Epoch: 0999 loss_train: 0.1974 acc_train: 0.8782 acc_val: 0.9600\n",
      "Epoch: 1000 loss_train: 0.1964 acc_train: 0.8849 acc_val: 0.9600\n",
      "Epoch: 1001 loss_train: 0.1906 acc_train: 0.8916 acc_val: 0.9600\n",
      "Epoch: 1002 loss_train: 0.2002 acc_train: 0.8797 acc_val: 0.9600\n",
      "Epoch: 1003 loss_train: 0.1842 acc_train: 0.8946 acc_val: 0.9600\n",
      "Epoch: 1004 loss_train: 0.1712 acc_train: 0.8983 acc_val: 0.9600\n",
      "Epoch: 1005 loss_train: 0.1666 acc_train: 0.8961 acc_val: 0.9600\n",
      "Epoch: 1006 loss_train: 0.1791 acc_train: 0.8901 acc_val: 0.9600\n",
      "Epoch: 1007 loss_train: 0.1872 acc_train: 0.8782 acc_val: 0.9600\n",
      "Epoch: 1008 loss_train: 0.1819 acc_train: 0.8901 acc_val: 0.9600\n",
      "Epoch: 1009 loss_train: 0.1609 acc_train: 0.9131 acc_val: 0.9600\n",
      "Epoch: 1010 loss_train: 0.1927 acc_train: 0.8864 acc_val: 0.9600\n",
      "Epoch: 1011 loss_train: 0.1985 acc_train: 0.8782 acc_val: 0.9600\n",
      "Epoch: 1012 loss_train: 0.1778 acc_train: 0.8872 acc_val: 0.9600\n",
      "Epoch: 1013 loss_train: 0.1870 acc_train: 0.8872 acc_val: 0.9600\n",
      "Epoch: 1014 loss_train: 0.1967 acc_train: 0.8916 acc_val: 0.9600\n",
      "Epoch: 1015 loss_train: 0.1964 acc_train: 0.8790 acc_val: 0.9600\n",
      "Epoch: 1016 loss_train: 0.1872 acc_train: 0.8886 acc_val: 0.9600\n",
      "Epoch: 1017 loss_train: 0.1962 acc_train: 0.8797 acc_val: 0.9600\n",
      "Epoch: 1018 loss_train: 0.1869 acc_train: 0.8909 acc_val: 0.9600\n",
      "Epoch: 1019 loss_train: 0.1834 acc_train: 0.8909 acc_val: 0.9600\n",
      "Epoch: 1020 loss_train: 0.1638 acc_train: 0.8983 acc_val: 0.9600\n",
      "Epoch: 1021 loss_train: 0.1659 acc_train: 0.9013 acc_val: 0.9600\n",
      "Epoch: 1022 loss_train: 0.1665 acc_train: 0.8968 acc_val: 0.9600\n",
      "Epoch: 1023 loss_train: 0.1690 acc_train: 0.9027 acc_val: 0.9600\n",
      "Epoch: 1024 loss_train: 0.1846 acc_train: 0.8872 acc_val: 0.9600\n",
      "Epoch: 1025 loss_train: 0.1913 acc_train: 0.8857 acc_val: 0.9600\n",
      "Epoch: 1026 loss_train: 0.1771 acc_train: 0.8938 acc_val: 0.9600\n",
      "Epoch: 1027 loss_train: 0.1956 acc_train: 0.8775 acc_val: 0.9600\n",
      "Epoch: 1028 loss_train: 0.1860 acc_train: 0.8894 acc_val: 0.9600\n",
      "Epoch: 1029 loss_train: 0.1803 acc_train: 0.8924 acc_val: 0.9600\n",
      "Epoch: 1030 loss_train: 0.2073 acc_train: 0.8664 acc_val: 0.9600\n",
      "Epoch: 1031 loss_train: 0.1834 acc_train: 0.8872 acc_val: 0.9600\n",
      "Epoch: 1032 loss_train: 0.1917 acc_train: 0.8782 acc_val: 0.9600\n",
      "Epoch: 1033 loss_train: 0.1963 acc_train: 0.8886 acc_val: 0.9600\n",
      "Epoch: 1034 loss_train: 0.1874 acc_train: 0.8968 acc_val: 0.9600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1035 loss_train: 0.1864 acc_train: 0.8790 acc_val: 0.9600\n",
      "Epoch: 1036 loss_train: 0.1791 acc_train: 0.8909 acc_val: 0.9600\n",
      "Epoch: 1037 loss_train: 0.1887 acc_train: 0.8842 acc_val: 0.9600\n",
      "Epoch: 1038 loss_train: 0.1779 acc_train: 0.8857 acc_val: 0.9600\n",
      "Epoch: 1039 loss_train: 0.1956 acc_train: 0.8872 acc_val: 0.9600\n",
      "Epoch: 1040 loss_train: 0.1799 acc_train: 0.8909 acc_val: 0.9600\n",
      "Epoch: 1041 loss_train: 0.1883 acc_train: 0.8894 acc_val: 0.9600\n",
      "Epoch: 1042 loss_train: 0.1899 acc_train: 0.8894 acc_val: 0.9600\n",
      "Epoch: 1043 loss_train: 0.1760 acc_train: 0.8924 acc_val: 0.9600\n",
      "Epoch: 1044 loss_train: 0.1846 acc_train: 0.8931 acc_val: 0.9600\n",
      "Epoch: 1045 loss_train: 0.1863 acc_train: 0.8872 acc_val: 0.9600\n",
      "Epoch: 1046 loss_train: 0.1820 acc_train: 0.8968 acc_val: 0.9600\n",
      "Epoch: 1047 loss_train: 0.1793 acc_train: 0.8909 acc_val: 0.9600\n",
      "Epoch: 1048 loss_train: 0.2002 acc_train: 0.8782 acc_val: 0.9600\n",
      "Epoch: 1049 loss_train: 0.1860 acc_train: 0.8886 acc_val: 0.9600\n",
      "Epoch: 1050 loss_train: 0.1932 acc_train: 0.8760 acc_val: 0.9600\n",
      "Epoch: 1051 loss_train: 0.1668 acc_train: 0.8931 acc_val: 0.9578\n",
      "Epoch: 1052 loss_train: 0.1834 acc_train: 0.8976 acc_val: 0.9578\n",
      "Epoch: 1053 loss_train: 0.1768 acc_train: 0.9050 acc_val: 0.9578\n",
      "Epoch: 1054 loss_train: 0.1942 acc_train: 0.8894 acc_val: 0.9578\n",
      "Epoch: 1055 loss_train: 0.1695 acc_train: 0.9139 acc_val: 0.9578\n",
      "Epoch: 1056 loss_train: 0.1618 acc_train: 0.8998 acc_val: 0.9578\n",
      "Epoch: 1057 loss_train: 0.1913 acc_train: 0.8857 acc_val: 0.9578\n",
      "Epoch: 1058 loss_train: 0.1806 acc_train: 0.8953 acc_val: 0.9578\n",
      "Epoch: 1059 loss_train: 0.1878 acc_train: 0.8775 acc_val: 0.9578\n",
      "Epoch: 1060 loss_train: 0.1773 acc_train: 0.8901 acc_val: 0.9578\n",
      "Epoch: 1061 loss_train: 0.1997 acc_train: 0.8790 acc_val: 0.9578\n",
      "Epoch: 1062 loss_train: 0.1626 acc_train: 0.9124 acc_val: 0.9578\n",
      "Epoch: 1063 loss_train: 0.1845 acc_train: 0.8916 acc_val: 0.9578\n",
      "Epoch: 1064 loss_train: 0.1825 acc_train: 0.8983 acc_val: 0.9578\n",
      "Epoch: 1065 loss_train: 0.1928 acc_train: 0.8961 acc_val: 0.9578\n",
      "Epoch: 1066 loss_train: 0.1956 acc_train: 0.8849 acc_val: 0.9578\n",
      "Epoch: 1067 loss_train: 0.1946 acc_train: 0.8820 acc_val: 0.9578\n",
      "Epoch: 1068 loss_train: 0.1908 acc_train: 0.8805 acc_val: 0.9578\n",
      "Epoch: 1069 loss_train: 0.1887 acc_train: 0.8864 acc_val: 0.9578\n",
      "Epoch: 1070 loss_train: 0.1871 acc_train: 0.8842 acc_val: 0.9578\n",
      "Epoch: 1071 loss_train: 0.2033 acc_train: 0.8834 acc_val: 0.9578\n",
      "Epoch: 1072 loss_train: 0.1857 acc_train: 0.8938 acc_val: 0.9578\n",
      "Epoch: 1073 loss_train: 0.1738 acc_train: 0.8983 acc_val: 0.9578\n",
      "Epoch: 1074 loss_train: 0.1674 acc_train: 0.8968 acc_val: 0.9578\n",
      "Epoch: 1075 loss_train: 0.1768 acc_train: 0.8968 acc_val: 0.9578\n",
      "Epoch: 1076 loss_train: 0.1888 acc_train: 0.8879 acc_val: 0.9578\n",
      "Epoch: 1077 loss_train: 0.1850 acc_train: 0.8909 acc_val: 0.9578\n",
      "Epoch: 1078 loss_train: 0.1834 acc_train: 0.8872 acc_val: 0.9578\n",
      "Epoch: 1079 loss_train: 0.2065 acc_train: 0.8693 acc_val: 0.9578\n",
      "Epoch: 1080 loss_train: 0.1635 acc_train: 0.8946 acc_val: 0.9578\n",
      "Epoch: 1081 loss_train: 0.1721 acc_train: 0.8879 acc_val: 0.9578\n",
      "Epoch: 1082 loss_train: 0.1753 acc_train: 0.8894 acc_val: 0.9578\n",
      "Epoch: 1083 loss_train: 0.1878 acc_train: 0.8805 acc_val: 0.9578\n",
      "Epoch: 1084 loss_train: 0.1855 acc_train: 0.8886 acc_val: 0.9578\n",
      "Epoch: 1085 loss_train: 0.2165 acc_train: 0.8745 acc_val: 0.9578\n",
      "Epoch: 1086 loss_train: 0.1880 acc_train: 0.8849 acc_val: 0.9578\n",
      "Epoch: 1087 loss_train: 0.2010 acc_train: 0.8849 acc_val: 0.9578\n",
      "Epoch: 1088 loss_train: 0.1897 acc_train: 0.8805 acc_val: 0.9578\n",
      "Epoch: 1089 loss_train: 0.1644 acc_train: 0.8916 acc_val: 0.9578\n",
      "Epoch: 1090 loss_train: 0.1811 acc_train: 0.8931 acc_val: 0.9578\n",
      "Epoch: 1091 loss_train: 0.1773 acc_train: 0.8931 acc_val: 0.9578\n",
      "Epoch: 1092 loss_train: 0.2044 acc_train: 0.8745 acc_val: 0.9578\n",
      "Epoch: 1093 loss_train: 0.2036 acc_train: 0.8805 acc_val: 0.9578\n",
      "Epoch: 1094 loss_train: 0.2002 acc_train: 0.8827 acc_val: 0.9578\n",
      "Epoch: 1095 loss_train: 0.1955 acc_train: 0.8827 acc_val: 0.9578\n",
      "Epoch: 1096 loss_train: 0.1895 acc_train: 0.8834 acc_val: 0.9578\n",
      "Epoch: 1097 loss_train: 0.1684 acc_train: 0.9005 acc_val: 0.9578\n",
      "Epoch: 1098 loss_train: 0.1781 acc_train: 0.8968 acc_val: 0.9578\n",
      "Epoch: 1099 loss_train: 0.1796 acc_train: 0.9013 acc_val: 0.9578\n",
      "Epoch: 1100 loss_train: 0.1822 acc_train: 0.8909 acc_val: 0.9578\n",
      "Epoch: 1101 loss_train: 0.1865 acc_train: 0.8842 acc_val: 0.9578\n",
      "Epoch: 1102 loss_train: 0.1856 acc_train: 0.8872 acc_val: 0.9578\n",
      "Epoch: 1103 loss_train: 0.1964 acc_train: 0.8894 acc_val: 0.9578\n",
      "Epoch: 1104 loss_train: 0.1863 acc_train: 0.8931 acc_val: 0.9578\n",
      "Epoch: 1105 loss_train: 0.1916 acc_train: 0.8924 acc_val: 0.9578\n",
      "Epoch: 1106 loss_train: 0.1675 acc_train: 0.9035 acc_val: 0.9578\n",
      "Epoch: 1107 loss_train: 0.1763 acc_train: 0.8901 acc_val: 0.9578\n",
      "Epoch: 1108 loss_train: 0.1726 acc_train: 0.8872 acc_val: 0.9578\n",
      "Epoch: 1109 loss_train: 0.1896 acc_train: 0.8924 acc_val: 0.9578\n",
      "Epoch: 1110 loss_train: 0.1565 acc_train: 0.9109 acc_val: 0.9578\n",
      "Epoch: 1111 loss_train: 0.2097 acc_train: 0.8671 acc_val: 0.9578\n",
      "Epoch: 1112 loss_train: 0.1949 acc_train: 0.8827 acc_val: 0.9578\n",
      "Epoch: 1113 loss_train: 0.1658 acc_train: 0.8983 acc_val: 0.9578\n",
      "Epoch: 1114 loss_train: 0.1808 acc_train: 0.8983 acc_val: 0.9578\n",
      "Epoch: 1115 loss_train: 0.1967 acc_train: 0.8931 acc_val: 0.9578\n",
      "Epoch: 1116 loss_train: 0.1836 acc_train: 0.9057 acc_val: 0.9578\n",
      "Epoch: 1117 loss_train: 0.1796 acc_train: 0.9013 acc_val: 0.9578\n",
      "Epoch: 1118 loss_train: 0.2078 acc_train: 0.8716 acc_val: 0.9578\n",
      "Epoch: 1119 loss_train: 0.1913 acc_train: 0.8961 acc_val: 0.9578\n",
      "Epoch: 1120 loss_train: 0.1815 acc_train: 0.8998 acc_val: 0.9578\n",
      "Epoch: 1121 loss_train: 0.1603 acc_train: 0.9102 acc_val: 0.9578\n",
      "Epoch: 1122 loss_train: 0.1936 acc_train: 0.8790 acc_val: 0.9578\n",
      "Epoch: 1123 loss_train: 0.1948 acc_train: 0.8842 acc_val: 0.9578\n",
      "Epoch: 1124 loss_train: 0.1808 acc_train: 0.8953 acc_val: 0.9578\n",
      "Epoch: 1125 loss_train: 0.1907 acc_train: 0.8812 acc_val: 0.9578\n",
      "Epoch: 1126 loss_train: 0.1973 acc_train: 0.8790 acc_val: 0.9578\n",
      "Epoch: 1127 loss_train: 0.1764 acc_train: 0.8872 acc_val: 0.9578\n",
      "Epoch: 1128 loss_train: 0.1780 acc_train: 0.8872 acc_val: 0.9578\n",
      "Epoch: 1129 loss_train: 0.1916 acc_train: 0.8901 acc_val: 0.9578\n",
      "Epoch: 1130 loss_train: 0.1990 acc_train: 0.8834 acc_val: 0.9578\n",
      "Epoch: 1131 loss_train: 0.2023 acc_train: 0.8901 acc_val: 0.9578\n",
      "Epoch: 1132 loss_train: 0.1879 acc_train: 0.8961 acc_val: 0.9578\n",
      "Epoch: 1133 loss_train: 0.1836 acc_train: 0.8968 acc_val: 0.9578\n",
      "Epoch: 1134 loss_train: 0.1715 acc_train: 0.8976 acc_val: 0.9578\n",
      "Epoch: 1135 loss_train: 0.1976 acc_train: 0.8842 acc_val: 0.9578\n",
      "Epoch: 1136 loss_train: 0.1837 acc_train: 0.8946 acc_val: 0.9578\n",
      "Epoch: 1137 loss_train: 0.1931 acc_train: 0.8938 acc_val: 0.9578\n",
      "Epoch: 1138 loss_train: 0.1817 acc_train: 0.8961 acc_val: 0.9578\n",
      "Epoch: 1139 loss_train: 0.1755 acc_train: 0.8901 acc_val: 0.9578\n",
      "Epoch: 1140 loss_train: 0.1761 acc_train: 0.8990 acc_val: 0.9578\n",
      "Epoch: 1141 loss_train: 0.1851 acc_train: 0.8820 acc_val: 0.9578\n",
      "Epoch: 1142 loss_train: 0.1780 acc_train: 0.8931 acc_val: 0.9578\n",
      "Epoch: 1143 loss_train: 0.1885 acc_train: 0.8857 acc_val: 0.9578\n",
      "Epoch: 1144 loss_train: 0.1857 acc_train: 0.8872 acc_val: 0.9578\n",
      "Epoch: 1145 loss_train: 0.1869 acc_train: 0.8886 acc_val: 0.9578\n",
      "Epoch: 1146 loss_train: 0.2117 acc_train: 0.8753 acc_val: 0.9578\n",
      "Epoch: 1147 loss_train: 0.1627 acc_train: 0.9065 acc_val: 0.9578\n",
      "Epoch: 1148 loss_train: 0.1913 acc_train: 0.8820 acc_val: 0.9578\n",
      "Epoch: 1149 loss_train: 0.1808 acc_train: 0.8864 acc_val: 0.9578\n",
      "Epoch: 1150 loss_train: 0.1699 acc_train: 0.9050 acc_val: 0.9578\n",
      "Epoch: 1151 loss_train: 0.1619 acc_train: 0.9042 acc_val: 0.9578\n",
      "Epoch: 1152 loss_train: 0.1676 acc_train: 0.8946 acc_val: 0.9578\n",
      "Epoch: 1153 loss_train: 0.1897 acc_train: 0.8909 acc_val: 0.9578\n",
      "Epoch: 1154 loss_train: 0.1886 acc_train: 0.8834 acc_val: 0.9578\n",
      "Epoch: 1155 loss_train: 0.1763 acc_train: 0.9020 acc_val: 0.9578\n",
      "Epoch: 1156 loss_train: 0.1768 acc_train: 0.9027 acc_val: 0.9578\n",
      "Epoch: 1157 loss_train: 0.1780 acc_train: 0.8946 acc_val: 0.9578\n",
      "Epoch: 1158 loss_train: 0.1887 acc_train: 0.8931 acc_val: 0.9578\n",
      "Epoch: 1159 loss_train: 0.2133 acc_train: 0.8731 acc_val: 0.9578\n",
      "Epoch: 1160 loss_train: 0.1854 acc_train: 0.8931 acc_val: 0.9578\n",
      "Epoch: 1161 loss_train: 0.1858 acc_train: 0.8864 acc_val: 0.9578\n",
      "Epoch: 1162 loss_train: 0.1899 acc_train: 0.8894 acc_val: 0.9578\n",
      "Epoch: 1163 loss_train: 0.1956 acc_train: 0.8901 acc_val: 0.9578\n",
      "Epoch: 1164 loss_train: 0.1656 acc_train: 0.9020 acc_val: 0.9578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1165 loss_train: 0.1711 acc_train: 0.8953 acc_val: 0.9578\n",
      "Epoch: 1166 loss_train: 0.1839 acc_train: 0.8953 acc_val: 0.9578\n",
      "Epoch: 1167 loss_train: 0.1913 acc_train: 0.8901 acc_val: 0.9578\n",
      "Epoch: 1168 loss_train: 0.1743 acc_train: 0.8924 acc_val: 0.9578\n",
      "Epoch: 1169 loss_train: 0.1856 acc_train: 0.8916 acc_val: 0.9578\n",
      "Epoch: 1170 loss_train: 0.1732 acc_train: 0.9020 acc_val: 0.9578\n",
      "Epoch: 1171 loss_train: 0.1859 acc_train: 0.8894 acc_val: 0.9578\n",
      "Epoch: 1172 loss_train: 0.1751 acc_train: 0.8990 acc_val: 0.9578\n",
      "Epoch: 1173 loss_train: 0.1733 acc_train: 0.9013 acc_val: 0.9578\n",
      "Epoch: 1174 loss_train: 0.2006 acc_train: 0.8775 acc_val: 0.9578\n",
      "Epoch: 1175 loss_train: 0.1782 acc_train: 0.8879 acc_val: 0.9578\n",
      "Epoch: 1176 loss_train: 0.1846 acc_train: 0.8857 acc_val: 0.9578\n",
      "Epoch: 1177 loss_train: 0.1685 acc_train: 0.8998 acc_val: 0.9578\n",
      "Epoch: 1178 loss_train: 0.1825 acc_train: 0.8834 acc_val: 0.9578\n",
      "Epoch: 1179 loss_train: 0.1852 acc_train: 0.8864 acc_val: 0.9578\n",
      "Epoch: 1180 loss_train: 0.1991 acc_train: 0.8790 acc_val: 0.9578\n",
      "Epoch: 1181 loss_train: 0.1995 acc_train: 0.8731 acc_val: 0.9578\n",
      "Epoch: 1182 loss_train: 0.1917 acc_train: 0.8790 acc_val: 0.9578\n",
      "Epoch: 1183 loss_train: 0.1941 acc_train: 0.8812 acc_val: 0.9578\n",
      "Epoch: 1184 loss_train: 0.2003 acc_train: 0.8842 acc_val: 0.9578\n",
      "Epoch: 1185 loss_train: 0.1795 acc_train: 0.8916 acc_val: 0.9578\n",
      "Epoch: 1186 loss_train: 0.1915 acc_train: 0.8976 acc_val: 0.9578\n",
      "Epoch: 1187 loss_train: 0.1837 acc_train: 0.8842 acc_val: 0.9578\n",
      "Epoch: 1188 loss_train: 0.1848 acc_train: 0.8968 acc_val: 0.9578\n",
      "Epoch: 1189 loss_train: 0.1829 acc_train: 0.8901 acc_val: 0.9578\n",
      "Epoch: 1190 loss_train: 0.1868 acc_train: 0.8894 acc_val: 0.9578\n",
      "Epoch: 1191 loss_train: 0.1601 acc_train: 0.9013 acc_val: 0.9578\n",
      "Epoch: 1192 loss_train: 0.2065 acc_train: 0.8701 acc_val: 0.9578\n",
      "Epoch: 1193 loss_train: 0.1976 acc_train: 0.8760 acc_val: 0.9578\n",
      "Epoch: 1194 loss_train: 0.1579 acc_train: 0.9102 acc_val: 0.9578\n",
      "Epoch: 1195 loss_train: 0.1972 acc_train: 0.8931 acc_val: 0.9578\n",
      "Epoch: 1196 loss_train: 0.1863 acc_train: 0.8849 acc_val: 0.9578\n",
      "Epoch: 1197 loss_train: 0.1993 acc_train: 0.8797 acc_val: 0.9578\n",
      "Epoch: 1198 loss_train: 0.1914 acc_train: 0.8827 acc_val: 0.9578\n",
      "Epoch: 1199 loss_train: 0.1824 acc_train: 0.8916 acc_val: 0.9578\n",
      "Epoch: 1200 loss_train: 0.1873 acc_train: 0.8924 acc_val: 0.9578\n",
      "Epoch: 1201 loss_train: 0.1779 acc_train: 0.8990 acc_val: 0.9578\n",
      "Epoch: 1202 loss_train: 0.1822 acc_train: 0.8961 acc_val: 0.9578\n",
      "Epoch: 1203 loss_train: 0.1821 acc_train: 0.8924 acc_val: 0.9578\n",
      "Epoch: 1204 loss_train: 0.1765 acc_train: 0.9005 acc_val: 0.9578\n",
      "Epoch: 1205 loss_train: 0.1895 acc_train: 0.8872 acc_val: 0.9578\n",
      "Epoch: 1206 loss_train: 0.1934 acc_train: 0.8879 acc_val: 0.9578\n",
      "Epoch: 1207 loss_train: 0.2066 acc_train: 0.8894 acc_val: 0.9578\n",
      "Epoch: 1208 loss_train: 0.1757 acc_train: 0.8909 acc_val: 0.9578\n",
      "Epoch: 1209 loss_train: 0.2058 acc_train: 0.8812 acc_val: 0.9578\n",
      "Epoch: 1210 loss_train: 0.1860 acc_train: 0.8946 acc_val: 0.9578\n",
      "Epoch: 1211 loss_train: 0.2038 acc_train: 0.8849 acc_val: 0.9578\n",
      "Epoch: 1212 loss_train: 0.1762 acc_train: 0.8983 acc_val: 0.9578\n",
      "Epoch: 1213 loss_train: 0.1751 acc_train: 0.8961 acc_val: 0.9578\n",
      "Epoch: 1214 loss_train: 0.1990 acc_train: 0.8805 acc_val: 0.9578\n",
      "Epoch: 1215 loss_train: 0.1848 acc_train: 0.8879 acc_val: 0.9578\n",
      "Epoch: 1216 loss_train: 0.1767 acc_train: 0.9005 acc_val: 0.9578\n",
      "Epoch: 1217 loss_train: 0.1953 acc_train: 0.8797 acc_val: 0.9578\n",
      "Epoch: 1218 loss_train: 0.1971 acc_train: 0.8857 acc_val: 0.9578\n",
      "Epoch: 1219 loss_train: 0.1898 acc_train: 0.8938 acc_val: 0.9578\n",
      "Epoch: 1220 loss_train: 0.1838 acc_train: 0.8916 acc_val: 0.9578\n",
      "Epoch: 1221 loss_train: 0.2011 acc_train: 0.8797 acc_val: 0.9578\n",
      "Epoch: 1222 loss_train: 0.1768 acc_train: 0.8894 acc_val: 0.9578\n",
      "Epoch: 1223 loss_train: 0.1885 acc_train: 0.8768 acc_val: 0.9578\n",
      "Epoch: 1224 loss_train: 0.1743 acc_train: 0.8924 acc_val: 0.9578\n",
      "Epoch: 1225 loss_train: 0.1730 acc_train: 0.9013 acc_val: 0.9578\n",
      "Epoch: 1226 loss_train: 0.1843 acc_train: 0.8886 acc_val: 0.9578\n",
      "Epoch: 1227 loss_train: 0.1957 acc_train: 0.8924 acc_val: 0.9578\n",
      "Epoch: 1228 loss_train: 0.1799 acc_train: 0.8931 acc_val: 0.9578\n",
      "Epoch: 1229 loss_train: 0.1905 acc_train: 0.8916 acc_val: 0.9578\n",
      "Epoch: 1230 loss_train: 0.1924 acc_train: 0.8872 acc_val: 0.9578\n",
      "Epoch: 1231 loss_train: 0.1951 acc_train: 0.8857 acc_val: 0.9578\n",
      "Epoch: 1232 loss_train: 0.1741 acc_train: 0.8834 acc_val: 0.9578\n",
      "Epoch: 1233 loss_train: 0.1778 acc_train: 0.9013 acc_val: 0.9578\n",
      "Epoch: 1234 loss_train: 0.1682 acc_train: 0.9005 acc_val: 0.9578\n",
      "Epoch: 1235 loss_train: 0.1790 acc_train: 0.8961 acc_val: 0.9578\n",
      "Epoch: 1236 loss_train: 0.1879 acc_train: 0.8931 acc_val: 0.9578\n",
      "Epoch: 1237 loss_train: 0.1747 acc_train: 0.9005 acc_val: 0.9578\n",
      "Epoch: 1238 loss_train: 0.1797 acc_train: 0.8901 acc_val: 0.9578\n",
      "Epoch: 1239 loss_train: 0.1690 acc_train: 0.8968 acc_val: 0.9578\n",
      "Epoch: 1240 loss_train: 0.1855 acc_train: 0.8827 acc_val: 0.9578\n",
      "Epoch: 1241 loss_train: 0.1808 acc_train: 0.8879 acc_val: 0.9578\n",
      "Epoch: 1242 loss_train: 0.1775 acc_train: 0.9065 acc_val: 0.9578\n",
      "Epoch: 1243 loss_train: 0.1805 acc_train: 0.9065 acc_val: 0.9578\n",
      "Epoch: 1244 loss_train: 0.1715 acc_train: 0.9027 acc_val: 0.9578\n",
      "Epoch: 1245 loss_train: 0.2012 acc_train: 0.8857 acc_val: 0.9578\n",
      "Epoch: 1246 loss_train: 0.1862 acc_train: 0.8946 acc_val: 0.9578\n",
      "Epoch: 1247 loss_train: 0.1897 acc_train: 0.8924 acc_val: 0.9578\n",
      "Epoch: 1248 loss_train: 0.1577 acc_train: 0.9057 acc_val: 0.9578\n",
      "Epoch: 1249 loss_train: 0.1725 acc_train: 0.8983 acc_val: 0.9578\n",
      "Epoch: 1250 loss_train: 0.1809 acc_train: 0.8857 acc_val: 0.9578\n",
      "Epoch: 1251 loss_train: 0.1895 acc_train: 0.8834 acc_val: 0.9578\n",
      "Epoch: 1252 loss_train: 0.1940 acc_train: 0.8894 acc_val: 0.9578\n",
      "Epoch: 1253 loss_train: 0.1862 acc_train: 0.8894 acc_val: 0.9578\n",
      "Epoch: 1254 loss_train: 0.1777 acc_train: 0.8961 acc_val: 0.9578\n",
      "Epoch: 1255 loss_train: 0.1957 acc_train: 0.8797 acc_val: 0.9578\n",
      "Epoch: 1256 loss_train: 0.1971 acc_train: 0.8879 acc_val: 0.9578\n",
      "Epoch: 1257 loss_train: 0.2018 acc_train: 0.8857 acc_val: 0.9578\n",
      "Epoch: 1258 loss_train: 0.1668 acc_train: 0.8931 acc_val: 0.9578\n",
      "Epoch: 1259 loss_train: 0.1801 acc_train: 0.8953 acc_val: 0.9578\n",
      "Epoch: 1260 loss_train: 0.1755 acc_train: 0.8953 acc_val: 0.9578\n",
      "Epoch: 1261 loss_train: 0.1939 acc_train: 0.8834 acc_val: 0.9578\n",
      "Epoch: 1262 loss_train: 0.1669 acc_train: 0.9027 acc_val: 0.9578\n",
      "Epoch: 1263 loss_train: 0.1667 acc_train: 0.9035 acc_val: 0.9578\n",
      "Epoch: 1264 loss_train: 0.1809 acc_train: 0.8953 acc_val: 0.9578\n",
      "Epoch: 1265 loss_train: 0.1774 acc_train: 0.8820 acc_val: 0.9578\n",
      "Epoch: 1266 loss_train: 0.1732 acc_train: 0.8909 acc_val: 0.9578\n",
      "Epoch: 1267 loss_train: 0.1575 acc_train: 0.8990 acc_val: 0.9578\n",
      "Epoch: 1268 loss_train: 0.1692 acc_train: 0.8946 acc_val: 0.9578\n",
      "Epoch: 1269 loss_train: 0.2029 acc_train: 0.8731 acc_val: 0.9578\n",
      "Epoch: 1270 loss_train: 0.1729 acc_train: 0.8961 acc_val: 0.9578\n",
      "Epoch: 1271 loss_train: 0.1597 acc_train: 0.9072 acc_val: 0.9578\n",
      "Epoch: 1272 loss_train: 0.1922 acc_train: 0.8849 acc_val: 0.9578\n",
      "Epoch: 1273 loss_train: 0.1783 acc_train: 0.8879 acc_val: 0.9578\n",
      "Epoch: 1274 loss_train: 0.1976 acc_train: 0.8775 acc_val: 0.9578\n",
      "Epoch: 1275 loss_train: 0.1871 acc_train: 0.8849 acc_val: 0.9578\n",
      "Epoch: 1276 loss_train: 0.1901 acc_train: 0.8872 acc_val: 0.9578\n",
      "Epoch: 1277 loss_train: 0.1850 acc_train: 0.8901 acc_val: 0.9578\n",
      "Epoch: 1278 loss_train: 0.1689 acc_train: 0.9027 acc_val: 0.9578\n",
      "Epoch: 1279 loss_train: 0.1698 acc_train: 0.9005 acc_val: 0.9578\n",
      "Epoch: 1280 loss_train: 0.1821 acc_train: 0.8924 acc_val: 0.9578\n",
      "Epoch: 1281 loss_train: 0.1965 acc_train: 0.8842 acc_val: 0.9578\n",
      "Epoch: 1282 loss_train: 0.1997 acc_train: 0.8782 acc_val: 0.9578\n",
      "Epoch: 1283 loss_train: 0.1671 acc_train: 0.8998 acc_val: 0.9578\n",
      "Epoch: 1284 loss_train: 0.1911 acc_train: 0.8834 acc_val: 0.9578\n",
      "Epoch: 1285 loss_train: 0.1972 acc_train: 0.8775 acc_val: 0.9578\n",
      "Epoch: 1286 loss_train: 0.1914 acc_train: 0.8849 acc_val: 0.9578\n",
      "Epoch: 1287 loss_train: 0.1669 acc_train: 0.8983 acc_val: 0.9578\n",
      "Epoch: 1288 loss_train: 0.1933 acc_train: 0.8820 acc_val: 0.9578\n",
      "Epoch: 1289 loss_train: 0.1729 acc_train: 0.8983 acc_val: 0.9578\n",
      "Epoch: 1290 loss_train: 0.1745 acc_train: 0.8938 acc_val: 0.9578\n",
      "Epoch: 1291 loss_train: 0.1803 acc_train: 0.8901 acc_val: 0.9578\n",
      "Epoch: 1292 loss_train: 0.1724 acc_train: 0.8916 acc_val: 0.9578\n",
      "Epoch: 1293 loss_train: 0.1879 acc_train: 0.8768 acc_val: 0.9578\n",
      "Epoch: 1294 loss_train: 0.1943 acc_train: 0.8775 acc_val: 0.9578\n",
      "Epoch: 1295 loss_train: 0.1945 acc_train: 0.8834 acc_val: 0.9578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1296 loss_train: 0.1733 acc_train: 0.9042 acc_val: 0.9578\n",
      "Epoch: 1297 loss_train: 0.1945 acc_train: 0.8775 acc_val: 0.9578\n",
      "Epoch: 1298 loss_train: 0.1832 acc_train: 0.8990 acc_val: 0.9578\n",
      "Epoch: 1299 loss_train: 0.1905 acc_train: 0.8864 acc_val: 0.9578\n",
      "Epoch: 1300 loss_train: 0.1862 acc_train: 0.8924 acc_val: 0.9578\n",
      "Epoch: 1301 loss_train: 0.1976 acc_train: 0.8805 acc_val: 0.9578\n",
      "Epoch: 1302 loss_train: 0.1794 acc_train: 0.8961 acc_val: 0.9578\n",
      "Epoch: 1303 loss_train: 0.1817 acc_train: 0.8938 acc_val: 0.9578\n",
      "Epoch: 1304 loss_train: 0.1794 acc_train: 0.8968 acc_val: 0.9578\n",
      "Epoch: 1305 loss_train: 0.1975 acc_train: 0.8842 acc_val: 0.9578\n",
      "Epoch: 1306 loss_train: 0.1701 acc_train: 0.9027 acc_val: 0.9578\n",
      "Epoch: 1307 loss_train: 0.1855 acc_train: 0.8834 acc_val: 0.9578\n",
      "Epoch: 1308 loss_train: 0.1981 acc_train: 0.8790 acc_val: 0.9578\n",
      "Epoch: 1309 loss_train: 0.1880 acc_train: 0.8894 acc_val: 0.9578\n",
      "Epoch: 1310 loss_train: 0.1923 acc_train: 0.8938 acc_val: 0.9578\n",
      "Epoch: 1311 loss_train: 0.2222 acc_train: 0.8693 acc_val: 0.9578\n",
      "Epoch: 1312 loss_train: 0.1915 acc_train: 0.8849 acc_val: 0.9578\n",
      "Epoch: 1313 loss_train: 0.1720 acc_train: 0.9005 acc_val: 0.9578\n",
      "Epoch: 1314 loss_train: 0.1954 acc_train: 0.8894 acc_val: 0.9578\n",
      "Epoch: 1315 loss_train: 0.1845 acc_train: 0.8976 acc_val: 0.9578\n",
      "Epoch: 1316 loss_train: 0.1851 acc_train: 0.8872 acc_val: 0.9578\n",
      "Epoch: 1317 loss_train: 0.1859 acc_train: 0.8879 acc_val: 0.9578\n",
      "Epoch: 1318 loss_train: 0.1856 acc_train: 0.8901 acc_val: 0.9578\n",
      "Epoch: 1319 loss_train: 0.1770 acc_train: 0.9013 acc_val: 0.9578\n",
      "Epoch: 1320 loss_train: 0.1754 acc_train: 0.8961 acc_val: 0.9578\n",
      "Epoch: 1321 loss_train: 0.1901 acc_train: 0.8820 acc_val: 0.9578\n",
      "Epoch: 1322 loss_train: 0.1939 acc_train: 0.8857 acc_val: 0.9578\n",
      "Epoch: 1323 loss_train: 0.1911 acc_train: 0.8797 acc_val: 0.9578\n",
      "Epoch: 1324 loss_train: 0.2008 acc_train: 0.8827 acc_val: 0.9578\n",
      "Epoch: 1325 loss_train: 0.1643 acc_train: 0.8998 acc_val: 0.9578\n",
      "Epoch: 1326 loss_train: 0.2021 acc_train: 0.8857 acc_val: 0.9578\n",
      "Epoch: 1327 loss_train: 0.1932 acc_train: 0.8827 acc_val: 0.9578\n",
      "Epoch: 1328 loss_train: 0.2010 acc_train: 0.8805 acc_val: 0.9578\n",
      "Epoch: 1329 loss_train: 0.1831 acc_train: 0.8827 acc_val: 0.9578\n",
      "Epoch: 1330 loss_train: 0.1664 acc_train: 0.8990 acc_val: 0.9578\n",
      "Epoch: 1331 loss_train: 0.1641 acc_train: 0.8946 acc_val: 0.9578\n",
      "Epoch: 1332 loss_train: 0.1990 acc_train: 0.8946 acc_val: 0.9578\n",
      "Epoch: 1333 loss_train: 0.1770 acc_train: 0.8983 acc_val: 0.9578\n",
      "Epoch: 1334 loss_train: 0.1719 acc_train: 0.8938 acc_val: 0.9578\n",
      "Epoch: 1335 loss_train: 0.1946 acc_train: 0.8820 acc_val: 0.9578\n",
      "Epoch: 1336 loss_train: 0.1917 acc_train: 0.8916 acc_val: 0.9578\n",
      "Epoch: 1337 loss_train: 0.1700 acc_train: 0.8961 acc_val: 0.9578\n",
      "Epoch: 1338 loss_train: 0.2016 acc_train: 0.8805 acc_val: 0.9578\n",
      "Epoch: 1339 loss_train: 0.1861 acc_train: 0.8916 acc_val: 0.9578\n",
      "Epoch: 1340 loss_train: 0.1819 acc_train: 0.8901 acc_val: 0.9578\n",
      "Epoch: 1341 loss_train: 0.1901 acc_train: 0.8849 acc_val: 0.9578\n",
      "Epoch: 1342 loss_train: 0.1892 acc_train: 0.8961 acc_val: 0.9578\n",
      "Epoch: 1343 loss_train: 0.1980 acc_train: 0.8738 acc_val: 0.9578\n",
      "Epoch: 1344 loss_train: 0.1888 acc_train: 0.8864 acc_val: 0.9578\n",
      "Epoch: 1345 loss_train: 0.1958 acc_train: 0.8842 acc_val: 0.9578\n",
      "Epoch: 1346 loss_train: 0.1776 acc_train: 0.8961 acc_val: 0.9578\n",
      "Epoch: 1347 loss_train: 0.1950 acc_train: 0.8886 acc_val: 0.9578\n",
      "Epoch: 1348 loss_train: 0.1738 acc_train: 0.8946 acc_val: 0.9578\n",
      "Epoch: 1349 loss_train: 0.1858 acc_train: 0.8983 acc_val: 0.9578\n",
      "Epoch: 1350 loss_train: 0.1906 acc_train: 0.8812 acc_val: 0.9578\n",
      "Epoch: 1351 loss_train: 0.1973 acc_train: 0.8753 acc_val: 0.9578\n",
      "Epoch: 1352 loss_train: 0.1827 acc_train: 0.8946 acc_val: 0.9578\n",
      "Epoch: 1353 loss_train: 0.1839 acc_train: 0.8916 acc_val: 0.9578\n",
      "Epoch: 1354 loss_train: 0.1762 acc_train: 0.8990 acc_val: 0.9578\n",
      "Epoch: 1355 loss_train: 0.1943 acc_train: 0.8812 acc_val: 0.9578\n",
      "Epoch: 1356 loss_train: 0.1870 acc_train: 0.8901 acc_val: 0.9578\n",
      "Epoch: 1357 loss_train: 0.1818 acc_train: 0.8894 acc_val: 0.9578\n",
      "Epoch: 1358 loss_train: 0.1795 acc_train: 0.8953 acc_val: 0.9578\n",
      "Epoch: 1359 loss_train: 0.1895 acc_train: 0.8961 acc_val: 0.9578\n",
      "Epoch: 1360 loss_train: 0.1901 acc_train: 0.8886 acc_val: 0.9578\n",
      "Epoch: 1361 loss_train: 0.1911 acc_train: 0.8797 acc_val: 0.9578\n",
      "Epoch: 1362 loss_train: 0.1725 acc_train: 0.8990 acc_val: 0.9578\n",
      "Epoch: 1363 loss_train: 0.1825 acc_train: 0.8938 acc_val: 0.9578\n",
      "Epoch: 1364 loss_train: 0.1824 acc_train: 0.8894 acc_val: 0.9578\n",
      "Epoch: 1365 loss_train: 0.1825 acc_train: 0.9013 acc_val: 0.9578\n",
      "Epoch: 1366 loss_train: 0.1769 acc_train: 0.8983 acc_val: 0.9578\n",
      "Epoch: 1367 loss_train: 0.1988 acc_train: 0.8797 acc_val: 0.9578\n",
      "Epoch: 1368 loss_train: 0.1861 acc_train: 0.8879 acc_val: 0.9578\n",
      "Epoch: 1369 loss_train: 0.1798 acc_train: 0.8924 acc_val: 0.9578\n",
      "Epoch: 1370 loss_train: 0.1828 acc_train: 0.9079 acc_val: 0.9578\n",
      "Epoch: 1371 loss_train: 0.1789 acc_train: 0.9020 acc_val: 0.9578\n",
      "Epoch: 1372 loss_train: 0.1937 acc_train: 0.8894 acc_val: 0.9578\n",
      "Epoch: 1373 loss_train: 0.2077 acc_train: 0.8760 acc_val: 0.9578\n",
      "Epoch: 1374 loss_train: 0.1701 acc_train: 0.9050 acc_val: 0.9578\n",
      "Epoch: 1375 loss_train: 0.2014 acc_train: 0.8797 acc_val: 0.9578\n",
      "Epoch: 1376 loss_train: 0.2010 acc_train: 0.8916 acc_val: 0.9578\n",
      "Epoch: 1377 loss_train: 0.1905 acc_train: 0.8886 acc_val: 0.9578\n",
      "Epoch: 1378 loss_train: 0.1954 acc_train: 0.8812 acc_val: 0.9578\n",
      "Epoch: 1379 loss_train: 0.1919 acc_train: 0.8953 acc_val: 0.9578\n",
      "Epoch: 1380 loss_train: 0.1958 acc_train: 0.8812 acc_val: 0.9578\n",
      "Epoch: 1381 loss_train: 0.1998 acc_train: 0.8849 acc_val: 0.9578\n",
      "Epoch: 1382 loss_train: 0.1657 acc_train: 0.8968 acc_val: 0.9578\n",
      "Epoch: 1383 loss_train: 0.1728 acc_train: 0.9005 acc_val: 0.9578\n",
      "Epoch: 1384 loss_train: 0.1954 acc_train: 0.8812 acc_val: 0.9578\n",
      "Epoch: 1385 loss_train: 0.1882 acc_train: 0.8820 acc_val: 0.9578\n",
      "Epoch: 1386 loss_train: 0.1886 acc_train: 0.8946 acc_val: 0.9578\n",
      "Epoch: 1387 loss_train: 0.1998 acc_train: 0.8849 acc_val: 0.9578\n",
      "Epoch: 1388 loss_train: 0.1824 acc_train: 0.8916 acc_val: 0.9578\n",
      "Epoch: 1389 loss_train: 0.1838 acc_train: 0.8968 acc_val: 0.9578\n",
      "Epoch: 1390 loss_train: 0.1821 acc_train: 0.8946 acc_val: 0.9578\n",
      "Epoch: 1391 loss_train: 0.1952 acc_train: 0.8909 acc_val: 0.9578\n",
      "Epoch: 1392 loss_train: 0.1809 acc_train: 0.8916 acc_val: 0.9578\n",
      "Epoch: 1393 loss_train: 0.1722 acc_train: 0.9087 acc_val: 0.9578\n",
      "Epoch: 1394 loss_train: 0.2043 acc_train: 0.8790 acc_val: 0.9578\n",
      "Epoch: 1395 loss_train: 0.1786 acc_train: 0.8901 acc_val: 0.9578\n",
      "Epoch: 1396 loss_train: 0.1911 acc_train: 0.8976 acc_val: 0.9578\n",
      "Epoch: 1397 loss_train: 0.1537 acc_train: 0.9117 acc_val: 0.9578\n",
      "Epoch: 1398 loss_train: 0.1739 acc_train: 0.8983 acc_val: 0.9578\n",
      "Epoch: 1399 loss_train: 0.1689 acc_train: 0.9020 acc_val: 0.9578\n",
      "Epoch: 1400 loss_train: 0.1836 acc_train: 0.8990 acc_val: 0.9578\n",
      "Epoch: 1401 loss_train: 0.1828 acc_train: 0.8976 acc_val: 0.9578\n",
      "Epoch: 1402 loss_train: 0.1987 acc_train: 0.8797 acc_val: 0.9578\n",
      "Epoch: 1403 loss_train: 0.1837 acc_train: 0.8886 acc_val: 0.9578\n",
      "Epoch: 1404 loss_train: 0.1712 acc_train: 0.8879 acc_val: 0.9578\n",
      "Epoch: 1405 loss_train: 0.1749 acc_train: 0.8946 acc_val: 0.9578\n",
      "Epoch: 1406 loss_train: 0.1794 acc_train: 0.8872 acc_val: 0.9578\n",
      "Epoch: 1407 loss_train: 0.1988 acc_train: 0.8827 acc_val: 0.9578\n",
      "Epoch: 1408 loss_train: 0.1958 acc_train: 0.8797 acc_val: 0.9578\n",
      "Epoch: 1409 loss_train: 0.2171 acc_train: 0.8664 acc_val: 0.9578\n",
      "Epoch: 1410 loss_train: 0.1883 acc_train: 0.8931 acc_val: 0.9578\n",
      "Epoch: 1411 loss_train: 0.1982 acc_train: 0.8827 acc_val: 0.9578\n",
      "Epoch: 1412 loss_train: 0.1887 acc_train: 0.8857 acc_val: 0.9578\n",
      "Epoch: 1413 loss_train: 0.1650 acc_train: 0.9109 acc_val: 0.9578\n",
      "Epoch: 1414 loss_train: 0.1752 acc_train: 0.8968 acc_val: 0.9578\n",
      "Epoch: 1415 loss_train: 0.1722 acc_train: 0.8946 acc_val: 0.9578\n",
      "Epoch: 1416 loss_train: 0.1822 acc_train: 0.8983 acc_val: 0.9578\n",
      "Epoch: 1417 loss_train: 0.1715 acc_train: 0.9020 acc_val: 0.9578\n",
      "Epoch: 1418 loss_train: 0.1832 acc_train: 0.8931 acc_val: 0.9578\n",
      "Epoch: 1419 loss_train: 0.1995 acc_train: 0.8872 acc_val: 0.9578\n",
      "Epoch: 1420 loss_train: 0.1720 acc_train: 0.8990 acc_val: 0.9578\n",
      "Epoch: 1421 loss_train: 0.2044 acc_train: 0.8768 acc_val: 0.9578\n",
      "Epoch: 1422 loss_train: 0.1698 acc_train: 0.9005 acc_val: 0.9578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1423 loss_train: 0.1760 acc_train: 0.8961 acc_val: 0.9578\n",
      "Epoch: 1424 loss_train: 0.2006 acc_train: 0.8879 acc_val: 0.9578\n",
      "Epoch: 1425 loss_train: 0.1813 acc_train: 0.8961 acc_val: 0.9578\n",
      "Epoch: 1426 loss_train: 0.1847 acc_train: 0.8775 acc_val: 0.9578\n",
      "Epoch: 1427 loss_train: 0.2025 acc_train: 0.8775 acc_val: 0.9578\n",
      "Epoch: 1428 loss_train: 0.2252 acc_train: 0.8693 acc_val: 0.9578\n",
      "Epoch: 1429 loss_train: 0.2050 acc_train: 0.8760 acc_val: 0.9578\n",
      "Epoch: 1430 loss_train: 0.1732 acc_train: 0.8976 acc_val: 0.9578\n",
      "Epoch: 1431 loss_train: 0.1829 acc_train: 0.8924 acc_val: 0.9578\n",
      "Epoch: 1432 loss_train: 0.2290 acc_train: 0.8686 acc_val: 0.9578\n",
      "Epoch: 1433 loss_train: 0.1709 acc_train: 0.9072 acc_val: 0.9578\n",
      "Epoch: 1434 loss_train: 0.1771 acc_train: 0.8961 acc_val: 0.9578\n",
      "Epoch: 1435 loss_train: 0.1966 acc_train: 0.8953 acc_val: 0.9578\n",
      "Epoch: 1436 loss_train: 0.1664 acc_train: 0.8894 acc_val: 0.9578\n",
      "Epoch: 1437 loss_train: 0.1847 acc_train: 0.8931 acc_val: 0.9578\n",
      "Epoch: 1438 loss_train: 0.1951 acc_train: 0.8909 acc_val: 0.9578\n",
      "Epoch: 1439 loss_train: 0.1820 acc_train: 0.8938 acc_val: 0.9578\n",
      "Epoch: 1440 loss_train: 0.1769 acc_train: 0.9013 acc_val: 0.9578\n",
      "Epoch: 1441 loss_train: 0.1882 acc_train: 0.8924 acc_val: 0.9578\n",
      "Epoch: 1442 loss_train: 0.1669 acc_train: 0.9057 acc_val: 0.9578\n",
      "Epoch: 1443 loss_train: 0.1742 acc_train: 0.8901 acc_val: 0.9578\n",
      "Epoch: 1444 loss_train: 0.1964 acc_train: 0.8827 acc_val: 0.9578\n",
      "Epoch: 1445 loss_train: 0.1835 acc_train: 0.8894 acc_val: 0.9578\n",
      "Epoch: 1446 loss_train: 0.2019 acc_train: 0.8768 acc_val: 0.9578\n",
      "Epoch: 1447 loss_train: 0.1912 acc_train: 0.8894 acc_val: 0.9578\n",
      "Epoch: 1448 loss_train: 0.1814 acc_train: 0.8983 acc_val: 0.9578\n",
      "Epoch: 1449 loss_train: 0.1785 acc_train: 0.8946 acc_val: 0.9578\n",
      "Epoch: 1450 loss_train: 0.1787 acc_train: 0.8916 acc_val: 0.9578\n",
      "Epoch: 1451 loss_train: 0.1693 acc_train: 0.8916 acc_val: 0.9578\n",
      "Epoch: 1452 loss_train: 0.1962 acc_train: 0.8834 acc_val: 0.9578\n",
      "Epoch: 1453 loss_train: 0.1811 acc_train: 0.8857 acc_val: 0.9578\n",
      "Epoch: 1454 loss_train: 0.1847 acc_train: 0.8834 acc_val: 0.9578\n",
      "Epoch: 1455 loss_train: 0.1929 acc_train: 0.8864 acc_val: 0.9578\n",
      "Epoch: 1456 loss_train: 0.1952 acc_train: 0.8820 acc_val: 0.9578\n",
      "Epoch: 1457 loss_train: 0.1903 acc_train: 0.8775 acc_val: 0.9578\n",
      "Epoch: 1458 loss_train: 0.1882 acc_train: 0.8812 acc_val: 0.9578\n",
      "Epoch: 1459 loss_train: 0.1928 acc_train: 0.8968 acc_val: 0.9578\n",
      "Epoch: 1460 loss_train: 0.2064 acc_train: 0.8894 acc_val: 0.9578\n",
      "Epoch: 1461 loss_train: 0.1769 acc_train: 0.9042 acc_val: 0.9578\n",
      "Epoch: 1462 loss_train: 0.1679 acc_train: 0.8983 acc_val: 0.9578\n",
      "Epoch: 1463 loss_train: 0.1870 acc_train: 0.8827 acc_val: 0.9578\n",
      "Epoch: 1464 loss_train: 0.1749 acc_train: 0.8924 acc_val: 0.9578\n",
      "Epoch: 1465 loss_train: 0.1881 acc_train: 0.8901 acc_val: 0.9578\n",
      "Epoch: 1466 loss_train: 0.1758 acc_train: 0.8901 acc_val: 0.9578\n",
      "Epoch: 1467 loss_train: 0.1760 acc_train: 0.9027 acc_val: 0.9578\n",
      "Epoch: 1468 loss_train: 0.1962 acc_train: 0.8820 acc_val: 0.9578\n",
      "Epoch: 1469 loss_train: 0.1735 acc_train: 0.8953 acc_val: 0.9578\n",
      "Epoch: 1470 loss_train: 0.1832 acc_train: 0.8990 acc_val: 0.9578\n",
      "Epoch: 1471 loss_train: 0.2127 acc_train: 0.8708 acc_val: 0.9578\n",
      "Epoch: 1472 loss_train: 0.1821 acc_train: 0.8827 acc_val: 0.9578\n",
      "Epoch: 1473 loss_train: 0.2115 acc_train: 0.8805 acc_val: 0.9578\n",
      "Epoch: 1474 loss_train: 0.1805 acc_train: 0.9020 acc_val: 0.9578\n",
      "Epoch: 1475 loss_train: 0.1893 acc_train: 0.8812 acc_val: 0.9578\n",
      "Epoch: 1476 loss_train: 0.1998 acc_train: 0.8909 acc_val: 0.9578\n",
      "Epoch: 1477 loss_train: 0.1972 acc_train: 0.8983 acc_val: 0.9578\n",
      "Epoch: 1478 loss_train: 0.1992 acc_train: 0.8842 acc_val: 0.9578\n",
      "Epoch: 1479 loss_train: 0.2032 acc_train: 0.8805 acc_val: 0.9578\n",
      "Epoch: 1480 loss_train: 0.1987 acc_train: 0.8760 acc_val: 0.9578\n",
      "Epoch: 1481 loss_train: 0.1879 acc_train: 0.8953 acc_val: 0.9578\n",
      "Epoch: 1482 loss_train: 0.1961 acc_train: 0.8834 acc_val: 0.9578\n",
      "Epoch: 1483 loss_train: 0.1708 acc_train: 0.8976 acc_val: 0.9578\n",
      "Epoch: 1484 loss_train: 0.2119 acc_train: 0.8768 acc_val: 0.9578\n",
      "Epoch: 1485 loss_train: 0.1989 acc_train: 0.8782 acc_val: 0.9578\n",
      "Epoch: 1486 loss_train: 0.1884 acc_train: 0.8879 acc_val: 0.9578\n",
      "Epoch: 1487 loss_train: 0.1831 acc_train: 0.9027 acc_val: 0.9578\n",
      "Epoch: 1488 loss_train: 0.1653 acc_train: 0.8976 acc_val: 0.9578\n",
      "Epoch: 1489 loss_train: 0.1846 acc_train: 0.8946 acc_val: 0.9578\n",
      "Epoch: 1490 loss_train: 0.1862 acc_train: 0.8864 acc_val: 0.9578\n",
      "Epoch: 1491 loss_train: 0.1966 acc_train: 0.8894 acc_val: 0.9578\n",
      "Epoch: 1492 loss_train: 0.2136 acc_train: 0.8745 acc_val: 0.9578\n",
      "Epoch: 1493 loss_train: 0.1947 acc_train: 0.8857 acc_val: 0.9578\n",
      "Epoch: 1494 loss_train: 0.1994 acc_train: 0.8834 acc_val: 0.9578\n",
      "Epoch: 1495 loss_train: 0.1740 acc_train: 0.8968 acc_val: 0.9578\n",
      "Epoch: 1496 loss_train: 0.1805 acc_train: 0.8931 acc_val: 0.9578\n",
      "Epoch: 1497 loss_train: 0.2068 acc_train: 0.8782 acc_val: 0.9578\n",
      "Epoch: 1498 loss_train: 0.2058 acc_train: 0.8760 acc_val: 0.9578\n",
      "Epoch: 1499 loss_train: 0.1872 acc_train: 0.8842 acc_val: 0.9578\n",
      "Epoch: 1500 loss_train: 0.1874 acc_train: 0.8872 acc_val: 0.9578\n",
      "Epoch: 1501 loss_train: 0.1692 acc_train: 0.9057 acc_val: 0.9578\n",
      "Epoch: 1502 loss_train: 0.1876 acc_train: 0.8849 acc_val: 0.9578\n",
      "Epoch: 1503 loss_train: 0.1907 acc_train: 0.8931 acc_val: 0.9578\n",
      "Epoch: 1504 loss_train: 0.2013 acc_train: 0.8879 acc_val: 0.9578\n",
      "Epoch: 1505 loss_train: 0.1706 acc_train: 0.8976 acc_val: 0.9578\n",
      "Epoch: 1506 loss_train: 0.1873 acc_train: 0.8834 acc_val: 0.9578\n",
      "Epoch: 1507 loss_train: 0.1750 acc_train: 0.8886 acc_val: 0.9578\n",
      "Epoch: 1508 loss_train: 0.1761 acc_train: 0.9020 acc_val: 0.9578\n",
      "Epoch: 1509 loss_train: 0.1997 acc_train: 0.8708 acc_val: 0.9578\n",
      "Epoch: 1510 loss_train: 0.1767 acc_train: 0.8924 acc_val: 0.9578\n",
      "Epoch: 1511 loss_train: 0.1700 acc_train: 0.8998 acc_val: 0.9578\n",
      "Epoch: 1512 loss_train: 0.1801 acc_train: 0.8976 acc_val: 0.9578\n",
      "Epoch: 1513 loss_train: 0.1830 acc_train: 0.8894 acc_val: 0.9578\n",
      "Epoch: 1514 loss_train: 0.1785 acc_train: 0.8924 acc_val: 0.9578\n",
      "Epoch: 1515 loss_train: 0.1845 acc_train: 0.8976 acc_val: 0.9578\n",
      "Epoch: 1516 loss_train: 0.1838 acc_train: 0.8872 acc_val: 0.9578\n",
      "Epoch: 1517 loss_train: 0.1769 acc_train: 0.8990 acc_val: 0.9578\n",
      "Epoch: 1518 loss_train: 0.1895 acc_train: 0.8938 acc_val: 0.9578\n",
      "Epoch: 1519 loss_train: 0.1869 acc_train: 0.8909 acc_val: 0.9578\n",
      "Epoch: 1520 loss_train: 0.1740 acc_train: 0.8938 acc_val: 0.9578\n",
      "Epoch: 1521 loss_train: 0.1903 acc_train: 0.8931 acc_val: 0.9578\n",
      "Epoch: 1522 loss_train: 0.2111 acc_train: 0.8731 acc_val: 0.9578\n",
      "Epoch: 1523 loss_train: 0.1711 acc_train: 0.8998 acc_val: 0.9578\n",
      "Epoch: 1524 loss_train: 0.1950 acc_train: 0.8961 acc_val: 0.9578\n",
      "Epoch: 1525 loss_train: 0.1824 acc_train: 0.8946 acc_val: 0.9578\n",
      "Epoch: 1526 loss_train: 0.1560 acc_train: 0.9057 acc_val: 0.9578\n",
      "Epoch: 1527 loss_train: 0.1870 acc_train: 0.9005 acc_val: 0.9578\n",
      "Epoch: 1528 loss_train: 0.2136 acc_train: 0.8790 acc_val: 0.9578\n",
      "Epoch: 1529 loss_train: 0.1872 acc_train: 0.8924 acc_val: 0.9578\n",
      "Epoch: 1530 loss_train: 0.1701 acc_train: 0.9042 acc_val: 0.9578\n",
      "Epoch: 1531 loss_train: 0.1867 acc_train: 0.8938 acc_val: 0.9578\n",
      "Epoch: 1532 loss_train: 0.1847 acc_train: 0.8842 acc_val: 0.9578\n",
      "Epoch: 1533 loss_train: 0.1670 acc_train: 0.8938 acc_val: 0.9578\n",
      "Epoch: 1534 loss_train: 0.1904 acc_train: 0.8901 acc_val: 0.9578\n",
      "Epoch: 1535 loss_train: 0.1734 acc_train: 0.9005 acc_val: 0.9578\n",
      "Epoch: 1536 loss_train: 0.1814 acc_train: 0.8901 acc_val: 0.9578\n",
      "Epoch: 1537 loss_train: 0.1952 acc_train: 0.8842 acc_val: 0.9578\n",
      "Epoch: 1538 loss_train: 0.2055 acc_train: 0.8664 acc_val: 0.9578\n",
      "Epoch: 1539 loss_train: 0.1907 acc_train: 0.8879 acc_val: 0.9578\n",
      "Epoch: 1540 loss_train: 0.1718 acc_train: 0.8938 acc_val: 0.9578\n",
      "Epoch: 1541 loss_train: 0.1714 acc_train: 0.8968 acc_val: 0.9578\n",
      "Epoch: 1542 loss_train: 0.1789 acc_train: 0.8916 acc_val: 0.9578\n",
      "Epoch: 1543 loss_train: 0.1772 acc_train: 0.8998 acc_val: 0.9578\n",
      "Epoch: 1544 loss_train: 0.1938 acc_train: 0.8834 acc_val: 0.9578\n",
      "Epoch: 1545 loss_train: 0.1967 acc_train: 0.8857 acc_val: 0.9578\n",
      "Epoch: 1546 loss_train: 0.2041 acc_train: 0.8857 acc_val: 0.9578\n",
      "Epoch: 1547 loss_train: 0.1995 acc_train: 0.8879 acc_val: 0.9578\n",
      "Epoch: 1548 loss_train: 0.1952 acc_train: 0.8805 acc_val: 0.9578\n",
      "Epoch: 1549 loss_train: 0.1870 acc_train: 0.8834 acc_val: 0.9578\n",
      "Epoch: 1550 loss_train: 0.2113 acc_train: 0.8738 acc_val: 0.9578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1551 loss_train: 0.1748 acc_train: 0.8938 acc_val: 0.9578\n",
      "Epoch: 1552 loss_train: 0.1825 acc_train: 0.8968 acc_val: 0.9578\n",
      "Epoch: 1553 loss_train: 0.1822 acc_train: 0.9027 acc_val: 0.9578\n",
      "Epoch: 1554 loss_train: 0.1772 acc_train: 0.8983 acc_val: 0.9578\n",
      "Epoch: 1555 loss_train: 0.2046 acc_train: 0.8931 acc_val: 0.9578\n",
      "Epoch: 1556 loss_train: 0.1672 acc_train: 0.9065 acc_val: 0.9578\n",
      "Epoch: 1557 loss_train: 0.1939 acc_train: 0.8916 acc_val: 0.9578\n",
      "Epoch: 1558 loss_train: 0.1890 acc_train: 0.8864 acc_val: 0.9578\n",
      "Epoch: 1559 loss_train: 0.1778 acc_train: 0.9005 acc_val: 0.9578\n",
      "Epoch: 1560 loss_train: 0.1917 acc_train: 0.8872 acc_val: 0.9578\n",
      "Epoch: 1561 loss_train: 0.1937 acc_train: 0.8849 acc_val: 0.9578\n",
      "Epoch: 1562 loss_train: 0.1759 acc_train: 0.8886 acc_val: 0.9578\n",
      "Epoch: 1563 loss_train: 0.1912 acc_train: 0.8849 acc_val: 0.9578\n",
      "Epoch: 1564 loss_train: 0.1831 acc_train: 0.8909 acc_val: 0.9578\n",
      "Epoch: 1565 loss_train: 0.1861 acc_train: 0.8968 acc_val: 0.9578\n",
      "Epoch: 1566 loss_train: 0.1595 acc_train: 0.9065 acc_val: 0.9578\n",
      "Epoch: 1567 loss_train: 0.2011 acc_train: 0.8931 acc_val: 0.9578\n",
      "Epoch: 1568 loss_train: 0.1967 acc_train: 0.8790 acc_val: 0.9578\n",
      "Epoch: 1569 loss_train: 0.1723 acc_train: 0.9042 acc_val: 0.9578\n",
      "Epoch: 1570 loss_train: 0.2070 acc_train: 0.8701 acc_val: 0.9578\n",
      "Epoch: 1571 loss_train: 0.1877 acc_train: 0.8931 acc_val: 0.9578\n",
      "Epoch: 1572 loss_train: 0.2028 acc_train: 0.8849 acc_val: 0.9578\n",
      "Epoch: 1573 loss_train: 0.1965 acc_train: 0.8909 acc_val: 0.9578\n",
      "Epoch: 1574 loss_train: 0.1796 acc_train: 0.8924 acc_val: 0.9578\n",
      "Epoch: 1575 loss_train: 0.1838 acc_train: 0.8938 acc_val: 0.9578\n",
      "Epoch: 1576 loss_train: 0.1763 acc_train: 0.8872 acc_val: 0.9578\n",
      "Epoch: 1577 loss_train: 0.1933 acc_train: 0.8849 acc_val: 0.9578\n",
      "Epoch: 1578 loss_train: 0.1884 acc_train: 0.8894 acc_val: 0.9578\n",
      "Epoch: 1579 loss_train: 0.1872 acc_train: 0.8931 acc_val: 0.9578\n",
      "Epoch: 1580 loss_train: 0.2013 acc_train: 0.8849 acc_val: 0.9578\n",
      "Epoch: 1581 loss_train: 0.1707 acc_train: 0.9065 acc_val: 0.9578\n",
      "Epoch: 1582 loss_train: 0.1933 acc_train: 0.8827 acc_val: 0.9578\n",
      "Epoch: 1583 loss_train: 0.1936 acc_train: 0.8805 acc_val: 0.9578\n",
      "Epoch: 1584 loss_train: 0.2049 acc_train: 0.8775 acc_val: 0.9578\n",
      "Epoch: 1585 loss_train: 0.1686 acc_train: 0.8976 acc_val: 0.9578\n",
      "Epoch: 1586 loss_train: 0.1865 acc_train: 0.8894 acc_val: 0.9578\n",
      "Epoch: 1587 loss_train: 0.1617 acc_train: 0.8990 acc_val: 0.9578\n",
      "Epoch: 1588 loss_train: 0.1763 acc_train: 0.8894 acc_val: 0.9578\n",
      "Epoch: 1589 loss_train: 0.1873 acc_train: 0.8864 acc_val: 0.9578\n",
      "Epoch: 1590 loss_train: 0.1760 acc_train: 0.9042 acc_val: 0.9578\n",
      "Epoch: 1591 loss_train: 0.1817 acc_train: 0.8879 acc_val: 0.9578\n",
      "Epoch: 1592 loss_train: 0.1853 acc_train: 0.8961 acc_val: 0.9578\n",
      "Epoch: 1593 loss_train: 0.1716 acc_train: 0.9027 acc_val: 0.9578\n",
      "Epoch: 1594 loss_train: 0.1928 acc_train: 0.8886 acc_val: 0.9578\n",
      "Epoch: 1595 loss_train: 0.1866 acc_train: 0.8961 acc_val: 0.9578\n",
      "Epoch: 1596 loss_train: 0.1728 acc_train: 0.8983 acc_val: 0.9578\n",
      "Epoch: 1597 loss_train: 0.1877 acc_train: 0.8946 acc_val: 0.9578\n",
      "Epoch: 1598 loss_train: 0.1950 acc_train: 0.8894 acc_val: 0.9578\n",
      "Epoch: 1599 loss_train: 0.1802 acc_train: 0.8849 acc_val: 0.9578\n",
      "Epoch: 1600 loss_train: 0.1687 acc_train: 0.8931 acc_val: 0.9578\n",
      "Epoch: 1601 loss_train: 0.1763 acc_train: 0.8961 acc_val: 0.9578\n",
      "Epoch: 1602 loss_train: 0.1845 acc_train: 0.8909 acc_val: 0.9578\n",
      "Epoch: 1603 loss_train: 0.1865 acc_train: 0.8909 acc_val: 0.9578\n",
      "Epoch: 1604 loss_train: 0.1972 acc_train: 0.8834 acc_val: 0.9578\n",
      "Epoch: 1605 loss_train: 0.1879 acc_train: 0.8805 acc_val: 0.9578\n",
      "Epoch: 1606 loss_train: 0.1964 acc_train: 0.8886 acc_val: 0.9578\n",
      "Epoch: 1607 loss_train: 0.2025 acc_train: 0.8864 acc_val: 0.9578\n",
      "Epoch: 1608 loss_train: 0.2007 acc_train: 0.8760 acc_val: 0.9578\n",
      "Epoch: 1609 loss_train: 0.2016 acc_train: 0.8805 acc_val: 0.9578\n",
      "Epoch: 1610 loss_train: 0.1897 acc_train: 0.8894 acc_val: 0.9578\n",
      "Epoch: 1611 loss_train: 0.1936 acc_train: 0.8901 acc_val: 0.9578\n",
      "Epoch: 1612 loss_train: 0.1703 acc_train: 0.8931 acc_val: 0.9578\n",
      "Epoch: 1613 loss_train: 0.1959 acc_train: 0.8782 acc_val: 0.9578\n",
      "Epoch: 1614 loss_train: 0.1909 acc_train: 0.8983 acc_val: 0.9578\n",
      "Epoch: 1615 loss_train: 0.1974 acc_train: 0.8894 acc_val: 0.9578\n",
      "Epoch: 1616 loss_train: 0.1840 acc_train: 0.8924 acc_val: 0.9578\n",
      "Epoch: 1617 loss_train: 0.1850 acc_train: 0.8782 acc_val: 0.9578\n",
      "Epoch: 1618 loss_train: 0.2026 acc_train: 0.8738 acc_val: 0.9578\n",
      "Epoch: 1619 loss_train: 0.1761 acc_train: 0.8983 acc_val: 0.9578\n",
      "Epoch: 1620 loss_train: 0.1823 acc_train: 0.8924 acc_val: 0.9578\n",
      "Epoch: 1621 loss_train: 0.1680 acc_train: 0.9020 acc_val: 0.9578\n",
      "Epoch: 1622 loss_train: 0.1968 acc_train: 0.8834 acc_val: 0.9578\n",
      "Epoch: 1623 loss_train: 0.1772 acc_train: 0.8916 acc_val: 0.9578\n",
      "Epoch: 1624 loss_train: 0.1708 acc_train: 0.8983 acc_val: 0.9578\n",
      "Epoch: 1625 loss_train: 0.1963 acc_train: 0.8872 acc_val: 0.9578\n",
      "Epoch: 1626 loss_train: 0.1904 acc_train: 0.8983 acc_val: 0.9578\n",
      "Epoch: 1627 loss_train: 0.1905 acc_train: 0.8768 acc_val: 0.9578\n",
      "Epoch: 1628 loss_train: 0.1844 acc_train: 0.8938 acc_val: 0.9578\n",
      "Epoch: 1629 loss_train: 0.1663 acc_train: 0.9094 acc_val: 0.9578\n",
      "Epoch: 1630 loss_train: 0.1806 acc_train: 0.8872 acc_val: 0.9578\n",
      "Epoch: 1631 loss_train: 0.1973 acc_train: 0.8909 acc_val: 0.9578\n",
      "Epoch: 1632 loss_train: 0.1937 acc_train: 0.8849 acc_val: 0.9578\n",
      "Epoch: 1633 loss_train: 0.1917 acc_train: 0.8872 acc_val: 0.9578\n",
      "Epoch: 1634 loss_train: 0.1659 acc_train: 0.8909 acc_val: 0.9578\n",
      "Epoch: 1635 loss_train: 0.1799 acc_train: 0.8857 acc_val: 0.9578\n",
      "Epoch: 1636 loss_train: 0.1799 acc_train: 0.8961 acc_val: 0.9578\n",
      "Epoch: 1637 loss_train: 0.1952 acc_train: 0.8775 acc_val: 0.9578\n",
      "Epoch: 1638 loss_train: 0.1891 acc_train: 0.8857 acc_val: 0.9578\n",
      "Epoch: 1639 loss_train: 0.1872 acc_train: 0.8968 acc_val: 0.9578\n",
      "Epoch: 1640 loss_train: 0.1805 acc_train: 0.8990 acc_val: 0.9578\n",
      "Epoch: 1641 loss_train: 0.1773 acc_train: 0.9027 acc_val: 0.9578\n",
      "Epoch: 1642 loss_train: 0.1851 acc_train: 0.9027 acc_val: 0.9578\n",
      "Epoch: 1643 loss_train: 0.1873 acc_train: 0.8909 acc_val: 0.9578\n",
      "Epoch: 1644 loss_train: 0.2015 acc_train: 0.8864 acc_val: 0.9578\n",
      "Epoch: 1645 loss_train: 0.1794 acc_train: 0.8968 acc_val: 0.9578\n",
      "Epoch: 1646 loss_train: 0.1904 acc_train: 0.8894 acc_val: 0.9578\n",
      "Epoch: 1647 loss_train: 0.2182 acc_train: 0.8723 acc_val: 0.9578\n",
      "Epoch: 1648 loss_train: 0.1729 acc_train: 0.8924 acc_val: 0.9578\n",
      "Epoch: 1649 loss_train: 0.1869 acc_train: 0.8938 acc_val: 0.9578\n",
      "Epoch: 1650 loss_train: 0.1568 acc_train: 0.9035 acc_val: 0.9578\n",
      "Epoch: 1651 loss_train: 0.1973 acc_train: 0.8790 acc_val: 0.9578\n",
      "Epoch: 1652 loss_train: 0.2021 acc_train: 0.8879 acc_val: 0.9578\n",
      "Epoch: 1653 loss_train: 0.2062 acc_train: 0.8782 acc_val: 0.9578\n",
      "Epoch: 1654 loss_train: 0.1817 acc_train: 0.8872 acc_val: 0.9578\n",
      "Epoch: 1655 loss_train: 0.1819 acc_train: 0.8983 acc_val: 0.9578\n",
      "Epoch: 1656 loss_train: 0.1824 acc_train: 0.8931 acc_val: 0.9578\n",
      "Epoch: 1657 loss_train: 0.2026 acc_train: 0.8797 acc_val: 0.9578\n",
      "Epoch: 1658 loss_train: 0.1948 acc_train: 0.8753 acc_val: 0.9578\n",
      "Epoch: 1659 loss_train: 0.1977 acc_train: 0.8790 acc_val: 0.9578\n",
      "Epoch: 1660 loss_train: 0.1954 acc_train: 0.8879 acc_val: 0.9578\n",
      "Epoch: 1661 loss_train: 0.1811 acc_train: 0.9013 acc_val: 0.9578\n",
      "Epoch: 1662 loss_train: 0.1683 acc_train: 0.9087 acc_val: 0.9578\n",
      "Epoch: 1663 loss_train: 0.1876 acc_train: 0.8842 acc_val: 0.9578\n",
      "Epoch: 1664 loss_train: 0.1910 acc_train: 0.8857 acc_val: 0.9578\n",
      "Epoch: 1665 loss_train: 0.1889 acc_train: 0.8857 acc_val: 0.9578\n",
      "Epoch: 1666 loss_train: 0.1927 acc_train: 0.8886 acc_val: 0.9578\n",
      "Epoch: 1667 loss_train: 0.1677 acc_train: 0.8998 acc_val: 0.9578\n",
      "Epoch: 1668 loss_train: 0.2020 acc_train: 0.8760 acc_val: 0.9578\n",
      "Epoch: 1669 loss_train: 0.1904 acc_train: 0.8753 acc_val: 0.9578\n",
      "Epoch: 1670 loss_train: 0.1772 acc_train: 0.8976 acc_val: 0.9578\n",
      "Epoch: 1671 loss_train: 0.2082 acc_train: 0.8708 acc_val: 0.9578\n",
      "Epoch: 1672 loss_train: 0.1865 acc_train: 0.8849 acc_val: 0.9578\n",
      "Epoch: 1673 loss_train: 0.2056 acc_train: 0.8760 acc_val: 0.9578\n",
      "Epoch: 1674 loss_train: 0.1905 acc_train: 0.8968 acc_val: 0.9578\n",
      "Epoch: 1675 loss_train: 0.1760 acc_train: 0.8938 acc_val: 0.9578\n",
      "Epoch: 1676 loss_train: 0.1849 acc_train: 0.8909 acc_val: 0.9578\n",
      "Epoch: 1677 loss_train: 0.2152 acc_train: 0.8693 acc_val: 0.9578\n",
      "Epoch: 1678 loss_train: 0.2003 acc_train: 0.8849 acc_val: 0.9578\n",
      "Epoch: 1679 loss_train: 0.1867 acc_train: 0.8946 acc_val: 0.9578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1680 loss_train: 0.1798 acc_train: 0.8849 acc_val: 0.9578\n",
      "Epoch: 1681 loss_train: 0.1909 acc_train: 0.8820 acc_val: 0.9578\n",
      "Epoch: 1682 loss_train: 0.1904 acc_train: 0.8805 acc_val: 0.9578\n",
      "Epoch: 1683 loss_train: 0.1682 acc_train: 0.9042 acc_val: 0.9578\n",
      "Epoch: 1684 loss_train: 0.1894 acc_train: 0.8924 acc_val: 0.9578\n",
      "Epoch: 1685 loss_train: 0.1808 acc_train: 0.9020 acc_val: 0.9578\n",
      "Epoch: 1686 loss_train: 0.1880 acc_train: 0.8924 acc_val: 0.9578\n",
      "Epoch: 1687 loss_train: 0.1850 acc_train: 0.8953 acc_val: 0.9578\n",
      "Epoch: 1688 loss_train: 0.1833 acc_train: 0.8901 acc_val: 0.9578\n",
      "Epoch: 1689 loss_train: 0.1841 acc_train: 0.8990 acc_val: 0.9578\n",
      "Epoch: 1690 loss_train: 0.1911 acc_train: 0.8834 acc_val: 0.9578\n",
      "Epoch: 1691 loss_train: 0.1767 acc_train: 0.8894 acc_val: 0.9578\n",
      "Epoch: 1692 loss_train: 0.1997 acc_train: 0.8812 acc_val: 0.9578\n",
      "Epoch: 1693 loss_train: 0.1933 acc_train: 0.8872 acc_val: 0.9578\n",
      "Epoch: 1694 loss_train: 0.1843 acc_train: 0.8879 acc_val: 0.9578\n",
      "Epoch: 1695 loss_train: 0.1674 acc_train: 0.9035 acc_val: 0.9578\n",
      "Epoch: 1696 loss_train: 0.1940 acc_train: 0.8938 acc_val: 0.9578\n",
      "Epoch: 1697 loss_train: 0.1950 acc_train: 0.8909 acc_val: 0.9578\n",
      "Epoch: 1698 loss_train: 0.1979 acc_train: 0.8842 acc_val: 0.9578\n",
      "Epoch: 1699 loss_train: 0.1720 acc_train: 0.9027 acc_val: 0.9578\n",
      "Epoch: 1700 loss_train: 0.1837 acc_train: 0.8998 acc_val: 0.9578\n",
      "Epoch: 1701 loss_train: 0.1861 acc_train: 0.8894 acc_val: 0.9578\n",
      "Epoch: 1702 loss_train: 0.1807 acc_train: 0.8894 acc_val: 0.9578\n",
      "Epoch: 1703 loss_train: 0.1722 acc_train: 0.9057 acc_val: 0.9578\n",
      "Epoch: 1704 loss_train: 0.1730 acc_train: 0.8909 acc_val: 0.9578\n",
      "Epoch: 1705 loss_train: 0.1931 acc_train: 0.8849 acc_val: 0.9578\n",
      "Epoch: 1706 loss_train: 0.1764 acc_train: 0.8968 acc_val: 0.9578\n",
      "Epoch: 1707 loss_train: 0.2142 acc_train: 0.8708 acc_val: 0.9578\n",
      "Epoch: 1708 loss_train: 0.1831 acc_train: 0.8983 acc_val: 0.9578\n",
      "Epoch: 1709 loss_train: 0.1832 acc_train: 0.8990 acc_val: 0.9578\n",
      "Epoch: 1710 loss_train: 0.1574 acc_train: 0.9057 acc_val: 0.9578\n",
      "Epoch: 1711 loss_train: 0.1714 acc_train: 0.8961 acc_val: 0.9578\n",
      "Epoch: 1712 loss_train: 0.1768 acc_train: 0.8931 acc_val: 0.9578\n",
      "Epoch: 1713 loss_train: 0.1757 acc_train: 0.9005 acc_val: 0.9578\n",
      "Epoch: 1714 loss_train: 0.1676 acc_train: 0.9065 acc_val: 0.9578\n",
      "Epoch: 1715 loss_train: 0.1978 acc_train: 0.8782 acc_val: 0.9578\n",
      "Epoch: 1716 loss_train: 0.1941 acc_train: 0.8849 acc_val: 0.9578\n",
      "Epoch: 1717 loss_train: 0.1869 acc_train: 0.8924 acc_val: 0.9578\n",
      "Epoch: 1718 loss_train: 0.1744 acc_train: 0.8886 acc_val: 0.9578\n",
      "Epoch: 1719 loss_train: 0.1842 acc_train: 0.8849 acc_val: 0.9578\n",
      "Epoch: 1720 loss_train: 0.1904 acc_train: 0.8879 acc_val: 0.9578\n",
      "Epoch: 1721 loss_train: 0.1779 acc_train: 0.8968 acc_val: 0.9578\n",
      "Epoch: 1722 loss_train: 0.1723 acc_train: 0.8968 acc_val: 0.9578\n",
      "Epoch: 1723 loss_train: 0.2060 acc_train: 0.8768 acc_val: 0.9578\n",
      "Epoch: 1724 loss_train: 0.1865 acc_train: 0.8901 acc_val: 0.9578\n",
      "Epoch: 1725 loss_train: 0.1855 acc_train: 0.8909 acc_val: 0.9578\n",
      "Epoch: 1726 loss_train: 0.1779 acc_train: 0.8924 acc_val: 0.9578\n",
      "Epoch: 1727 loss_train: 0.1912 acc_train: 0.8901 acc_val: 0.9578\n",
      "Epoch: 1728 loss_train: 0.1875 acc_train: 0.8849 acc_val: 0.9578\n",
      "Epoch: 1729 loss_train: 0.1701 acc_train: 0.9050 acc_val: 0.9578\n",
      "Epoch: 1730 loss_train: 0.1902 acc_train: 0.8790 acc_val: 0.9578\n",
      "Epoch: 1731 loss_train: 0.1858 acc_train: 0.8901 acc_val: 0.9578\n",
      "Epoch: 1732 loss_train: 0.1746 acc_train: 0.8931 acc_val: 0.9578\n",
      "Epoch: 1733 loss_train: 0.1804 acc_train: 0.8938 acc_val: 0.9578\n",
      "Epoch: 1734 loss_train: 0.1445 acc_train: 0.9176 acc_val: 0.9578\n",
      "Epoch: 1735 loss_train: 0.1970 acc_train: 0.8842 acc_val: 0.9578\n",
      "Epoch: 1736 loss_train: 0.2005 acc_train: 0.8820 acc_val: 0.9578\n",
      "Epoch: 1737 loss_train: 0.1867 acc_train: 0.8924 acc_val: 0.9578\n",
      "Epoch: 1738 loss_train: 0.1719 acc_train: 0.8983 acc_val: 0.9578\n",
      "Epoch: 1739 loss_train: 0.1794 acc_train: 0.9027 acc_val: 0.9578\n",
      "Epoch: 1740 loss_train: 0.1853 acc_train: 0.8916 acc_val: 0.9578\n",
      "Epoch: 1741 loss_train: 0.1734 acc_train: 0.8990 acc_val: 0.9578\n",
      "Epoch: 1742 loss_train: 0.1913 acc_train: 0.8849 acc_val: 0.9578\n",
      "Epoch: 1743 loss_train: 0.2032 acc_train: 0.8820 acc_val: 0.9578\n",
      "Epoch: 1744 loss_train: 0.1818 acc_train: 0.9013 acc_val: 0.9578\n",
      "Epoch: 1745 loss_train: 0.1925 acc_train: 0.8842 acc_val: 0.9578\n",
      "Epoch: 1746 loss_train: 0.1872 acc_train: 0.8834 acc_val: 0.9578\n",
      "Epoch: 1747 loss_train: 0.1639 acc_train: 0.9020 acc_val: 0.9578\n",
      "Epoch: 1748 loss_train: 0.1869 acc_train: 0.8976 acc_val: 0.9578\n",
      "Epoch: 1749 loss_train: 0.1753 acc_train: 0.8968 acc_val: 0.9578\n",
      "Epoch: 1750 loss_train: 0.1903 acc_train: 0.8931 acc_val: 0.9578\n",
      "Epoch: 1751 loss_train: 0.1819 acc_train: 0.8901 acc_val: 0.9578\n",
      "Epoch: 1752 loss_train: 0.1899 acc_train: 0.8872 acc_val: 0.9578\n",
      "Epoch: 1753 loss_train: 0.1949 acc_train: 0.8768 acc_val: 0.9578\n",
      "Epoch: 1754 loss_train: 0.1679 acc_train: 0.8976 acc_val: 0.9578\n",
      "Epoch: 1755 loss_train: 0.1743 acc_train: 0.8931 acc_val: 0.9578\n",
      "Epoch: 1756 loss_train: 0.1912 acc_train: 0.8872 acc_val: 0.9578\n",
      "Epoch: 1757 loss_train: 0.1791 acc_train: 0.8968 acc_val: 0.9578\n",
      "Epoch: 1758 loss_train: 0.2084 acc_train: 0.8768 acc_val: 0.9578\n",
      "Epoch: 1759 loss_train: 0.1753 acc_train: 0.8983 acc_val: 0.9578\n",
      "Epoch: 1760 loss_train: 0.1842 acc_train: 0.8931 acc_val: 0.9578\n",
      "Epoch: 1761 loss_train: 0.1813 acc_train: 0.8834 acc_val: 0.9578\n",
      "Epoch: 1762 loss_train: 0.1705 acc_train: 0.8931 acc_val: 0.9578\n",
      "Epoch: 1763 loss_train: 0.1719 acc_train: 0.9005 acc_val: 0.9578\n",
      "Epoch: 1764 loss_train: 0.1942 acc_train: 0.8879 acc_val: 0.9578\n",
      "Epoch: 1765 loss_train: 0.1686 acc_train: 0.9005 acc_val: 0.9578\n",
      "Epoch: 1766 loss_train: 0.1924 acc_train: 0.8775 acc_val: 0.9578\n",
      "Epoch: 1767 loss_train: 0.1923 acc_train: 0.8879 acc_val: 0.9578\n",
      "Epoch: 1768 loss_train: 0.2002 acc_train: 0.8842 acc_val: 0.9578\n",
      "Epoch: 1769 loss_train: 0.1753 acc_train: 0.8968 acc_val: 0.9578\n",
      "Epoch: 1770 loss_train: 0.1896 acc_train: 0.8864 acc_val: 0.9578\n",
      "Epoch: 1771 loss_train: 0.1911 acc_train: 0.8857 acc_val: 0.9578\n",
      "Epoch: 1772 loss_train: 0.1642 acc_train: 0.9087 acc_val: 0.9578\n",
      "Epoch: 1773 loss_train: 0.1899 acc_train: 0.8894 acc_val: 0.9578\n",
      "Epoch: 1774 loss_train: 0.1801 acc_train: 0.9005 acc_val: 0.9578\n",
      "Epoch: 1775 loss_train: 0.1850 acc_train: 0.8901 acc_val: 0.9578\n",
      "Epoch: 1776 loss_train: 0.1789 acc_train: 0.8968 acc_val: 0.9578\n",
      "Epoch: 1777 loss_train: 0.2015 acc_train: 0.8790 acc_val: 0.9578\n",
      "Epoch: 1778 loss_train: 0.1907 acc_train: 0.8849 acc_val: 0.9578\n",
      "Epoch: 1779 loss_train: 0.1835 acc_train: 0.8782 acc_val: 0.9578\n",
      "Epoch: 1780 loss_train: 0.1890 acc_train: 0.8924 acc_val: 0.9578\n",
      "Epoch: 1781 loss_train: 0.1955 acc_train: 0.8901 acc_val: 0.9578\n",
      "Epoch: 1782 loss_train: 0.1749 acc_train: 0.9065 acc_val: 0.9578\n",
      "Epoch: 1783 loss_train: 0.1791 acc_train: 0.8872 acc_val: 0.9578\n",
      "Epoch: 1784 loss_train: 0.1529 acc_train: 0.9146 acc_val: 0.9578\n",
      "Epoch: 1785 loss_train: 0.1791 acc_train: 0.8901 acc_val: 0.9578\n",
      "Epoch: 1786 loss_train: 0.1748 acc_train: 0.8938 acc_val: 0.9578\n",
      "Epoch: 1787 loss_train: 0.1763 acc_train: 0.8931 acc_val: 0.9578\n",
      "Epoch: 1788 loss_train: 0.1801 acc_train: 0.8894 acc_val: 0.9578\n",
      "Epoch: 1789 loss_train: 0.2030 acc_train: 0.8782 acc_val: 0.9578\n",
      "Epoch: 1790 loss_train: 0.1920 acc_train: 0.8909 acc_val: 0.9578\n",
      "Epoch: 1791 loss_train: 0.1751 acc_train: 0.9013 acc_val: 0.9578\n",
      "Epoch: 1792 loss_train: 0.1812 acc_train: 0.8916 acc_val: 0.9578\n",
      "Epoch: 1793 loss_train: 0.1835 acc_train: 0.8946 acc_val: 0.9578\n",
      "Epoch: 1794 loss_train: 0.1896 acc_train: 0.8842 acc_val: 0.9578\n",
      "Epoch: 1795 loss_train: 0.1957 acc_train: 0.8916 acc_val: 0.9578\n",
      "Epoch: 1796 loss_train: 0.1856 acc_train: 0.8909 acc_val: 0.9578\n",
      "Epoch: 1797 loss_train: 0.1748 acc_train: 0.8916 acc_val: 0.9578\n",
      "Epoch: 1798 loss_train: 0.1696 acc_train: 0.9020 acc_val: 0.9578\n",
      "Epoch: 1799 loss_train: 0.2112 acc_train: 0.8857 acc_val: 0.9578\n",
      "Epoch: 1800 loss_train: 0.1736 acc_train: 0.9027 acc_val: 0.9578\n",
      "Epoch: 1801 loss_train: 0.1807 acc_train: 0.8946 acc_val: 0.9578\n",
      "Epoch: 1802 loss_train: 0.1902 acc_train: 0.8864 acc_val: 0.9578\n",
      "Epoch: 1803 loss_train: 0.1783 acc_train: 0.8968 acc_val: 0.9578\n",
      "Epoch: 1804 loss_train: 0.1755 acc_train: 0.8931 acc_val: 0.9578\n",
      "Epoch: 1805 loss_train: 0.1888 acc_train: 0.8924 acc_val: 0.9578\n",
      "Epoch: 1806 loss_train: 0.1847 acc_train: 0.8872 acc_val: 0.9578\n",
      "Epoch: 1807 loss_train: 0.1870 acc_train: 0.8849 acc_val: 0.9578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1808 loss_train: 0.1800 acc_train: 0.8946 acc_val: 0.9578\n",
      "Epoch: 1809 loss_train: 0.1939 acc_train: 0.8886 acc_val: 0.9578\n",
      "Epoch: 1810 loss_train: 0.1842 acc_train: 0.8953 acc_val: 0.9578\n",
      "Epoch: 1811 loss_train: 0.1754 acc_train: 0.8968 acc_val: 0.9578\n",
      "Epoch: 1812 loss_train: 0.1867 acc_train: 0.8842 acc_val: 0.9578\n",
      "Epoch: 1813 loss_train: 0.2001 acc_train: 0.8812 acc_val: 0.9578\n",
      "Epoch: 1814 loss_train: 0.1808 acc_train: 0.8968 acc_val: 0.9578\n",
      "Epoch: 1815 loss_train: 0.1937 acc_train: 0.8872 acc_val: 0.9578\n",
      "Epoch: 1816 loss_train: 0.2002 acc_train: 0.8857 acc_val: 0.9578\n",
      "Epoch: 1817 loss_train: 0.1867 acc_train: 0.8931 acc_val: 0.9578\n",
      "Epoch: 1818 loss_train: 0.1829 acc_train: 0.8894 acc_val: 0.9578\n",
      "Epoch: 1819 loss_train: 0.1873 acc_train: 0.8797 acc_val: 0.9578\n",
      "Epoch: 1820 loss_train: 0.1696 acc_train: 0.9005 acc_val: 0.9578\n",
      "Epoch: 1821 loss_train: 0.1813 acc_train: 0.8990 acc_val: 0.9578\n",
      "Epoch: 1822 loss_train: 0.1840 acc_train: 0.8916 acc_val: 0.9578\n",
      "Epoch: 1823 loss_train: 0.1740 acc_train: 0.8998 acc_val: 0.9578\n",
      "Epoch: 1824 loss_train: 0.1824 acc_train: 0.8990 acc_val: 0.9578\n",
      "Epoch: 1825 loss_train: 0.1843 acc_train: 0.9027 acc_val: 0.9578\n",
      "Epoch: 1826 loss_train: 0.1938 acc_train: 0.8790 acc_val: 0.9578\n",
      "Epoch: 1827 loss_train: 0.1866 acc_train: 0.8886 acc_val: 0.9578\n",
      "Epoch: 1828 loss_train: 0.1900 acc_train: 0.8834 acc_val: 0.9578\n",
      "Epoch: 1829 loss_train: 0.1955 acc_train: 0.8805 acc_val: 0.9578\n",
      "Epoch: 1830 loss_train: 0.1857 acc_train: 0.8857 acc_val: 0.9578\n",
      "Epoch: 1831 loss_train: 0.1679 acc_train: 0.8946 acc_val: 0.9578\n",
      "Epoch: 1832 loss_train: 0.1821 acc_train: 0.8924 acc_val: 0.9578\n",
      "Epoch: 1833 loss_train: 0.1984 acc_train: 0.8894 acc_val: 0.9578\n",
      "Epoch: 1834 loss_train: 0.1857 acc_train: 0.8857 acc_val: 0.9578\n",
      "Epoch: 1835 loss_train: 0.2000 acc_train: 0.8938 acc_val: 0.9578\n",
      "Epoch: 1836 loss_train: 0.1951 acc_train: 0.8916 acc_val: 0.9578\n",
      "Epoch: 1837 loss_train: 0.1836 acc_train: 0.8924 acc_val: 0.9578\n",
      "Epoch: 1838 loss_train: 0.1904 acc_train: 0.8872 acc_val: 0.9578\n",
      "Epoch: 1839 loss_train: 0.1860 acc_train: 0.8901 acc_val: 0.9578\n",
      "Epoch: 1840 loss_train: 0.1779 acc_train: 0.8901 acc_val: 0.9578\n",
      "Epoch: 1841 loss_train: 0.1811 acc_train: 0.8864 acc_val: 0.9578\n",
      "Epoch: 1842 loss_train: 0.1847 acc_train: 0.8834 acc_val: 0.9578\n",
      "Epoch: 1843 loss_train: 0.1766 acc_train: 0.8946 acc_val: 0.9578\n",
      "Epoch: 1844 loss_train: 0.1958 acc_train: 0.8894 acc_val: 0.9578\n",
      "Epoch: 1845 loss_train: 0.1833 acc_train: 0.8968 acc_val: 0.9578\n",
      "Epoch: 1846 loss_train: 0.1869 acc_train: 0.8842 acc_val: 0.9578\n",
      "Epoch: 1847 loss_train: 0.1758 acc_train: 0.8931 acc_val: 0.9578\n",
      "Epoch: 1848 loss_train: 0.1813 acc_train: 0.8976 acc_val: 0.9578\n",
      "Epoch: 1849 loss_train: 0.1936 acc_train: 0.8820 acc_val: 0.9578\n",
      "Epoch: 1850 loss_train: 0.1874 acc_train: 0.8931 acc_val: 0.9578\n",
      "Epoch: 1851 loss_train: 0.1888 acc_train: 0.8931 acc_val: 0.9578\n",
      "Epoch: 1852 loss_train: 0.1846 acc_train: 0.8931 acc_val: 0.9578\n",
      "Epoch: 1853 loss_train: 0.1762 acc_train: 0.8976 acc_val: 0.9578\n",
      "Epoch: 1854 loss_train: 0.1687 acc_train: 0.9013 acc_val: 0.9578\n",
      "Epoch: 1855 loss_train: 0.1871 acc_train: 0.8805 acc_val: 0.9578\n",
      "Epoch: 1856 loss_train: 0.2061 acc_train: 0.8745 acc_val: 0.9578\n",
      "Epoch: 1857 loss_train: 0.1882 acc_train: 0.8938 acc_val: 0.9578\n",
      "Epoch: 1858 loss_train: 0.1799 acc_train: 0.8976 acc_val: 0.9578\n",
      "Epoch: 1859 loss_train: 0.1761 acc_train: 0.8990 acc_val: 0.9578\n",
      "Epoch: 1860 loss_train: 0.1887 acc_train: 0.8909 acc_val: 0.9578\n",
      "Epoch: 1861 loss_train: 0.1818 acc_train: 0.8879 acc_val: 0.9578\n",
      "Epoch: 1862 loss_train: 0.1960 acc_train: 0.8849 acc_val: 0.9578\n",
      "Epoch: 1863 loss_train: 0.1979 acc_train: 0.8812 acc_val: 0.9578\n",
      "Epoch: 1864 loss_train: 0.1737 acc_train: 0.8976 acc_val: 0.9578\n",
      "Epoch: 1865 loss_train: 0.1994 acc_train: 0.8790 acc_val: 0.9578\n",
      "Epoch: 1866 loss_train: 0.1818 acc_train: 0.8953 acc_val: 0.9578\n",
      "Epoch: 1867 loss_train: 0.1651 acc_train: 0.9042 acc_val: 0.9578\n",
      "Epoch: 1868 loss_train: 0.1879 acc_train: 0.8872 acc_val: 0.9578\n",
      "Epoch: 1869 loss_train: 0.1883 acc_train: 0.8953 acc_val: 0.9578\n",
      "Epoch: 1870 loss_train: 0.1812 acc_train: 0.8924 acc_val: 0.9600\n",
      "Epoch: 1871 loss_train: 0.7068 acc_train: 0.8968 acc_val: 0.9578\n",
      "Epoch: 1872 loss_train: 0.1774 acc_train: 0.8976 acc_val: 0.9600\n",
      "Epoch: 1873 loss_train: 0.2713 acc_train: 0.8797 acc_val: 0.9600\n",
      "Epoch: 1874 loss_train: 0.1667 acc_train: 0.8983 acc_val: 0.9578\n",
      "Epoch: 1875 loss_train: 0.1996 acc_train: 0.8775 acc_val: 0.9600\n",
      "Epoch: 1876 loss_train: 0.1872 acc_train: 0.8901 acc_val: 0.9600\n",
      "Epoch: 1877 loss_train: 0.4731 acc_train: 0.9131 acc_val: 0.9578\n",
      "Epoch: 1878 loss_train: 0.1684 acc_train: 0.9027 acc_val: 0.9600\n",
      "Epoch: 1879 loss_train: 0.1713 acc_train: 0.8938 acc_val: 0.9600\n",
      "Epoch: 1880 loss_train: 0.9529 acc_train: 0.8812 acc_val: 0.9600\n",
      "Epoch: 1881 loss_train: 0.1895 acc_train: 0.8909 acc_val: 0.9600\n",
      "Epoch: 1882 loss_train: 0.1838 acc_train: 0.8901 acc_val: 0.9578\n",
      "Epoch: 1883 loss_train: 0.4986 acc_train: 0.8768 acc_val: 0.9622\n",
      "Epoch: 1884 loss_train: 0.3729 acc_train: 0.8916 acc_val: 0.9600\n",
      "Epoch: 1885 loss_train: 1.2431 acc_train: 0.8968 acc_val: 0.9578\n",
      "Epoch: 1886 loss_train: 0.7041 acc_train: 0.8753 acc_val: 0.9578\n",
      "Epoch: 1887 loss_train: 4.9268 acc_train: 0.8842 acc_val: 0.9600\n",
      "Epoch: 1888 loss_train: 3.0234 acc_train: 0.8820 acc_val: 0.9622\n",
      "Epoch: 1889 loss_train: 32.1409 acc_train: 0.8857 acc_val: 0.9467\n",
      "Epoch: 1890 loss_train: 102.7219 acc_train: 0.8760 acc_val: 0.9533\n",
      "Epoch: 1891 loss_train: 128.4830 acc_train: 0.8649 acc_val: 0.9289\n",
      "Epoch: 1892 loss_train: 500.5900 acc_train: 0.8270 acc_val: 0.9067\n",
      "Epoch: 1893 loss_train: 782.9158 acc_train: 0.8137 acc_val: 0.9022\n",
      "Epoch: 1894 loss_train: 1197.6558 acc_train: 0.7988 acc_val: 0.8867\n",
      "Epoch: 1895 loss_train: 1601.0331 acc_train: 0.7884 acc_val: 0.9000\n",
      "Epoch: 1896 loss_train: 846.7803 acc_train: 0.8151 acc_val: 0.9378\n",
      "Epoch: 1897 loss_train: 416.2759 acc_train: 0.8411 acc_val: 0.7422\n",
      "Epoch: 1898 loss_train: 4343.9644 acc_train: 0.6793 acc_val: 0.8667\n",
      "Epoch: 1899 loss_train: 3908.7256 acc_train: 0.7342 acc_val: 0.8511\n",
      "Epoch: 1900 loss_train: 2025.1251 acc_train: 0.7528 acc_val: 0.6089\n",
      "Epoch: 1901 loss_train: 12018.2148 acc_train: 0.5798 acc_val: 0.6333\n",
      "Epoch: 1902 loss_train: 17189.7324 acc_train: 0.5991 acc_val: 0.7933\n",
      "Epoch: 1903 loss_train: 15659.4775 acc_train: 0.6719 acc_val: 0.8822\n",
      "Epoch: 1904 loss_train: 7643.8013 acc_train: 0.7424 acc_val: 0.7378\n",
      "Epoch: 1905 loss_train: 19857.0684 acc_train: 0.6258 acc_val: 0.7822\n",
      "Epoch: 1906 loss_train: 12758.1680 acc_train: 0.7134 acc_val: 0.7000\n",
      "Epoch: 1907 loss_train: 20055.8301 acc_train: 0.6437 acc_val: 0.9222\n",
      "Epoch: 1908 loss_train: 8314.1826 acc_train: 0.7572 acc_val: 0.9244\n",
      "Epoch: 1909 loss_train: 5520.5610 acc_train: 0.7847 acc_val: 0.8756\n",
      "Epoch: 1910 loss_train: 9155.1289 acc_train: 0.7506 acc_val: 0.8933\n",
      "Epoch: 1911 loss_train: 9341.2607 acc_train: 0.7528 acc_val: 0.9600\n",
      "Epoch: 1912 loss_train: 4541.9155 acc_train: 0.7803 acc_val: 0.9222\n",
      "Epoch: 1913 loss_train: 4616.6396 acc_train: 0.7958 acc_val: 0.9178\n",
      "Epoch: 1914 loss_train: 3149.6448 acc_train: 0.7944 acc_val: 0.9178\n",
      "Epoch: 1915 loss_train: 2922.5298 acc_train: 0.8077 acc_val: 0.9156\n",
      "Epoch: 1916 loss_train: 2996.3269 acc_train: 0.7877 acc_val: 0.9467\n",
      "Epoch: 1917 loss_train: 1843.5358 acc_train: 0.8315 acc_val: 0.9511\n",
      "Epoch: 1918 loss_train: 1729.1173 acc_train: 0.8270 acc_val: 0.9511\n",
      "Epoch: 1919 loss_train: 1544.1973 acc_train: 0.8337 acc_val: 0.9511\n",
      "Epoch: 1920 loss_train: 1407.3423 acc_train: 0.8419 acc_val: 0.9622\n",
      "Epoch: 1921 loss_train: 1175.4753 acc_train: 0.8523 acc_val: 0.9600\n",
      "Epoch: 1922 loss_train: 1131.3767 acc_train: 0.8537 acc_val: 0.9400\n",
      "Epoch: 1923 loss_train: 1352.0992 acc_train: 0.8627 acc_val: 0.9622\n",
      "Epoch: 1924 loss_train: 903.8902 acc_train: 0.8471 acc_val: 0.9711\n",
      "Epoch: 1925 loss_train: 809.3904 acc_train: 0.8708 acc_val: 0.9711\n",
      "Epoch: 1926 loss_train: 830.0990 acc_train: 0.8604 acc_val: 0.9689\n",
      "Epoch: 1927 loss_train: 660.6990 acc_train: 0.8649 acc_val: 0.9689\n",
      "Epoch: 1928 loss_train: 686.9652 acc_train: 0.8679 acc_val: 0.9667\n",
      "Epoch: 1929 loss_train: 735.0512 acc_train: 0.8768 acc_val: 0.9644\n",
      "Epoch: 1930 loss_train: 450.8770 acc_train: 0.8508 acc_val: 0.9733\n",
      "Epoch: 1931 loss_train: 416.3586 acc_train: 0.8812 acc_val: 0.9756\n",
      "Epoch: 1932 loss_train: 507.6688 acc_train: 0.8768 acc_val: 0.9778\n",
      "Epoch: 1933 loss_train: 359.5742 acc_train: 0.8805 acc_val: 0.9778\n",
      "Epoch: 1934 loss_train: 350.6251 acc_train: 0.8738 acc_val: 0.9800\n",
      "Epoch: 1935 loss_train: 430.0720 acc_train: 0.8716 acc_val: 0.9800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1936 loss_train: 331.9471 acc_train: 0.8760 acc_val: 0.9778\n",
      "Epoch: 1937 loss_train: 314.9981 acc_train: 0.8924 acc_val: 0.9733\n",
      "Epoch: 1938 loss_train: 390.9150 acc_train: 0.8775 acc_val: 0.9711\n",
      "Epoch: 1939 loss_train: 151.9386 acc_train: 0.8679 acc_val: 0.9689\n",
      "Epoch: 1940 loss_train: 265.9167 acc_train: 0.8857 acc_val: 0.9689\n",
      "Epoch: 1941 loss_train: 294.5642 acc_train: 0.8805 acc_val: 0.9689\n",
      "Epoch: 1942 loss_train: 259.5828 acc_train: 0.8872 acc_val: 0.9711\n",
      "Epoch: 1943 loss_train: 209.1682 acc_train: 0.8656 acc_val: 0.9756\n",
      "Epoch: 1944 loss_train: 147.4005 acc_train: 0.8797 acc_val: 0.9756\n",
      "Epoch: 1945 loss_train: 195.0806 acc_train: 0.8790 acc_val: 0.9756\n",
      "Epoch: 1946 loss_train: 210.5369 acc_train: 0.8820 acc_val: 0.9756\n",
      "Epoch: 1947 loss_train: 106.0725 acc_train: 0.8894 acc_val: 0.9778\n",
      "Epoch: 1948 loss_train: 124.4314 acc_train: 0.8745 acc_val: 0.9800\n",
      "Epoch: 1949 loss_train: 114.1474 acc_train: 0.8745 acc_val: 0.9778\n",
      "Epoch: 1950 loss_train: 45.0318 acc_train: 0.8916 acc_val: 0.9778\n",
      "Epoch: 1951 loss_train: 32.5667 acc_train: 0.9005 acc_val: 0.9756\n",
      "Epoch: 1952 loss_train: 58.1930 acc_train: 0.8768 acc_val: 0.9756\n",
      "Epoch: 1953 loss_train: 23.4340 acc_train: 0.8916 acc_val: 0.9756\n",
      "Epoch: 1954 loss_train: 62.9173 acc_train: 0.8849 acc_val: 0.9778\n",
      "Epoch: 1955 loss_train: 54.8117 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 1956 loss_train: 24.8004 acc_train: 0.8879 acc_val: 0.9778\n",
      "Epoch: 1957 loss_train: 84.7866 acc_train: 0.8849 acc_val: 0.9756\n",
      "Epoch: 1958 loss_train: 76.7173 acc_train: 0.8894 acc_val: 0.9778\n",
      "Epoch: 1959 loss_train: 40.1853 acc_train: 0.8872 acc_val: 0.9778\n",
      "Epoch: 1960 loss_train: 12.7314 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 1961 loss_train: 27.0558 acc_train: 0.8879 acc_val: 0.9733\n",
      "Epoch: 1962 loss_train: 21.3227 acc_train: 0.8879 acc_val: 0.9733\n",
      "Epoch: 1963 loss_train: 97.1797 acc_train: 0.8693 acc_val: 0.9733\n",
      "Epoch: 1964 loss_train: 16.0689 acc_train: 0.8701 acc_val: 0.9733\n",
      "Epoch: 1965 loss_train: 78.6162 acc_train: 0.8879 acc_val: 0.9733\n",
      "Epoch: 1966 loss_train: 27.8943 acc_train: 0.8983 acc_val: 0.9756\n",
      "Epoch: 1967 loss_train: 36.1695 acc_train: 0.8820 acc_val: 0.9800\n",
      "Epoch: 1968 loss_train: 77.2753 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 1969 loss_train: 12.0978 acc_train: 0.9013 acc_val: 0.9756\n",
      "Epoch: 1970 loss_train: 8.1933 acc_train: 0.8909 acc_val: 0.9711\n",
      "Epoch: 1971 loss_train: 6.2641 acc_train: 0.8731 acc_val: 0.9689\n",
      "Epoch: 1972 loss_train: 10.6506 acc_train: 0.8820 acc_val: 0.9756\n",
      "Epoch: 1973 loss_train: 21.1066 acc_train: 0.8805 acc_val: 0.9756\n",
      "Epoch: 1974 loss_train: 25.6751 acc_train: 0.8812 acc_val: 0.9756\n",
      "Epoch: 1975 loss_train: 15.7527 acc_train: 0.8931 acc_val: 0.9778\n",
      "Epoch: 1976 loss_train: 47.4169 acc_train: 0.8723 acc_val: 0.9756\n",
      "Epoch: 1977 loss_train: 10.0962 acc_train: 0.8901 acc_val: 0.9756\n",
      "Epoch: 1978 loss_train: 9.9016 acc_train: 0.8849 acc_val: 0.9756\n",
      "Epoch: 1979 loss_train: 34.3387 acc_train: 0.8857 acc_val: 0.9756\n",
      "Epoch: 1980 loss_train: 27.7051 acc_train: 0.8872 acc_val: 0.9733\n",
      "Epoch: 1981 loss_train: 56.5999 acc_train: 0.9057 acc_val: 0.9733\n",
      "Epoch: 1982 loss_train: 26.7027 acc_train: 0.8857 acc_val: 0.9778\n",
      "Epoch: 1983 loss_train: 25.9136 acc_train: 0.8953 acc_val: 0.9778\n",
      "Epoch: 1984 loss_train: 11.1028 acc_train: 0.8805 acc_val: 0.9756\n",
      "Epoch: 1985 loss_train: 11.0041 acc_train: 0.8775 acc_val: 0.9778\n",
      "Epoch: 1986 loss_train: 16.8072 acc_train: 0.8753 acc_val: 0.9778\n",
      "Epoch: 1987 loss_train: 13.1768 acc_train: 0.8834 acc_val: 0.9756\n",
      "Epoch: 1988 loss_train: 35.0737 acc_train: 0.8938 acc_val: 0.9756\n",
      "Epoch: 1989 loss_train: 8.4702 acc_train: 0.8760 acc_val: 0.9756\n",
      "Epoch: 1990 loss_train: 23.0891 acc_train: 0.8812 acc_val: 0.9756\n",
      "Epoch: 1991 loss_train: 16.8991 acc_train: 0.8857 acc_val: 0.9756\n",
      "Epoch: 1992 loss_train: 28.7015 acc_train: 0.8872 acc_val: 0.9756\n",
      "Epoch: 1993 loss_train: 2.1797 acc_train: 0.8901 acc_val: 0.9778\n",
      "Epoch: 1994 loss_train: 10.2286 acc_train: 0.9020 acc_val: 0.9756\n",
      "Epoch: 1995 loss_train: 3.5627 acc_train: 0.8894 acc_val: 0.9756\n",
      "Epoch: 1996 loss_train: 2.2061 acc_train: 0.8864 acc_val: 0.9756\n",
      "Epoch: 1997 loss_train: 0.2018 acc_train: 0.8849 acc_val: 0.9756\n",
      "Epoch: 1998 loss_train: 21.0726 acc_train: 0.8998 acc_val: 0.9756\n",
      "Epoch: 1999 loss_train: 5.9995 acc_train: 0.8797 acc_val: 0.9756\n",
      "Epoch: 2000 loss_train: 7.5197 acc_train: 0.8842 acc_val: 0.9800\n",
      "Epoch: 2001 loss_train: 9.1961 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 2002 loss_train: 3.5502 acc_train: 0.8886 acc_val: 0.9800\n",
      "Epoch: 2003 loss_train: 1.2250 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 2004 loss_train: 0.1994 acc_train: 0.8842 acc_val: 0.9778\n",
      "Epoch: 2005 loss_train: 1.6449 acc_train: 0.8968 acc_val: 0.9778\n",
      "Epoch: 2006 loss_train: 20.1718 acc_train: 0.8790 acc_val: 0.9778\n",
      "Epoch: 2007 loss_train: 12.1110 acc_train: 0.8879 acc_val: 0.9778\n",
      "Epoch: 2008 loss_train: 0.1746 acc_train: 0.8938 acc_val: 0.9778\n",
      "Epoch: 2009 loss_train: 0.1770 acc_train: 0.8983 acc_val: 0.9778\n",
      "Epoch: 2010 loss_train: 9.3402 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 2011 loss_train: 0.2066 acc_train: 0.8864 acc_val: 0.9800\n",
      "Epoch: 2012 loss_train: 6.5450 acc_train: 0.8983 acc_val: 0.9800\n",
      "Epoch: 2013 loss_train: 3.9067 acc_train: 0.8953 acc_val: 0.9756\n",
      "Epoch: 2014 loss_train: 8.4241 acc_train: 0.8946 acc_val: 0.9756\n",
      "Epoch: 2015 loss_train: 1.4393 acc_train: 0.8805 acc_val: 0.9756\n",
      "Epoch: 2016 loss_train: 0.8439 acc_train: 0.8938 acc_val: 0.9756\n",
      "Epoch: 2017 loss_train: 10.5412 acc_train: 0.8998 acc_val: 0.9756\n",
      "Epoch: 2018 loss_train: 2.1021 acc_train: 0.9072 acc_val: 0.9778\n",
      "Epoch: 2019 loss_train: 2.9775 acc_train: 0.8842 acc_val: 0.9800\n",
      "Epoch: 2020 loss_train: 4.6807 acc_train: 0.8961 acc_val: 0.9800\n",
      "Epoch: 2021 loss_train: 5.7334 acc_train: 0.8827 acc_val: 0.9778\n",
      "Epoch: 2022 loss_train: 8.0008 acc_train: 0.8864 acc_val: 0.9800\n",
      "Epoch: 2023 loss_train: 4.2408 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 2024 loss_train: 2.1264 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 2025 loss_train: 4.2663 acc_train: 0.9050 acc_val: 0.9800\n",
      "Epoch: 2026 loss_train: 2.7128 acc_train: 0.8961 acc_val: 0.9778\n",
      "Epoch: 2027 loss_train: 0.8234 acc_train: 0.8753 acc_val: 0.9778\n",
      "Epoch: 2028 loss_train: 0.6883 acc_train: 0.8857 acc_val: 0.9778\n",
      "Epoch: 2029 loss_train: 1.0171 acc_train: 0.8872 acc_val: 0.9778\n",
      "Epoch: 2030 loss_train: 0.1858 acc_train: 0.8872 acc_val: 0.9778\n",
      "Epoch: 2031 loss_train: 0.1845 acc_train: 0.8894 acc_val: 0.9778\n",
      "Epoch: 2032 loss_train: 0.1832 acc_train: 0.8968 acc_val: 0.9778\n",
      "Epoch: 2033 loss_train: 1.1268 acc_train: 0.9005 acc_val: 0.9778\n",
      "Epoch: 2034 loss_train: 0.2910 acc_train: 0.9020 acc_val: 0.9778\n",
      "Epoch: 2035 loss_train: 0.5014 acc_train: 0.8775 acc_val: 0.9778\n",
      "Epoch: 2036 loss_train: 0.1763 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 2037 loss_train: 0.1769 acc_train: 0.8968 acc_val: 0.9800\n",
      "Epoch: 2038 loss_train: 0.1785 acc_train: 0.8983 acc_val: 0.9800\n",
      "Epoch: 2039 loss_train: 0.7854 acc_train: 0.8864 acc_val: 0.9800\n",
      "Epoch: 2040 loss_train: 1.0944 acc_train: 0.8990 acc_val: 0.9800\n",
      "Epoch: 2041 loss_train: 0.1920 acc_train: 0.8983 acc_val: 0.9778\n",
      "Epoch: 2042 loss_train: 0.2092 acc_train: 0.8842 acc_val: 0.9778\n",
      "Epoch: 2043 loss_train: 6.5032 acc_train: 0.8812 acc_val: 0.9778\n",
      "Epoch: 2044 loss_train: 0.1706 acc_train: 0.9005 acc_val: 0.9800\n",
      "Epoch: 2045 loss_train: 1.7171 acc_train: 0.9020 acc_val: 0.9800\n",
      "Epoch: 2046 loss_train: 2.0346 acc_train: 0.8983 acc_val: 0.9800\n",
      "Epoch: 2047 loss_train: 1.8845 acc_train: 0.8998 acc_val: 0.9800\n",
      "Epoch: 2048 loss_train: 0.1825 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 2049 loss_train: 0.1895 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 2050 loss_train: 0.1838 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 2051 loss_train: 2.2663 acc_train: 0.8953 acc_val: 0.9800\n",
      "Epoch: 2052 loss_train: 0.6404 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 2053 loss_train: 0.1983 acc_train: 0.8738 acc_val: 0.9778\n",
      "Epoch: 2054 loss_train: 0.7962 acc_train: 0.8931 acc_val: 0.9778\n",
      "Epoch: 2055 loss_train: 0.7655 acc_train: 0.8998 acc_val: 0.9778\n",
      "Epoch: 2056 loss_train: 0.1801 acc_train: 0.8946 acc_val: 0.9778\n",
      "Epoch: 2057 loss_train: 0.1792 acc_train: 0.8968 acc_val: 0.9756\n",
      "Epoch: 2058 loss_train: 0.1890 acc_train: 0.8849 acc_val: 0.9756\n",
      "Epoch: 2059 loss_train: 6.2001 acc_train: 0.8812 acc_val: 0.9778\n",
      "Epoch: 2060 loss_train: 0.1942 acc_train: 0.8968 acc_val: 0.9778\n",
      "Epoch: 2061 loss_train: 0.1719 acc_train: 0.9072 acc_val: 0.9800\n",
      "Epoch: 2062 loss_train: 0.1974 acc_train: 0.8812 acc_val: 0.9800\n",
      "Epoch: 2063 loss_train: 0.1771 acc_train: 0.8953 acc_val: 0.9800\n",
      "Epoch: 2064 loss_train: 0.1853 acc_train: 0.8790 acc_val: 0.9800\n",
      "Epoch: 2065 loss_train: 0.1713 acc_train: 0.9013 acc_val: 0.9800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2066 loss_train: 0.1526 acc_train: 0.9183 acc_val: 0.9800\n",
      "Epoch: 2067 loss_train: 0.1876 acc_train: 0.8953 acc_val: 0.9800\n",
      "Epoch: 2068 loss_train: 0.1866 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 2069 loss_train: 0.6664 acc_train: 0.8812 acc_val: 0.9800\n",
      "Epoch: 2070 loss_train: 0.2256 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 2071 loss_train: 0.1975 acc_train: 0.8864 acc_val: 0.9800\n",
      "Epoch: 2072 loss_train: 0.1794 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 2073 loss_train: 0.1865 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 2074 loss_train: 0.2100 acc_train: 0.8775 acc_val: 0.9800\n",
      "Epoch: 2075 loss_train: 0.1849 acc_train: 0.8983 acc_val: 0.9800\n",
      "Epoch: 2076 loss_train: 0.1803 acc_train: 0.8990 acc_val: 0.9800\n",
      "Epoch: 2077 loss_train: 0.1736 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 2078 loss_train: 0.1913 acc_train: 0.8990 acc_val: 0.9800\n",
      "Epoch: 2079 loss_train: 0.1838 acc_train: 0.8998 acc_val: 0.9800\n",
      "Epoch: 2080 loss_train: 0.1996 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 2081 loss_train: 0.1820 acc_train: 0.8953 acc_val: 0.9800\n",
      "Epoch: 2082 loss_train: 0.3832 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 2083 loss_train: 0.1985 acc_train: 0.8738 acc_val: 0.9800\n",
      "Epoch: 2084 loss_train: 0.1876 acc_train: 0.8864 acc_val: 0.9800\n",
      "Epoch: 2085 loss_train: 0.1751 acc_train: 0.8953 acc_val: 0.9800\n",
      "Epoch: 2086 loss_train: 0.1972 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 2087 loss_train: 0.1869 acc_train: 0.8990 acc_val: 0.9800\n",
      "Epoch: 2088 loss_train: 0.3135 acc_train: 0.8805 acc_val: 0.9778\n",
      "Epoch: 2089 loss_train: 0.1821 acc_train: 0.8849 acc_val: 0.9778\n",
      "Epoch: 2090 loss_train: 2.6159 acc_train: 0.8879 acc_val: 0.9778\n",
      "Epoch: 2091 loss_train: 0.1720 acc_train: 0.8998 acc_val: 0.9800\n",
      "Epoch: 2092 loss_train: 0.1626 acc_train: 0.8968 acc_val: 0.9800\n",
      "Epoch: 2093 loss_train: 0.1793 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 2094 loss_train: 0.8229 acc_train: 0.8834 acc_val: 0.9800\n",
      "Epoch: 2095 loss_train: 0.1679 acc_train: 0.8998 acc_val: 0.9800\n",
      "Epoch: 2096 loss_train: 0.1965 acc_train: 0.8842 acc_val: 0.9800\n",
      "Epoch: 2097 loss_train: 0.1986 acc_train: 0.8782 acc_val: 0.9800\n",
      "Epoch: 2098 loss_train: 2.1879 acc_train: 0.8886 acc_val: 0.9800\n",
      "Epoch: 2099 loss_train: 0.1913 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 2100 loss_train: 1.5180 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 2101 loss_train: 0.1921 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 2102 loss_train: 1.5856 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 2103 loss_train: 0.8128 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 2104 loss_train: 0.1804 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 2105 loss_train: 0.2134 acc_train: 0.8976 acc_val: 0.9800\n",
      "Epoch: 2106 loss_train: 0.2102 acc_train: 0.8797 acc_val: 0.9800\n",
      "Epoch: 2107 loss_train: 0.2539 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 2108 loss_train: 0.6483 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 2109 loss_train: 0.4047 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 2110 loss_train: 0.1906 acc_train: 0.8842 acc_val: 0.9800\n",
      "Epoch: 2111 loss_train: 0.1920 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 2112 loss_train: 0.1786 acc_train: 0.9087 acc_val: 0.9800\n",
      "Epoch: 2113 loss_train: 0.1996 acc_train: 0.8820 acc_val: 0.9800\n",
      "Epoch: 2114 loss_train: 0.1911 acc_train: 0.8953 acc_val: 0.9800\n",
      "Epoch: 2115 loss_train: 0.4546 acc_train: 0.8953 acc_val: 0.9800\n",
      "Epoch: 2116 loss_train: 0.1702 acc_train: 0.8953 acc_val: 0.9800\n",
      "Epoch: 2117 loss_train: 0.1841 acc_train: 0.8782 acc_val: 0.9800\n",
      "Epoch: 2118 loss_train: 0.4518 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 2119 loss_train: 0.1736 acc_train: 0.8976 acc_val: 0.9800\n",
      "Epoch: 2120 loss_train: 0.1651 acc_train: 0.9020 acc_val: 0.9800\n",
      "Epoch: 2121 loss_train: 0.2050 acc_train: 0.8731 acc_val: 0.9800\n",
      "Epoch: 2122 loss_train: 0.1812 acc_train: 0.9057 acc_val: 0.9800\n",
      "Epoch: 2123 loss_train: 0.1967 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 2124 loss_train: 0.1732 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 2125 loss_train: 0.2006 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 2126 loss_train: 0.3320 acc_train: 0.8864 acc_val: 0.9800\n",
      "Epoch: 2127 loss_train: 2.9205 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 2128 loss_train: 0.1979 acc_train: 0.8797 acc_val: 0.9800\n",
      "Epoch: 2129 loss_train: 0.1793 acc_train: 0.9035 acc_val: 0.9800\n",
      "Epoch: 2130 loss_train: 0.1895 acc_train: 0.8834 acc_val: 0.9800\n",
      "Epoch: 2131 loss_train: 0.1881 acc_train: 0.8864 acc_val: 0.9800\n",
      "Epoch: 2132 loss_train: 0.1910 acc_train: 0.8805 acc_val: 0.9800\n",
      "Epoch: 2133 loss_train: 0.7206 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 2134 loss_train: 0.1841 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 2135 loss_train: 0.1628 acc_train: 0.9176 acc_val: 0.9800\n",
      "Epoch: 2136 loss_train: 0.7037 acc_train: 0.8775 acc_val: 0.9800\n",
      "Epoch: 2137 loss_train: 0.1722 acc_train: 0.9013 acc_val: 0.9800\n",
      "Epoch: 2138 loss_train: 0.1565 acc_train: 0.9109 acc_val: 0.9800\n",
      "Epoch: 2139 loss_train: 0.1815 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 2140 loss_train: 0.1952 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 2141 loss_train: 0.1809 acc_train: 0.9020 acc_val: 0.9800\n",
      "Epoch: 2142 loss_train: 0.2013 acc_train: 0.8827 acc_val: 0.9800\n",
      "Epoch: 2143 loss_train: 0.1962 acc_train: 0.8790 acc_val: 0.9800\n",
      "Epoch: 2144 loss_train: 0.1825 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 2145 loss_train: 0.1860 acc_train: 0.8834 acc_val: 0.9800\n",
      "Epoch: 2146 loss_train: 0.2053 acc_train: 0.8820 acc_val: 0.9800\n",
      "Epoch: 2147 loss_train: 0.1964 acc_train: 0.8790 acc_val: 0.9800\n",
      "Epoch: 2148 loss_train: 0.1849 acc_train: 0.8998 acc_val: 0.9800\n",
      "Epoch: 2149 loss_train: 0.1735 acc_train: 0.8886 acc_val: 0.9800\n",
      "Epoch: 2150 loss_train: 0.1729 acc_train: 0.8976 acc_val: 0.9800\n",
      "Epoch: 2151 loss_train: 0.1847 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 2152 loss_train: 0.1904 acc_train: 0.8864 acc_val: 0.9800\n",
      "Epoch: 2153 loss_train: 0.1783 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 2154 loss_train: 0.1771 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 2155 loss_train: 0.1955 acc_train: 0.8968 acc_val: 0.9800\n",
      "Epoch: 2156 loss_train: 0.2910 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 2157 loss_train: 0.1832 acc_train: 0.8990 acc_val: 0.9800\n",
      "Epoch: 2158 loss_train: 0.1922 acc_train: 0.8723 acc_val: 0.9800\n",
      "Epoch: 2159 loss_train: 0.1746 acc_train: 0.9027 acc_val: 0.9800\n",
      "Epoch: 2160 loss_train: 0.1973 acc_train: 0.8842 acc_val: 0.9800\n",
      "Epoch: 2161 loss_train: 0.1570 acc_train: 0.9057 acc_val: 0.9800\n",
      "Epoch: 2162 loss_train: 0.1617 acc_train: 0.9005 acc_val: 0.9800\n",
      "Epoch: 2163 loss_train: 0.1870 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 2164 loss_train: 0.1910 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 2165 loss_train: 0.1954 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 2166 loss_train: 0.1728 acc_train: 0.9042 acc_val: 0.9800\n",
      "Epoch: 2167 loss_train: 0.1642 acc_train: 0.9042 acc_val: 0.9800\n",
      "Epoch: 2168 loss_train: 0.1828 acc_train: 0.8886 acc_val: 0.9800\n",
      "Epoch: 2169 loss_train: 0.1916 acc_train: 0.8812 acc_val: 0.9800\n",
      "Epoch: 2170 loss_train: 0.1790 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 2171 loss_train: 0.1808 acc_train: 0.8998 acc_val: 0.9800\n",
      "Epoch: 2172 loss_train: 0.1791 acc_train: 0.8976 acc_val: 0.9800\n",
      "Epoch: 2173 loss_train: 0.1930 acc_train: 0.8805 acc_val: 0.9800\n",
      "Epoch: 2174 loss_train: 0.1826 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 2175 loss_train: 0.1970 acc_train: 0.8790 acc_val: 0.9800\n",
      "Epoch: 2176 loss_train: 0.1829 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 2177 loss_train: 0.1753 acc_train: 0.9005 acc_val: 0.9800\n",
      "Epoch: 2178 loss_train: 0.1778 acc_train: 0.9013 acc_val: 0.9800\n",
      "Epoch: 2179 loss_train: 0.1944 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 2180 loss_train: 0.1871 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 2181 loss_train: 0.1743 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 2182 loss_train: 0.1584 acc_train: 0.9027 acc_val: 0.9800\n",
      "Epoch: 2183 loss_train: 0.1939 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 2184 loss_train: 0.1844 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 2185 loss_train: 0.1864 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 2186 loss_train: 0.2001 acc_train: 0.8827 acc_val: 0.9800\n",
      "Epoch: 2187 loss_train: 0.2217 acc_train: 0.8797 acc_val: 0.9800\n",
      "Epoch: 2188 loss_train: 0.2039 acc_train: 0.8827 acc_val: 0.9800\n",
      "Epoch: 2189 loss_train: 0.1838 acc_train: 0.8961 acc_val: 0.9800\n",
      "Epoch: 2190 loss_train: 0.1685 acc_train: 0.9042 acc_val: 0.9800\n",
      "Epoch: 2191 loss_train: 0.1638 acc_train: 0.9072 acc_val: 0.9800\n",
      "Epoch: 2192 loss_train: 0.1939 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 2193 loss_train: 0.1894 acc_train: 0.8782 acc_val: 0.9800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2194 loss_train: 0.1956 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 2195 loss_train: 0.1925 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 2196 loss_train: 0.1816 acc_train: 0.9013 acc_val: 0.9800\n",
      "Epoch: 2197 loss_train: 0.1873 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 2198 loss_train: 0.1725 acc_train: 0.8998 acc_val: 0.9800\n",
      "Epoch: 2199 loss_train: 0.1848 acc_train: 0.8886 acc_val: 0.9800\n",
      "Epoch: 2200 loss_train: 0.1779 acc_train: 0.9027 acc_val: 0.9800\n",
      "Epoch: 2201 loss_train: 0.1996 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 2202 loss_train: 0.1793 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 2203 loss_train: 0.1885 acc_train: 0.8842 acc_val: 0.9800\n",
      "Epoch: 2204 loss_train: 0.1818 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 2205 loss_train: 0.2026 acc_train: 0.8805 acc_val: 0.9800\n",
      "Epoch: 2206 loss_train: 0.1796 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 2207 loss_train: 0.1829 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 2208 loss_train: 0.1936 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 2209 loss_train: 0.1796 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 2210 loss_train: 0.1933 acc_train: 0.8790 acc_val: 0.9800\n",
      "Epoch: 2211 loss_train: 0.1687 acc_train: 0.9102 acc_val: 0.9800\n",
      "Epoch: 2212 loss_train: 0.1776 acc_train: 0.9005 acc_val: 0.9800\n",
      "Epoch: 2213 loss_train: 0.1907 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 2214 loss_train: 0.2016 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 2215 loss_train: 0.2004 acc_train: 0.8760 acc_val: 0.9800\n",
      "Epoch: 2216 loss_train: 0.1849 acc_train: 0.8842 acc_val: 0.9800\n",
      "Epoch: 2217 loss_train: 0.1851 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 2218 loss_train: 0.1734 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 2219 loss_train: 0.1954 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 2220 loss_train: 0.1837 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 2221 loss_train: 0.1950 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 2222 loss_train: 0.1951 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 2223 loss_train: 0.1950 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 2224 loss_train: 0.1864 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 2225 loss_train: 0.1630 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 2226 loss_train: 0.1955 acc_train: 0.8842 acc_val: 0.9800\n",
      "Epoch: 2227 loss_train: 0.1886 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 2228 loss_train: 0.1975 acc_train: 0.8834 acc_val: 0.9800\n",
      "Epoch: 2229 loss_train: 0.1846 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 2230 loss_train: 0.1868 acc_train: 0.8834 acc_val: 0.9800\n",
      "Epoch: 2231 loss_train: 0.1753 acc_train: 0.8812 acc_val: 0.9800\n",
      "Epoch: 2232 loss_train: 0.1917 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 2233 loss_train: 0.2021 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 2234 loss_train: 0.1795 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 2235 loss_train: 0.1878 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 2236 loss_train: 0.1932 acc_train: 0.8834 acc_val: 0.9800\n",
      "Epoch: 2237 loss_train: 0.1740 acc_train: 0.8983 acc_val: 0.9800\n",
      "Epoch: 2238 loss_train: 0.1929 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 2239 loss_train: 0.1658 acc_train: 0.9109 acc_val: 0.9800\n",
      "Epoch: 2240 loss_train: 0.1750 acc_train: 0.8976 acc_val: 0.9800\n",
      "Epoch: 2241 loss_train: 0.1641 acc_train: 0.9079 acc_val: 0.9800\n",
      "Epoch: 2242 loss_train: 0.1856 acc_train: 0.8990 acc_val: 0.9800\n",
      "Epoch: 2243 loss_train: 0.1998 acc_train: 0.8775 acc_val: 0.9800\n",
      "Epoch: 2244 loss_train: 0.1795 acc_train: 0.9005 acc_val: 0.9800\n",
      "Epoch: 2245 loss_train: 0.1655 acc_train: 0.8976 acc_val: 0.9800\n",
      "Epoch: 2246 loss_train: 0.1976 acc_train: 0.8790 acc_val: 0.9800\n",
      "Epoch: 2247 loss_train: 0.1776 acc_train: 0.8976 acc_val: 0.9800\n",
      "Epoch: 2248 loss_train: 0.1863 acc_train: 0.8976 acc_val: 0.9800\n",
      "Epoch: 2249 loss_train: 0.1973 acc_train: 0.8820 acc_val: 0.9800\n",
      "Epoch: 2250 loss_train: 0.1681 acc_train: 0.9050 acc_val: 0.9800\n",
      "Epoch: 2251 loss_train: 0.1604 acc_train: 0.9109 acc_val: 0.9800\n",
      "Epoch: 2252 loss_train: 0.2106 acc_train: 0.8834 acc_val: 0.9800\n",
      "Epoch: 2253 loss_train: 0.1735 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 2254 loss_train: 0.2037 acc_train: 0.8782 acc_val: 0.9800\n",
      "Epoch: 2255 loss_train: 0.1822 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 2256 loss_train: 0.1791 acc_train: 0.8968 acc_val: 0.9800\n",
      "Epoch: 2257 loss_train: 0.1775 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 2258 loss_train: 0.1650 acc_train: 0.9079 acc_val: 0.9800\n",
      "Epoch: 2259 loss_train: 0.1828 acc_train: 0.8976 acc_val: 0.9800\n",
      "Epoch: 2260 loss_train: 0.2025 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 2261 loss_train: 0.2039 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 2262 loss_train: 0.1965 acc_train: 0.8827 acc_val: 0.9800\n",
      "Epoch: 2263 loss_train: 0.1931 acc_train: 0.8768 acc_val: 0.9800\n",
      "Epoch: 2264 loss_train: 0.1632 acc_train: 0.8976 acc_val: 0.9800\n",
      "Epoch: 2265 loss_train: 0.1971 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 2266 loss_train: 0.1847 acc_train: 0.8842 acc_val: 0.9800\n",
      "Epoch: 2267 loss_train: 0.1957 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 2268 loss_train: 0.2117 acc_train: 0.8745 acc_val: 0.9800\n",
      "Epoch: 2269 loss_train: 0.2023 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 2270 loss_train: 0.1923 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 2271 loss_train: 0.1789 acc_train: 0.8976 acc_val: 0.9800\n",
      "Epoch: 2272 loss_train: 0.2125 acc_train: 0.8797 acc_val: 0.9800\n",
      "Epoch: 2273 loss_train: 0.2009 acc_train: 0.8805 acc_val: 0.9800\n",
      "Epoch: 2274 loss_train: 0.1921 acc_train: 0.8827 acc_val: 0.9800\n",
      "Epoch: 2275 loss_train: 0.1735 acc_train: 0.8961 acc_val: 0.9800\n",
      "Epoch: 2276 loss_train: 0.1908 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 2277 loss_train: 0.1751 acc_train: 0.8961 acc_val: 0.9800\n",
      "Epoch: 2278 loss_train: 0.1901 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 2279 loss_train: 0.1853 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 2280 loss_train: 0.1859 acc_train: 0.8820 acc_val: 0.9800\n",
      "Epoch: 2281 loss_train: 0.1844 acc_train: 0.8953 acc_val: 0.9800\n",
      "Epoch: 2282 loss_train: 0.1862 acc_train: 0.8961 acc_val: 0.9800\n",
      "Epoch: 2283 loss_train: 0.1850 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 2284 loss_train: 0.2112 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 2285 loss_train: 0.2001 acc_train: 0.8760 acc_val: 0.9800\n",
      "Epoch: 2286 loss_train: 0.1897 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 2287 loss_train: 0.1890 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 2288 loss_train: 0.1781 acc_train: 0.9013 acc_val: 0.9800\n",
      "Epoch: 2289 loss_train: 0.1998 acc_train: 0.8731 acc_val: 0.9800\n",
      "Epoch: 2290 loss_train: 0.1680 acc_train: 0.9020 acc_val: 0.9800\n",
      "Epoch: 2291 loss_train: 0.1977 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 2292 loss_train: 0.1826 acc_train: 0.9005 acc_val: 0.9800\n",
      "Epoch: 2293 loss_train: 0.2011 acc_train: 0.8834 acc_val: 0.9800\n",
      "Epoch: 2294 loss_train: 0.1930 acc_train: 0.8782 acc_val: 0.9800\n",
      "Epoch: 2295 loss_train: 0.2083 acc_train: 0.8738 acc_val: 0.9800\n",
      "Epoch: 2296 loss_train: 0.1743 acc_train: 0.8990 acc_val: 0.9800\n",
      "Epoch: 2297 loss_train: 0.2192 acc_train: 0.8768 acc_val: 0.9800\n",
      "Epoch: 2298 loss_train: 0.1698 acc_train: 0.8953 acc_val: 0.9800\n",
      "Epoch: 2299 loss_train: 0.1832 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 2300 loss_train: 0.1735 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 2301 loss_train: 0.1964 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 2302 loss_train: 0.1902 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 2303 loss_train: 0.1932 acc_train: 0.8790 acc_val: 0.9800\n",
      "Epoch: 2304 loss_train: 0.1910 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 2305 loss_train: 0.1836 acc_train: 0.8820 acc_val: 0.9800\n",
      "Epoch: 2306 loss_train: 0.1829 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 2307 loss_train: 0.1779 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 2308 loss_train: 0.1747 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 2309 loss_train: 0.1913 acc_train: 0.8834 acc_val: 0.9800\n",
      "Epoch: 2310 loss_train: 0.1930 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 2311 loss_train: 0.1813 acc_train: 0.8953 acc_val: 0.9800\n",
      "Epoch: 2312 loss_train: 0.2098 acc_train: 0.8805 acc_val: 0.9800\n",
      "Epoch: 2313 loss_train: 0.1918 acc_train: 0.8976 acc_val: 0.9800\n",
      "Epoch: 2314 loss_train: 0.1921 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 2315 loss_train: 0.1816 acc_train: 0.8990 acc_val: 0.9800\n",
      "Epoch: 2316 loss_train: 0.1942 acc_train: 0.8820 acc_val: 0.9800\n",
      "Epoch: 2317 loss_train: 0.1745 acc_train: 0.9035 acc_val: 0.9800\n",
      "Epoch: 2318 loss_train: 0.2073 acc_train: 0.8775 acc_val: 0.9800\n",
      "Epoch: 2319 loss_train: 0.2018 acc_train: 0.8753 acc_val: 0.9800\n",
      "Epoch: 2320 loss_train: 0.1838 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 2321 loss_train: 0.1807 acc_train: 0.8909 acc_val: 0.9800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2322 loss_train: 0.1939 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 2323 loss_train: 0.1825 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 2324 loss_train: 0.1826 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 2325 loss_train: 0.2057 acc_train: 0.8738 acc_val: 0.9800\n",
      "Epoch: 2326 loss_train: 0.1978 acc_train: 0.8738 acc_val: 0.9800\n",
      "Epoch: 2327 loss_train: 0.1701 acc_train: 0.9072 acc_val: 0.9800\n",
      "Epoch: 2328 loss_train: 0.1741 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 2329 loss_train: 0.1928 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 2330 loss_train: 0.1682 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 2331 loss_train: 0.1813 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 2332 loss_train: 0.1860 acc_train: 0.8812 acc_val: 0.9800\n",
      "Epoch: 2333 loss_train: 0.1780 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 2334 loss_train: 0.1945 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 2335 loss_train: 0.2089 acc_train: 0.8716 acc_val: 0.9800\n",
      "Epoch: 2336 loss_train: 0.1867 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 2337 loss_train: 0.1834 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 2338 loss_train: 0.1801 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 2339 loss_train: 0.1814 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 2340 loss_train: 0.1802 acc_train: 0.8842 acc_val: 0.9800\n",
      "Epoch: 2341 loss_train: 0.1799 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 2342 loss_train: 0.1869 acc_train: 0.8864 acc_val: 0.9800\n",
      "Epoch: 2343 loss_train: 0.2141 acc_train: 0.8827 acc_val: 0.9800\n",
      "Epoch: 2344 loss_train: 0.1624 acc_train: 0.9035 acc_val: 0.9800\n",
      "Epoch: 2345 loss_train: 0.1809 acc_train: 0.9020 acc_val: 0.9800\n",
      "Epoch: 2346 loss_train: 0.1715 acc_train: 0.9005 acc_val: 0.9800\n",
      "Epoch: 2347 loss_train: 0.1960 acc_train: 0.8797 acc_val: 0.9800\n",
      "Epoch: 2348 loss_train: 0.2031 acc_train: 0.8745 acc_val: 0.9800\n",
      "Epoch: 2349 loss_train: 0.1785 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 2350 loss_train: 0.1751 acc_train: 0.8961 acc_val: 0.9800\n",
      "Epoch: 2351 loss_train: 0.1996 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 2352 loss_train: 0.1832 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 2353 loss_train: 0.1793 acc_train: 0.8827 acc_val: 0.9800\n",
      "Epoch: 2354 loss_train: 0.1866 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 2355 loss_train: 0.1879 acc_train: 0.8864 acc_val: 0.9800\n",
      "Epoch: 2356 loss_train: 0.1925 acc_train: 0.8827 acc_val: 0.9800\n",
      "Epoch: 2357 loss_train: 0.2070 acc_train: 0.8827 acc_val: 0.9800\n",
      "Epoch: 2358 loss_train: 0.1832 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 2359 loss_train: 0.1855 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 2360 loss_train: 0.1833 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 2361 loss_train: 0.1887 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 2362 loss_train: 0.1662 acc_train: 0.8983 acc_val: 0.9800\n",
      "Epoch: 2363 loss_train: 0.1753 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 2364 loss_train: 0.1944 acc_train: 0.8790 acc_val: 0.9800\n",
      "Epoch: 2365 loss_train: 0.1734 acc_train: 0.8961 acc_val: 0.9800\n",
      "Epoch: 2366 loss_train: 0.1773 acc_train: 0.9013 acc_val: 0.9800\n",
      "Epoch: 2367 loss_train: 0.1972 acc_train: 0.8775 acc_val: 0.9800\n",
      "Epoch: 2368 loss_train: 0.1684 acc_train: 0.9042 acc_val: 0.9800\n",
      "Epoch: 2369 loss_train: 0.1849 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 2370 loss_train: 0.1723 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 2371 loss_train: 0.1924 acc_train: 0.8805 acc_val: 0.9800\n",
      "Epoch: 2372 loss_train: 0.1918 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 2373 loss_train: 0.1794 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 2374 loss_train: 0.1775 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 2375 loss_train: 0.2165 acc_train: 0.8753 acc_val: 0.9800\n",
      "Epoch: 2376 loss_train: 0.1635 acc_train: 0.9087 acc_val: 0.9800\n",
      "Epoch: 2377 loss_train: 0.1882 acc_train: 0.8886 acc_val: 0.9800\n",
      "Epoch: 2378 loss_train: 0.1932 acc_train: 0.8820 acc_val: 0.9800\n",
      "Epoch: 2379 loss_train: 0.2066 acc_train: 0.8768 acc_val: 0.9800\n",
      "Epoch: 2380 loss_train: 0.1964 acc_train: 0.8886 acc_val: 0.9800\n",
      "Epoch: 2381 loss_train: 0.1814 acc_train: 0.8990 acc_val: 0.9800\n",
      "Epoch: 2382 loss_train: 0.1904 acc_train: 0.8834 acc_val: 0.9800\n",
      "Epoch: 2383 loss_train: 0.1959 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 2384 loss_train: 0.1683 acc_train: 0.9027 acc_val: 0.9800\n",
      "Epoch: 2385 loss_train: 0.1902 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 2386 loss_train: 0.1913 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 2387 loss_train: 0.1696 acc_train: 0.8998 acc_val: 0.9800\n",
      "Epoch: 2388 loss_train: 0.1825 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 2389 loss_train: 0.1803 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 2390 loss_train: 0.1949 acc_train: 0.8790 acc_val: 0.9800\n",
      "Epoch: 2391 loss_train: 0.1658 acc_train: 0.9027 acc_val: 0.9800\n",
      "Epoch: 2392 loss_train: 0.1916 acc_train: 0.8886 acc_val: 0.9800\n",
      "Epoch: 2393 loss_train: 0.1801 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 2394 loss_train: 0.1713 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 2395 loss_train: 0.2014 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 2396 loss_train: 0.1784 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 2397 loss_train: 0.1994 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 2398 loss_train: 0.1649 acc_train: 0.9042 acc_val: 0.9800\n",
      "Epoch: 2399 loss_train: 0.1859 acc_train: 0.8864 acc_val: 0.9800\n",
      "Epoch: 2400 loss_train: 0.1881 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 2401 loss_train: 0.1676 acc_train: 0.9020 acc_val: 0.9800\n",
      "Epoch: 2402 loss_train: 0.1994 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 2403 loss_train: 0.1668 acc_train: 0.9020 acc_val: 0.9800\n",
      "Epoch: 2404 loss_train: 0.1661 acc_train: 0.9027 acc_val: 0.9800\n",
      "Epoch: 2405 loss_train: 0.1794 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 2406 loss_train: 0.1799 acc_train: 0.8864 acc_val: 0.9800\n",
      "Epoch: 2407 loss_train: 0.1915 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 2408 loss_train: 0.1827 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 2409 loss_train: 0.1879 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 2410 loss_train: 0.1858 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 2411 loss_train: 0.1915 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 2412 loss_train: 0.1818 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 2413 loss_train: 0.1767 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 2414 loss_train: 0.1965 acc_train: 0.8790 acc_val: 0.9800\n",
      "Epoch: 2415 loss_train: 0.1962 acc_train: 0.8827 acc_val: 0.9800\n",
      "Epoch: 2416 loss_train: 0.1888 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 2417 loss_train: 0.1835 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 2418 loss_train: 0.1703 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 2419 loss_train: 0.1806 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 2420 loss_train: 0.1962 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 2421 loss_train: 0.1845 acc_train: 0.8968 acc_val: 0.9800\n",
      "Epoch: 2422 loss_train: 0.1805 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 2423 loss_train: 0.1949 acc_train: 0.8797 acc_val: 0.9800\n",
      "Epoch: 2424 loss_train: 0.2044 acc_train: 0.8827 acc_val: 0.9800\n",
      "Epoch: 2425 loss_train: 0.1823 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 2426 loss_train: 0.1824 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 2427 loss_train: 0.1647 acc_train: 0.9005 acc_val: 0.9800\n",
      "Epoch: 2428 loss_train: 0.1743 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 2429 loss_train: 0.1908 acc_train: 0.8864 acc_val: 0.9800\n",
      "Epoch: 2430 loss_train: 0.1882 acc_train: 0.8886 acc_val: 0.9800\n",
      "Epoch: 2431 loss_train: 0.1852 acc_train: 0.8998 acc_val: 0.9800\n",
      "Epoch: 2432 loss_train: 0.1940 acc_train: 0.8745 acc_val: 0.9800\n",
      "Epoch: 2433 loss_train: 0.1815 acc_train: 0.8998 acc_val: 0.9800\n",
      "Epoch: 2434 loss_train: 0.1868 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 2435 loss_train: 0.1726 acc_train: 0.9020 acc_val: 0.9800\n",
      "Epoch: 2436 loss_train: 0.2007 acc_train: 0.8738 acc_val: 0.9800\n",
      "Epoch: 2437 loss_train: 0.1988 acc_train: 0.8790 acc_val: 0.9800\n",
      "Epoch: 2438 loss_train: 0.2011 acc_train: 0.8797 acc_val: 0.9800\n",
      "Epoch: 2439 loss_train: 0.1897 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 2440 loss_train: 0.1932 acc_train: 0.8827 acc_val: 0.9800\n",
      "Epoch: 2441 loss_train: 0.1964 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 2442 loss_train: 0.1735 acc_train: 0.8968 acc_val: 0.9800\n",
      "Epoch: 2443 loss_train: 0.1867 acc_train: 0.8834 acc_val: 0.9800\n",
      "Epoch: 2444 loss_train: 0.1883 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 2445 loss_train: 0.1925 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 2446 loss_train: 0.1969 acc_train: 0.8797 acc_val: 0.9800\n",
      "Epoch: 2447 loss_train: 0.1897 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 2448 loss_train: 0.1993 acc_train: 0.8968 acc_val: 0.9800\n",
      "Epoch: 2449 loss_train: 0.1879 acc_train: 0.8820 acc_val: 0.9800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2450 loss_train: 0.1811 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 2451 loss_train: 0.1815 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 2452 loss_train: 0.1830 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 2453 loss_train: 0.2020 acc_train: 0.8760 acc_val: 0.9800\n",
      "Epoch: 2454 loss_train: 0.1915 acc_train: 0.8886 acc_val: 0.9800\n",
      "Epoch: 2455 loss_train: 0.1825 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 2456 loss_train: 0.2064 acc_train: 0.8775 acc_val: 0.9800\n",
      "Epoch: 2457 loss_train: 0.1692 acc_train: 0.9005 acc_val: 0.9800\n",
      "Epoch: 2458 loss_train: 0.2020 acc_train: 0.8753 acc_val: 0.9800\n",
      "Epoch: 2459 loss_train: 0.2007 acc_train: 0.8790 acc_val: 0.9800\n",
      "Epoch: 2460 loss_train: 0.1901 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 2461 loss_train: 0.1824 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 2462 loss_train: 0.2015 acc_train: 0.8790 acc_val: 0.9800\n",
      "Epoch: 2463 loss_train: 0.1916 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 2464 loss_train: 0.1758 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 2465 loss_train: 0.1828 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 2466 loss_train: 0.2036 acc_train: 0.8753 acc_val: 0.9800\n",
      "Epoch: 2467 loss_train: 0.1926 acc_train: 0.8842 acc_val: 0.9800\n",
      "Epoch: 2468 loss_train: 0.1811 acc_train: 0.9013 acc_val: 0.9800\n",
      "Epoch: 2469 loss_train: 0.1971 acc_train: 0.8812 acc_val: 0.9800\n",
      "Epoch: 2470 loss_train: 0.1869 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 2471 loss_train: 0.1678 acc_train: 0.9013 acc_val: 0.9800\n",
      "Epoch: 2472 loss_train: 0.1843 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 2473 loss_train: 0.1822 acc_train: 0.8990 acc_val: 0.9800\n",
      "Epoch: 2474 loss_train: 0.2006 acc_train: 0.8820 acc_val: 0.9800\n",
      "Epoch: 2475 loss_train: 0.1878 acc_train: 0.8968 acc_val: 0.9800\n",
      "Epoch: 2476 loss_train: 0.1963 acc_train: 0.8864 acc_val: 0.9800\n",
      "Epoch: 2477 loss_train: 0.1720 acc_train: 0.8968 acc_val: 0.9800\n",
      "Epoch: 2478 loss_train: 0.1631 acc_train: 0.9079 acc_val: 0.9800\n",
      "Epoch: 2479 loss_train: 0.1727 acc_train: 0.9087 acc_val: 0.9800\n",
      "Epoch: 2480 loss_train: 0.1938 acc_train: 0.8812 acc_val: 0.9800\n",
      "Epoch: 2481 loss_train: 0.1669 acc_train: 0.9020 acc_val: 0.9800\n",
      "Epoch: 2482 loss_train: 0.1741 acc_train: 0.8990 acc_val: 0.9800\n",
      "Epoch: 2483 loss_train: 0.1754 acc_train: 0.8990 acc_val: 0.9800\n",
      "Epoch: 2484 loss_train: 0.1933 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 2485 loss_train: 0.1716 acc_train: 0.8961 acc_val: 0.9800\n",
      "Epoch: 2486 loss_train: 0.1850 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 2487 loss_train: 0.1747 acc_train: 0.8998 acc_val: 0.9800\n",
      "Epoch: 2488 loss_train: 0.1971 acc_train: 0.8820 acc_val: 0.9800\n",
      "Epoch: 2489 loss_train: 0.1886 acc_train: 0.8842 acc_val: 0.9800\n",
      "Epoch: 2490 loss_train: 0.2084 acc_train: 0.8768 acc_val: 0.9800\n",
      "Epoch: 2491 loss_train: 0.1863 acc_train: 0.8790 acc_val: 0.9800\n",
      "Epoch: 2492 loss_train: 0.1977 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 2493 loss_train: 0.1854 acc_train: 0.8886 acc_val: 0.9800\n",
      "Epoch: 2494 loss_train: 0.1908 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 2495 loss_train: 0.1923 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 2496 loss_train: 0.1924 acc_train: 0.8820 acc_val: 0.9800\n",
      "Epoch: 2497 loss_train: 0.1808 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 2498 loss_train: 0.1761 acc_train: 0.9042 acc_val: 0.9800\n",
      "Epoch: 2499 loss_train: 0.1580 acc_train: 0.9146 acc_val: 0.9800\n",
      "Epoch: 2500 loss_train: 0.1807 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 2501 loss_train: 0.1775 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 2502 loss_train: 0.2181 acc_train: 0.8686 acc_val: 0.9800\n",
      "Epoch: 2503 loss_train: 0.1974 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 2504 loss_train: 0.1898 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 2505 loss_train: 0.1919 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 2506 loss_train: 0.1784 acc_train: 0.8998 acc_val: 0.9800\n",
      "Epoch: 2507 loss_train: 0.1885 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 2508 loss_train: 0.1675 acc_train: 0.9102 acc_val: 0.9800\n",
      "Epoch: 2509 loss_train: 0.1762 acc_train: 0.8842 acc_val: 0.9800\n",
      "Epoch: 2510 loss_train: 0.1989 acc_train: 0.8842 acc_val: 0.9800\n",
      "Epoch: 2511 loss_train: 0.1836 acc_train: 0.8968 acc_val: 0.9800\n",
      "Epoch: 2512 loss_train: 0.1688 acc_train: 0.9035 acc_val: 0.9800\n",
      "Epoch: 2513 loss_train: 0.1805 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 2514 loss_train: 0.1710 acc_train: 0.8961 acc_val: 0.9800\n",
      "Epoch: 2515 loss_train: 0.1832 acc_train: 0.8886 acc_val: 0.9800\n",
      "Epoch: 2516 loss_train: 0.2042 acc_train: 0.8782 acc_val: 0.9800\n",
      "Epoch: 2517 loss_train: 0.1800 acc_train: 0.8983 acc_val: 0.9800\n",
      "Epoch: 2518 loss_train: 0.1948 acc_train: 0.8745 acc_val: 0.9800\n",
      "Epoch: 2519 loss_train: 0.1963 acc_train: 0.8953 acc_val: 0.9800\n",
      "Epoch: 2520 loss_train: 0.1985 acc_train: 0.8805 acc_val: 0.9800\n",
      "Epoch: 2521 loss_train: 0.1953 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 2522 loss_train: 0.2109 acc_train: 0.8842 acc_val: 0.9800\n",
      "Epoch: 2523 loss_train: 0.1733 acc_train: 0.8976 acc_val: 0.9800\n",
      "Epoch: 2524 loss_train: 0.1804 acc_train: 0.8983 acc_val: 0.9800\n",
      "Epoch: 2525 loss_train: 0.1687 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 2526 loss_train: 0.1841 acc_train: 0.8953 acc_val: 0.9800\n",
      "Epoch: 2527 loss_train: 0.1638 acc_train: 0.9013 acc_val: 0.9800\n",
      "Epoch: 2528 loss_train: 0.1978 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 2529 loss_train: 0.1792 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 2530 loss_train: 0.1974 acc_train: 0.8961 acc_val: 0.9800\n",
      "Epoch: 2531 loss_train: 0.1643 acc_train: 0.9013 acc_val: 0.9800\n",
      "Epoch: 2532 loss_train: 0.1853 acc_train: 0.8886 acc_val: 0.9800\n",
      "Epoch: 2533 loss_train: 0.1584 acc_train: 0.9042 acc_val: 0.9800\n",
      "Epoch: 2534 loss_train: 0.2004 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 2535 loss_train: 0.1828 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 2536 loss_train: 0.2008 acc_train: 0.8805 acc_val: 0.9800\n",
      "Epoch: 2537 loss_train: 0.1678 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 2538 loss_train: 0.1877 acc_train: 0.8886 acc_val: 0.9800\n",
      "Epoch: 2539 loss_train: 0.1712 acc_train: 0.8998 acc_val: 0.9800\n",
      "Epoch: 2540 loss_train: 0.2001 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 2541 loss_train: 0.1855 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 2542 loss_train: 0.1915 acc_train: 0.8961 acc_val: 0.9800\n",
      "Epoch: 2543 loss_train: 0.1880 acc_train: 0.8827 acc_val: 0.9800\n",
      "Epoch: 2544 loss_train: 0.1856 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 2545 loss_train: 0.1814 acc_train: 0.8968 acc_val: 0.9800\n",
      "Epoch: 2546 loss_train: 0.2016 acc_train: 0.8723 acc_val: 0.9800\n",
      "Epoch: 2547 loss_train: 0.1893 acc_train: 0.8864 acc_val: 0.9800\n",
      "Epoch: 2548 loss_train: 0.1938 acc_train: 0.8797 acc_val: 0.9800\n",
      "Epoch: 2549 loss_train: 0.2028 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 2550 loss_train: 0.1896 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 2551 loss_train: 0.1912 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 2552 loss_train: 0.1993 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 2553 loss_train: 0.1873 acc_train: 0.8753 acc_val: 0.9800\n",
      "Epoch: 2554 loss_train: 0.2114 acc_train: 0.8708 acc_val: 0.9800\n",
      "Epoch: 2555 loss_train: 0.1629 acc_train: 0.9020 acc_val: 0.9800\n",
      "Epoch: 2556 loss_train: 0.1864 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 2557 loss_train: 0.1915 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 2558 loss_train: 0.1820 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 2559 loss_train: 0.1924 acc_train: 0.8864 acc_val: 0.9800\n",
      "Epoch: 2560 loss_train: 0.1800 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 2561 loss_train: 0.1719 acc_train: 0.9005 acc_val: 0.9800\n",
      "Epoch: 2562 loss_train: 0.1940 acc_train: 0.8886 acc_val: 0.9800\n",
      "Epoch: 2563 loss_train: 0.1981 acc_train: 0.8953 acc_val: 0.9800\n",
      "Epoch: 2564 loss_train: 0.1859 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 2565 loss_train: 0.1869 acc_train: 0.8953 acc_val: 0.9800\n",
      "Epoch: 2566 loss_train: 0.1840 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 2567 loss_train: 0.2188 acc_train: 0.8738 acc_val: 0.9800\n",
      "Epoch: 2568 loss_train: 0.1738 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 2569 loss_train: 0.1847 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 2570 loss_train: 0.1779 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 2571 loss_train: 0.1951 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 2572 loss_train: 0.1674 acc_train: 0.8990 acc_val: 0.9800\n",
      "Epoch: 2573 loss_train: 0.1948 acc_train: 0.8864 acc_val: 0.9800\n",
      "Epoch: 2574 loss_train: 0.1821 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 2575 loss_train: 0.1869 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 2576 loss_train: 0.1575 acc_train: 0.8990 acc_val: 0.9800\n",
      "Epoch: 2577 loss_train: 0.1912 acc_train: 0.8812 acc_val: 0.9800\n",
      "Epoch: 2578 loss_train: 0.1914 acc_train: 0.8842 acc_val: 0.9800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2579 loss_train: 0.1795 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 2580 loss_train: 0.1797 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 2581 loss_train: 0.1672 acc_train: 0.9020 acc_val: 0.9800\n",
      "Epoch: 2582 loss_train: 0.2120 acc_train: 0.8797 acc_val: 0.9800\n",
      "Epoch: 2583 loss_train: 0.1659 acc_train: 0.9035 acc_val: 0.9800\n",
      "Epoch: 2584 loss_train: 0.1717 acc_train: 0.9079 acc_val: 0.9800\n",
      "Epoch: 2585 loss_train: 0.2091 acc_train: 0.8745 acc_val: 0.9800\n",
      "Epoch: 2586 loss_train: 0.1873 acc_train: 0.8834 acc_val: 0.9800\n",
      "Epoch: 2587 loss_train: 0.1961 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 2588 loss_train: 0.1803 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 2589 loss_train: 0.1777 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 2590 loss_train: 0.1889 acc_train: 0.8886 acc_val: 0.9800\n",
      "Epoch: 2591 loss_train: 0.1843 acc_train: 0.8953 acc_val: 0.9800\n",
      "Epoch: 2592 loss_train: 0.1887 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 2593 loss_train: 0.2100 acc_train: 0.8827 acc_val: 0.9800\n",
      "Epoch: 2594 loss_train: 0.1639 acc_train: 0.9079 acc_val: 0.9800\n",
      "Epoch: 2595 loss_train: 0.1659 acc_train: 0.9013 acc_val: 0.9800\n",
      "Epoch: 2596 loss_train: 0.1869 acc_train: 0.8953 acc_val: 0.9800\n",
      "Epoch: 2597 loss_train: 0.1812 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 2598 loss_train: 0.1830 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 2599 loss_train: 0.1819 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 2600 loss_train: 0.2053 acc_train: 0.8760 acc_val: 0.9800\n",
      "Epoch: 2601 loss_train: 0.1964 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 2602 loss_train: 0.1932 acc_train: 0.8834 acc_val: 0.9800\n",
      "Epoch: 2603 loss_train: 0.2015 acc_train: 0.8812 acc_val: 0.9800\n",
      "Epoch: 2604 loss_train: 0.1803 acc_train: 0.8990 acc_val: 0.9800\n",
      "Epoch: 2605 loss_train: 0.1831 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 2606 loss_train: 0.1768 acc_train: 0.9005 acc_val: 0.9800\n",
      "Epoch: 2607 loss_train: 0.1836 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 2608 loss_train: 0.1777 acc_train: 0.8953 acc_val: 0.9800\n",
      "Epoch: 2609 loss_train: 0.1658 acc_train: 0.9057 acc_val: 0.9800\n",
      "Epoch: 2610 loss_train: 0.1966 acc_train: 0.8797 acc_val: 0.9800\n",
      "Epoch: 2611 loss_train: 0.1789 acc_train: 0.9013 acc_val: 0.9800\n",
      "Epoch: 2612 loss_train: 0.1711 acc_train: 0.8990 acc_val: 0.9800\n",
      "Epoch: 2613 loss_train: 0.1968 acc_train: 0.8805 acc_val: 0.9800\n",
      "Epoch: 2614 loss_train: 0.1861 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 2615 loss_train: 0.1831 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 2616 loss_train: 0.1736 acc_train: 0.9005 acc_val: 0.9800\n",
      "Epoch: 2617 loss_train: 0.1924 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 2618 loss_train: 0.1760 acc_train: 0.8983 acc_val: 0.9800\n",
      "Epoch: 2619 loss_train: 0.2063 acc_train: 0.8768 acc_val: 0.9800\n",
      "Epoch: 2620 loss_train: 0.2011 acc_train: 0.8827 acc_val: 0.9800\n",
      "Epoch: 2621 loss_train: 0.1865 acc_train: 0.8961 acc_val: 0.9800\n",
      "Epoch: 2622 loss_train: 0.1875 acc_train: 0.8768 acc_val: 0.9800\n",
      "Epoch: 2623 loss_train: 0.1711 acc_train: 0.9050 acc_val: 0.9800\n",
      "Epoch: 2624 loss_train: 0.1900 acc_train: 0.8834 acc_val: 0.9800\n",
      "Epoch: 2625 loss_train: 0.1870 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 2626 loss_train: 0.1780 acc_train: 0.9005 acc_val: 0.9800\n",
      "Epoch: 2627 loss_train: 0.1909 acc_train: 0.8886 acc_val: 0.9800\n",
      "Epoch: 2628 loss_train: 0.1866 acc_train: 0.8834 acc_val: 0.9800\n",
      "Epoch: 2629 loss_train: 0.1820 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 2630 loss_train: 0.1898 acc_train: 0.8820 acc_val: 0.9800\n",
      "Epoch: 2631 loss_train: 0.1858 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 2632 loss_train: 0.1798 acc_train: 0.8990 acc_val: 0.9800\n",
      "Epoch: 2633 loss_train: 0.1780 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 2634 loss_train: 0.1770 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 2635 loss_train: 0.1837 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 2636 loss_train: 0.1856 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 2637 loss_train: 0.1940 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 2638 loss_train: 0.1906 acc_train: 0.8790 acc_val: 0.9800\n",
      "Epoch: 2639 loss_train: 0.2042 acc_train: 0.8790 acc_val: 0.9800\n",
      "Epoch: 2640 loss_train: 0.1601 acc_train: 0.8968 acc_val: 0.9800\n",
      "Epoch: 2641 loss_train: 0.1940 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 2642 loss_train: 0.1808 acc_train: 0.8961 acc_val: 0.9800\n",
      "Epoch: 2643 loss_train: 0.1671 acc_train: 0.9005 acc_val: 0.9800\n",
      "Epoch: 2644 loss_train: 0.1823 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 2645 loss_train: 0.1794 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 2646 loss_train: 0.1990 acc_train: 0.8760 acc_val: 0.9800\n",
      "Epoch: 2647 loss_train: 0.1825 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 2648 loss_train: 0.1770 acc_train: 0.9042 acc_val: 0.9800\n",
      "Epoch: 2649 loss_train: 0.2021 acc_train: 0.8790 acc_val: 0.9800\n",
      "Epoch: 2650 loss_train: 0.1726 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 2651 loss_train: 0.1961 acc_train: 0.8834 acc_val: 0.9800\n",
      "Epoch: 2652 loss_train: 0.1987 acc_train: 0.8820 acc_val: 0.9800\n",
      "Epoch: 2653 loss_train: 0.1923 acc_train: 0.8782 acc_val: 0.9800\n",
      "Epoch: 2654 loss_train: 0.2079 acc_train: 0.8842 acc_val: 0.9800\n",
      "Epoch: 2655 loss_train: 0.1732 acc_train: 0.9042 acc_val: 0.9800\n",
      "Epoch: 2656 loss_train: 0.1877 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 2657 loss_train: 0.1698 acc_train: 0.9042 acc_val: 0.9800\n",
      "Epoch: 2658 loss_train: 0.2057 acc_train: 0.8753 acc_val: 0.9800\n",
      "Epoch: 2659 loss_train: 0.1889 acc_train: 0.8842 acc_val: 0.9800\n",
      "Epoch: 2660 loss_train: 0.1681 acc_train: 0.9079 acc_val: 0.9800\n",
      "Epoch: 2661 loss_train: 0.1827 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 2662 loss_train: 0.1854 acc_train: 0.8953 acc_val: 0.9800\n",
      "Epoch: 2663 loss_train: 0.1742 acc_train: 0.8953 acc_val: 0.9800\n",
      "Epoch: 2664 loss_train: 0.1910 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 2665 loss_train: 0.1857 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 2666 loss_train: 0.1954 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 2667 loss_train: 0.1830 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 2668 loss_train: 0.1761 acc_train: 0.8953 acc_val: 0.9800\n",
      "Epoch: 2669 loss_train: 0.1771 acc_train: 0.9005 acc_val: 0.9800\n",
      "Epoch: 2670 loss_train: 0.1991 acc_train: 0.8797 acc_val: 0.9800\n",
      "Epoch: 2671 loss_train: 0.1741 acc_train: 0.9027 acc_val: 0.9800\n",
      "Epoch: 2672 loss_train: 0.1913 acc_train: 0.8968 acc_val: 0.9800\n",
      "Epoch: 2673 loss_train: 0.1952 acc_train: 0.8827 acc_val: 0.9800\n",
      "Epoch: 2674 loss_train: 0.1792 acc_train: 0.8886 acc_val: 0.9800\n",
      "Epoch: 2675 loss_train: 0.1745 acc_train: 0.9013 acc_val: 0.9800\n",
      "Epoch: 2676 loss_train: 0.1858 acc_train: 0.8842 acc_val: 0.9800\n",
      "Epoch: 2677 loss_train: 0.1914 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 2678 loss_train: 0.1915 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 2679 loss_train: 0.1974 acc_train: 0.8716 acc_val: 0.9800\n",
      "Epoch: 2680 loss_train: 0.1800 acc_train: 0.8961 acc_val: 0.9800\n",
      "Epoch: 2681 loss_train: 0.1852 acc_train: 0.8961 acc_val: 0.9800\n",
      "Epoch: 2682 loss_train: 0.1987 acc_train: 0.8797 acc_val: 0.9800\n",
      "Epoch: 2683 loss_train: 0.1841 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 2684 loss_train: 0.1636 acc_train: 0.9057 acc_val: 0.9800\n",
      "Epoch: 2685 loss_train: 0.1946 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 2686 loss_train: 0.1959 acc_train: 0.8805 acc_val: 0.9800\n",
      "Epoch: 2687 loss_train: 0.1872 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 2688 loss_train: 0.1920 acc_train: 0.8886 acc_val: 0.9800\n",
      "Epoch: 2689 loss_train: 0.1515 acc_train: 0.9124 acc_val: 0.9800\n",
      "Epoch: 2690 loss_train: 0.1996 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 2691 loss_train: 0.1761 acc_train: 0.9013 acc_val: 0.9800\n",
      "Epoch: 2692 loss_train: 0.1907 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 2693 loss_train: 0.1881 acc_train: 0.8983 acc_val: 0.9800\n",
      "Epoch: 2694 loss_train: 0.1846 acc_train: 0.9035 acc_val: 0.9800\n",
      "Epoch: 2695 loss_train: 0.1730 acc_train: 0.9005 acc_val: 0.9800\n",
      "Epoch: 2696 loss_train: 0.2004 acc_train: 0.8842 acc_val: 0.9800\n",
      "Epoch: 2697 loss_train: 0.1890 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 2698 loss_train: 0.1925 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 2699 loss_train: 0.1936 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 2700 loss_train: 0.1929 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 2701 loss_train: 0.2014 acc_train: 0.8834 acc_val: 0.9800\n",
      "Epoch: 2702 loss_train: 0.1812 acc_train: 0.8976 acc_val: 0.9800\n",
      "Epoch: 2703 loss_train: 0.1939 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 2704 loss_train: 0.1867 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 2705 loss_train: 0.1946 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 2706 loss_train: 0.1648 acc_train: 0.9050 acc_val: 0.9800\n",
      "Epoch: 2707 loss_train: 0.1749 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 2708 loss_train: 0.1865 acc_train: 0.8909 acc_val: 0.9800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2709 loss_train: 0.1881 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 2710 loss_train: 0.1644 acc_train: 0.8968 acc_val: 0.9800\n",
      "Epoch: 2711 loss_train: 0.1929 acc_train: 0.8820 acc_val: 0.9800\n",
      "Epoch: 2712 loss_train: 0.1866 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 2713 loss_train: 0.1738 acc_train: 0.9013 acc_val: 0.9800\n",
      "Epoch: 2714 loss_train: 0.1734 acc_train: 0.9020 acc_val: 0.9800\n",
      "Epoch: 2715 loss_train: 0.1925 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 2716 loss_train: 0.1852 acc_train: 0.8961 acc_val: 0.9800\n",
      "Epoch: 2717 loss_train: 0.1706 acc_train: 0.8968 acc_val: 0.9800\n",
      "Epoch: 2718 loss_train: 0.2177 acc_train: 0.8753 acc_val: 0.9800\n",
      "Epoch: 2719 loss_train: 0.1717 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 2720 loss_train: 0.1892 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 2721 loss_train: 0.2013 acc_train: 0.8827 acc_val: 0.9800\n",
      "Epoch: 2722 loss_train: 0.1950 acc_train: 0.8827 acc_val: 0.9800\n",
      "Epoch: 2723 loss_train: 0.1896 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 2724 loss_train: 0.1853 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 2725 loss_train: 0.1923 acc_train: 0.8827 acc_val: 0.9800\n",
      "Epoch: 2726 loss_train: 0.1810 acc_train: 0.8864 acc_val: 0.9800\n",
      "Epoch: 2727 loss_train: 0.2024 acc_train: 0.8805 acc_val: 0.9800\n",
      "Epoch: 2728 loss_train: 0.1860 acc_train: 0.8864 acc_val: 0.9800\n",
      "Epoch: 2729 loss_train: 0.1898 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 2730 loss_train: 0.1701 acc_train: 0.9035 acc_val: 0.9800\n",
      "Epoch: 2731 loss_train: 0.2037 acc_train: 0.8834 acc_val: 0.9800\n",
      "Epoch: 2732 loss_train: 0.1716 acc_train: 0.9013 acc_val: 0.9800\n",
      "Epoch: 2733 loss_train: 0.1729 acc_train: 0.8983 acc_val: 0.9800\n",
      "Epoch: 2734 loss_train: 0.1874 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 2735 loss_train: 0.1894 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 2736 loss_train: 0.1954 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 2737 loss_train: 0.1861 acc_train: 0.8998 acc_val: 0.9800\n",
      "Epoch: 2738 loss_train: 0.2021 acc_train: 0.8842 acc_val: 0.9800\n",
      "Epoch: 2739 loss_train: 0.1870 acc_train: 0.8864 acc_val: 0.9800\n",
      "Epoch: 2740 loss_train: 0.1864 acc_train: 0.8812 acc_val: 0.9800\n",
      "Epoch: 2741 loss_train: 0.1685 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 2742 loss_train: 0.1837 acc_train: 0.8886 acc_val: 0.9800\n",
      "Epoch: 2743 loss_train: 0.1913 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 2744 loss_train: 0.1937 acc_train: 0.8834 acc_val: 0.9800\n",
      "Epoch: 2745 loss_train: 0.1955 acc_train: 0.8797 acc_val: 0.9800\n",
      "Epoch: 2746 loss_train: 0.1718 acc_train: 0.8953 acc_val: 0.9800\n",
      "Epoch: 2747 loss_train: 0.1734 acc_train: 0.9020 acc_val: 0.9800\n",
      "Epoch: 2748 loss_train: 0.1933 acc_train: 0.8797 acc_val: 0.9800\n",
      "Epoch: 2749 loss_train: 0.1810 acc_train: 0.8886 acc_val: 0.9800\n",
      "Epoch: 2750 loss_train: 0.2035 acc_train: 0.8886 acc_val: 0.9800\n",
      "Epoch: 2751 loss_train: 0.1664 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 2752 loss_train: 0.1721 acc_train: 0.8983 acc_val: 0.9800\n",
      "Epoch: 2753 loss_train: 0.1927 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 2754 loss_train: 0.1812 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 2755 loss_train: 0.1803 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 2756 loss_train: 0.1699 acc_train: 0.8990 acc_val: 0.9800\n",
      "Epoch: 2757 loss_train: 0.1906 acc_train: 0.8968 acc_val: 0.9800\n",
      "Epoch: 2758 loss_train: 0.1798 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 2759 loss_train: 0.2081 acc_train: 0.8797 acc_val: 0.9800\n",
      "Epoch: 2760 loss_train: 0.1791 acc_train: 0.8961 acc_val: 0.9800\n",
      "Epoch: 2761 loss_train: 0.2168 acc_train: 0.8693 acc_val: 0.9800\n",
      "Epoch: 2762 loss_train: 0.1942 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 2763 loss_train: 0.1829 acc_train: 0.8983 acc_val: 0.9800\n",
      "Epoch: 2764 loss_train: 0.1898 acc_train: 0.8968 acc_val: 0.9800\n",
      "Epoch: 2765 loss_train: 0.1907 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 2766 loss_train: 0.1896 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 2767 loss_train: 0.1746 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 2768 loss_train: 0.1825 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 2769 loss_train: 0.1883 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 2770 loss_train: 0.1704 acc_train: 0.8998 acc_val: 0.9800\n",
      "Epoch: 2771 loss_train: 0.2054 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 2772 loss_train: 0.1911 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 2773 loss_train: 0.1878 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 2774 loss_train: 0.1996 acc_train: 0.8909 acc_val: 0.9778\n",
      "Epoch: 2775 loss_train: 0.1934 acc_train: 0.8820 acc_val: 0.9778\n",
      "Epoch: 2776 loss_train: 0.1813 acc_train: 0.8916 acc_val: 0.9778\n",
      "Epoch: 2777 loss_train: 0.5942 acc_train: 0.9013 acc_val: 0.9800\n",
      "Epoch: 2778 loss_train: 0.1778 acc_train: 0.9050 acc_val: 0.9800\n",
      "Epoch: 2779 loss_train: 0.1933 acc_train: 0.8805 acc_val: 0.9800\n",
      "Epoch: 2780 loss_train: 0.1879 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 2781 loss_train: 0.1920 acc_train: 0.8745 acc_val: 0.9800\n",
      "Epoch: 2782 loss_train: 0.1826 acc_train: 0.9005 acc_val: 0.9800\n",
      "Epoch: 2783 loss_train: 0.1785 acc_train: 0.8976 acc_val: 0.9800\n",
      "Epoch: 2784 loss_train: 0.1824 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 2785 loss_train: 0.1717 acc_train: 0.8976 acc_val: 0.9800\n",
      "Epoch: 2786 loss_train: 0.1749 acc_train: 0.8990 acc_val: 0.9800\n",
      "Epoch: 2787 loss_train: 0.1922 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 2788 loss_train: 0.1685 acc_train: 0.9079 acc_val: 0.9800\n",
      "Epoch: 2789 loss_train: 0.1820 acc_train: 0.8983 acc_val: 0.9800\n",
      "Epoch: 2790 loss_train: 0.1721 acc_train: 0.8998 acc_val: 0.9800\n",
      "Epoch: 2791 loss_train: 0.1997 acc_train: 0.8812 acc_val: 0.9800\n",
      "Epoch: 2792 loss_train: 0.1853 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 2793 loss_train: 0.1691 acc_train: 0.9013 acc_val: 0.9800\n",
      "Epoch: 2794 loss_train: 0.1736 acc_train: 0.9013 acc_val: 0.9800\n",
      "Epoch: 2795 loss_train: 0.1924 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 2796 loss_train: 0.2025 acc_train: 0.8805 acc_val: 0.9800\n",
      "Epoch: 2797 loss_train: 0.1861 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 2798 loss_train: 0.1850 acc_train: 0.8961 acc_val: 0.9800\n",
      "Epoch: 2799 loss_train: 0.1908 acc_train: 0.8790 acc_val: 0.9800\n",
      "Epoch: 2800 loss_train: 0.1993 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 2801 loss_train: 0.1906 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 2802 loss_train: 0.1925 acc_train: 0.8983 acc_val: 0.9800\n",
      "Epoch: 2803 loss_train: 0.1776 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 2804 loss_train: 0.1968 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 2805 loss_train: 0.1761 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 2806 loss_train: 0.1798 acc_train: 0.8953 acc_val: 0.9800\n",
      "Epoch: 2807 loss_train: 0.1765 acc_train: 0.8961 acc_val: 0.9800\n",
      "Epoch: 2808 loss_train: 0.1735 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 2809 loss_train: 0.1815 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 2810 loss_train: 0.1839 acc_train: 0.9005 acc_val: 0.9800\n",
      "Epoch: 2811 loss_train: 0.2053 acc_train: 0.8797 acc_val: 0.9800\n",
      "Epoch: 2812 loss_train: 0.1940 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 2813 loss_train: 0.2020 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 2814 loss_train: 0.1925 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 2815 loss_train: 0.1889 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 2816 loss_train: 0.1867 acc_train: 0.8976 acc_val: 0.9800\n",
      "Epoch: 2817 loss_train: 0.1815 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 2818 loss_train: 0.1953 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 2819 loss_train: 0.1787 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 2820 loss_train: 0.1885 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 2821 loss_train: 0.1645 acc_train: 0.9087 acc_val: 0.9800\n",
      "Epoch: 2822 loss_train: 0.1950 acc_train: 0.8760 acc_val: 0.9800\n",
      "Epoch: 2823 loss_train: 0.1907 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 2824 loss_train: 0.1798 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 2825 loss_train: 0.2175 acc_train: 0.8686 acc_val: 0.9800\n",
      "Epoch: 2826 loss_train: 0.1866 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 2827 loss_train: 0.2105 acc_train: 0.8760 acc_val: 0.9800\n",
      "Epoch: 2828 loss_train: 0.1829 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 2829 loss_train: 0.1642 acc_train: 0.9079 acc_val: 0.9800\n",
      "Epoch: 2830 loss_train: 0.1817 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 2831 loss_train: 0.1743 acc_train: 0.8990 acc_val: 0.9800\n",
      "Epoch: 2832 loss_train: 0.1937 acc_train: 0.8790 acc_val: 0.9800\n",
      "Epoch: 2833 loss_train: 0.1797 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 2834 loss_train: 0.1830 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 2835 loss_train: 0.1913 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 2836 loss_train: 0.1742 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 2837 loss_train: 0.2107 acc_train: 0.8790 acc_val: 0.9800\n",
      "Epoch: 2838 loss_train: 0.2003 acc_train: 0.8790 acc_val: 0.9800\n",
      "Epoch: 2839 loss_train: 0.1819 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 2840 loss_train: 0.1937 acc_train: 0.8953 acc_val: 0.9800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2841 loss_train: 0.1679 acc_train: 0.8953 acc_val: 0.9800\n",
      "Epoch: 2842 loss_train: 0.1801 acc_train: 0.8886 acc_val: 0.9800\n",
      "Epoch: 2843 loss_train: 0.1744 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 2844 loss_train: 0.9927 acc_train: 0.8731 acc_val: 0.9800\n",
      "Epoch: 2845 loss_train: 0.1845 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 2846 loss_train: 0.2064 acc_train: 0.8827 acc_val: 0.9800\n",
      "Epoch: 2847 loss_train: 0.1799 acc_train: 0.9013 acc_val: 0.9800\n",
      "Epoch: 2848 loss_train: 0.1831 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 2849 loss_train: 0.1832 acc_train: 0.9020 acc_val: 0.9800\n",
      "Epoch: 2850 loss_train: 0.1812 acc_train: 0.8961 acc_val: 0.9800\n",
      "Epoch: 2851 loss_train: 0.1822 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 2852 loss_train: 0.1859 acc_train: 0.8976 acc_val: 0.9800\n",
      "Epoch: 2853 loss_train: 0.1728 acc_train: 0.9050 acc_val: 0.9800\n",
      "Epoch: 2854 loss_train: 0.2061 acc_train: 0.8827 acc_val: 0.9800\n",
      "Epoch: 2855 loss_train: 0.1775 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 2856 loss_train: 0.1710 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 2857 loss_train: 0.1939 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 2858 loss_train: 0.1726 acc_train: 0.9013 acc_val: 0.9800\n",
      "Epoch: 2859 loss_train: 0.1842 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 2860 loss_train: 0.1779 acc_train: 0.8983 acc_val: 0.9800\n",
      "Epoch: 2861 loss_train: 0.1768 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 2862 loss_train: 0.1905 acc_train: 0.8886 acc_val: 0.9800\n",
      "Epoch: 2863 loss_train: 0.1814 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 2864 loss_train: 0.1976 acc_train: 0.8886 acc_val: 0.9800\n",
      "Epoch: 2865 loss_train: 0.1892 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 2866 loss_train: 0.1864 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 2867 loss_train: 0.1795 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 2868 loss_train: 0.1924 acc_train: 0.8805 acc_val: 0.9800\n",
      "Epoch: 2869 loss_train: 0.1716 acc_train: 0.8998 acc_val: 0.9800\n",
      "Epoch: 2870 loss_train: 0.1858 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 2871 loss_train: 0.1844 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 2872 loss_train: 0.1995 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 2873 loss_train: 0.1909 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 2874 loss_train: 0.1923 acc_train: 0.8953 acc_val: 0.9800\n",
      "Epoch: 2875 loss_train: 0.1956 acc_train: 0.8842 acc_val: 0.9800\n",
      "Epoch: 2876 loss_train: 0.1806 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 2877 loss_train: 0.1817 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 2878 loss_train: 0.1708 acc_train: 0.9005 acc_val: 0.9800\n",
      "Epoch: 2879 loss_train: 0.2040 acc_train: 0.8827 acc_val: 0.9800\n",
      "Epoch: 2880 loss_train: 0.1724 acc_train: 0.8998 acc_val: 0.9800\n",
      "Epoch: 2881 loss_train: 0.1882 acc_train: 0.8886 acc_val: 0.9800\n",
      "Epoch: 2882 loss_train: 0.1716 acc_train: 0.8968 acc_val: 0.9800\n",
      "Epoch: 2883 loss_train: 0.1743 acc_train: 0.9109 acc_val: 0.9800\n",
      "Epoch: 2884 loss_train: 0.1765 acc_train: 0.8961 acc_val: 0.9800\n",
      "Epoch: 2885 loss_train: 0.1776 acc_train: 0.8968 acc_val: 0.9800\n",
      "Epoch: 2886 loss_train: 0.1674 acc_train: 0.9050 acc_val: 0.9800\n",
      "Epoch: 2887 loss_train: 0.1946 acc_train: 0.8775 acc_val: 0.9800\n",
      "Epoch: 2888 loss_train: 0.1925 acc_train: 0.8805 acc_val: 0.9800\n",
      "Epoch: 2889 loss_train: 0.2066 acc_train: 0.8738 acc_val: 0.9800\n",
      "Epoch: 2890 loss_train: 0.1777 acc_train: 0.8983 acc_val: 0.9800\n",
      "Epoch: 2891 loss_train: 0.1824 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 2892 loss_train: 0.1794 acc_train: 0.9013 acc_val: 0.9800\n",
      "Epoch: 2893 loss_train: 0.1873 acc_train: 0.8864 acc_val: 0.9800\n",
      "Epoch: 2894 loss_train: 0.1938 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 2895 loss_train: 0.1818 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 2896 loss_train: 0.1933 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 2897 loss_train: 0.1888 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 2898 loss_train: 0.1926 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 2899 loss_train: 0.1915 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 2900 loss_train: 0.1493 acc_train: 0.9154 acc_val: 0.9800\n",
      "Epoch: 2901 loss_train: 0.1829 acc_train: 0.8983 acc_val: 0.9800\n",
      "Epoch: 2902 loss_train: 0.1903 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 2903 loss_train: 0.1726 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 2904 loss_train: 0.1934 acc_train: 0.8864 acc_val: 0.9800\n",
      "Epoch: 2905 loss_train: 0.1891 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 2906 loss_train: 0.1858 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 2907 loss_train: 0.1913 acc_train: 0.8886 acc_val: 0.9800\n",
      "Epoch: 2908 loss_train: 0.1867 acc_train: 0.8976 acc_val: 0.9800\n",
      "Epoch: 2909 loss_train: 0.2082 acc_train: 0.8790 acc_val: 0.9800\n",
      "Epoch: 2910 loss_train: 0.1921 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 2911 loss_train: 0.1825 acc_train: 0.9050 acc_val: 0.9800\n",
      "Epoch: 2912 loss_train: 0.2052 acc_train: 0.8731 acc_val: 0.9800\n",
      "Epoch: 2913 loss_train: 0.1769 acc_train: 0.9042 acc_val: 0.9800\n",
      "Epoch: 2914 loss_train: 0.2059 acc_train: 0.8768 acc_val: 0.9800\n",
      "Epoch: 2915 loss_train: 0.1861 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 2916 loss_train: 0.1937 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 2917 loss_train: 0.1771 acc_train: 0.8983 acc_val: 0.9800\n",
      "Epoch: 2918 loss_train: 0.1968 acc_train: 0.8864 acc_val: 0.9800\n",
      "Epoch: 2919 loss_train: 0.1728 acc_train: 0.8953 acc_val: 0.9800\n",
      "Epoch: 2920 loss_train: 0.1875 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 2921 loss_train: 0.1892 acc_train: 0.8834 acc_val: 0.9800\n",
      "Epoch: 2922 loss_train: 0.1850 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 2923 loss_train: 0.1810 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 2924 loss_train: 0.2051 acc_train: 0.8797 acc_val: 0.9800\n",
      "Epoch: 2925 loss_train: 0.1840 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 2926 loss_train: 0.1865 acc_train: 0.8886 acc_val: 0.9800\n",
      "Epoch: 2927 loss_train: 0.1867 acc_train: 0.8998 acc_val: 0.9800\n",
      "Epoch: 2928 loss_train: 0.1795 acc_train: 0.8961 acc_val: 0.9800\n",
      "Epoch: 2929 loss_train: 0.1914 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 2930 loss_train: 0.1784 acc_train: 0.8990 acc_val: 0.9800\n",
      "Epoch: 2931 loss_train: 0.2003 acc_train: 0.8805 acc_val: 0.9800\n",
      "Epoch: 2932 loss_train: 0.1880 acc_train: 0.8864 acc_val: 0.9800\n",
      "Epoch: 2933 loss_train: 0.1581 acc_train: 0.9050 acc_val: 0.9800\n",
      "Epoch: 2934 loss_train: 0.1743 acc_train: 0.8953 acc_val: 0.9800\n",
      "Epoch: 2935 loss_train: 0.1998 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 2936 loss_train: 0.1887 acc_train: 0.8812 acc_val: 0.9800\n",
      "Epoch: 2937 loss_train: 0.1845 acc_train: 0.8976 acc_val: 0.9800\n",
      "Epoch: 2938 loss_train: 0.1865 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 2939 loss_train: 0.1898 acc_train: 0.8797 acc_val: 0.9800\n",
      "Epoch: 2940 loss_train: 0.1906 acc_train: 0.8805 acc_val: 0.9800\n",
      "Epoch: 2941 loss_train: 0.1881 acc_train: 0.8976 acc_val: 0.9800\n",
      "Epoch: 2942 loss_train: 0.1923 acc_train: 0.8820 acc_val: 0.9800\n",
      "Epoch: 2943 loss_train: 0.1756 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 2944 loss_train: 0.1747 acc_train: 0.9050 acc_val: 0.9800\n",
      "Epoch: 2945 loss_train: 0.1993 acc_train: 0.8827 acc_val: 0.9800\n",
      "Epoch: 2946 loss_train: 0.1866 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 2947 loss_train: 0.1980 acc_train: 0.8864 acc_val: 0.9800\n",
      "Epoch: 2948 loss_train: 0.1744 acc_train: 0.8998 acc_val: 0.9800\n",
      "Epoch: 2949 loss_train: 0.1951 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 2950 loss_train: 0.1696 acc_train: 0.8953 acc_val: 0.9800\n",
      "Epoch: 2951 loss_train: 0.1729 acc_train: 0.8968 acc_val: 0.9800\n",
      "Epoch: 2952 loss_train: 0.1890 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 2953 loss_train: 0.1846 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 2954 loss_train: 0.2073 acc_train: 0.8745 acc_val: 0.9800\n",
      "Epoch: 2955 loss_train: 0.1963 acc_train: 0.8820 acc_val: 0.9800\n",
      "Epoch: 2956 loss_train: 0.2059 acc_train: 0.8775 acc_val: 0.9800\n",
      "Epoch: 2957 loss_train: 0.1924 acc_train: 0.8842 acc_val: 0.9800\n",
      "Epoch: 2958 loss_train: 0.1859 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 2959 loss_train: 0.1795 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 2960 loss_train: 0.1819 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 2961 loss_train: 0.1695 acc_train: 0.9035 acc_val: 0.9800\n",
      "Epoch: 2962 loss_train: 0.1825 acc_train: 0.8886 acc_val: 0.9800\n",
      "Epoch: 2963 loss_train: 0.2050 acc_train: 0.8716 acc_val: 0.9800\n",
      "Epoch: 2964 loss_train: 0.1964 acc_train: 0.8834 acc_val: 0.9800\n",
      "Epoch: 2965 loss_train: 0.1944 acc_train: 0.8842 acc_val: 0.9800\n",
      "Epoch: 2966 loss_train: 0.1889 acc_train: 0.8953 acc_val: 0.9800\n",
      "Epoch: 2967 loss_train: 0.1806 acc_train: 0.9013 acc_val: 0.9800\n",
      "Epoch: 2968 loss_train: 0.1762 acc_train: 0.8961 acc_val: 0.9800\n",
      "Epoch: 2969 loss_train: 0.1775 acc_train: 0.9065 acc_val: 0.9800\n",
      "Epoch: 2970 loss_train: 0.1957 acc_train: 0.8872 acc_val: 0.9800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2971 loss_train: 0.1747 acc_train: 0.8968 acc_val: 0.9800\n",
      "Epoch: 2972 loss_train: 0.1878 acc_train: 0.8812 acc_val: 0.9800\n",
      "Epoch: 2973 loss_train: 0.2009 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 2974 loss_train: 0.1811 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 2975 loss_train: 0.2008 acc_train: 0.8820 acc_val: 0.9800\n",
      "Epoch: 2976 loss_train: 0.1787 acc_train: 0.8976 acc_val: 0.9800\n",
      "Epoch: 2977 loss_train: 0.1928 acc_train: 0.8842 acc_val: 0.9800\n",
      "Epoch: 2978 loss_train: 0.1932 acc_train: 0.8820 acc_val: 0.9800\n",
      "Epoch: 2979 loss_train: 0.1951 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 2980 loss_train: 0.1942 acc_train: 0.8886 acc_val: 0.9800\n",
      "Epoch: 2981 loss_train: 0.1985 acc_train: 0.8827 acc_val: 0.9800\n",
      "Epoch: 2982 loss_train: 0.1870 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 2983 loss_train: 0.1836 acc_train: 0.8976 acc_val: 0.9800\n",
      "Epoch: 2984 loss_train: 0.1867 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 2985 loss_train: 0.1925 acc_train: 0.8834 acc_val: 0.9800\n",
      "Epoch: 2986 loss_train: 0.2019 acc_train: 0.8820 acc_val: 0.9800\n",
      "Epoch: 2987 loss_train: 0.1818 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 2988 loss_train: 0.1910 acc_train: 0.8820 acc_val: 0.9800\n",
      "Epoch: 2989 loss_train: 0.1955 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 2990 loss_train: 0.1896 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 2991 loss_train: 0.1939 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 2992 loss_train: 0.1738 acc_train: 0.9035 acc_val: 0.9800\n",
      "Epoch: 2993 loss_train: 0.1878 acc_train: 0.8968 acc_val: 0.9800\n",
      "Epoch: 2994 loss_train: 0.1987 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 2995 loss_train: 0.1839 acc_train: 0.8976 acc_val: 0.9800\n",
      "Epoch: 2996 loss_train: 0.1804 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 2997 loss_train: 0.1773 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 2998 loss_train: 0.1819 acc_train: 0.8968 acc_val: 0.9800\n",
      "Epoch: 2999 loss_train: 0.1958 acc_train: 0.8775 acc_val: 0.9800\n",
      "Epoch: 3000 loss_train: 0.1788 acc_train: 0.8961 acc_val: 0.9800\n",
      "Epoch: 3001 loss_train: 0.1761 acc_train: 0.9020 acc_val: 0.9800\n",
      "Epoch: 3002 loss_train: 0.1850 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 3003 loss_train: 0.1982 acc_train: 0.8820 acc_val: 0.9800\n",
      "Epoch: 3004 loss_train: 0.1895 acc_train: 0.8820 acc_val: 0.9800\n",
      "Epoch: 3005 loss_train: 0.1956 acc_train: 0.8827 acc_val: 0.9800\n",
      "Epoch: 3006 loss_train: 0.1950 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 3007 loss_train: 0.1879 acc_train: 0.8842 acc_val: 0.9800\n",
      "Epoch: 3008 loss_train: 0.1880 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 3009 loss_train: 0.1821 acc_train: 0.8886 acc_val: 0.9800\n",
      "Epoch: 3010 loss_train: 0.2005 acc_train: 0.8790 acc_val: 0.9800\n",
      "Epoch: 3011 loss_train: 0.1833 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 3012 loss_train: 0.1751 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 3013 loss_train: 0.1633 acc_train: 0.9050 acc_val: 0.9800\n",
      "Epoch: 3014 loss_train: 0.1873 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 3015 loss_train: 0.1796 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 3016 loss_train: 0.1630 acc_train: 0.9027 acc_val: 0.9800\n",
      "Epoch: 3017 loss_train: 0.1821 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 3018 loss_train: 0.1739 acc_train: 0.9020 acc_val: 0.9800\n",
      "Epoch: 3019 loss_train: 0.1990 acc_train: 0.8864 acc_val: 0.9800\n",
      "Epoch: 3020 loss_train: 0.1703 acc_train: 0.9094 acc_val: 0.9800\n",
      "Epoch: 3021 loss_train: 0.1817 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 3022 loss_train: 0.1789 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 3023 loss_train: 0.1839 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 3024 loss_train: 0.1799 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 3025 loss_train: 0.2038 acc_train: 0.8820 acc_val: 0.9800\n",
      "Epoch: 3026 loss_train: 0.1691 acc_train: 0.9079 acc_val: 0.9800\n",
      "Epoch: 3027 loss_train: 0.1804 acc_train: 0.8976 acc_val: 0.9800\n",
      "Epoch: 3028 loss_train: 0.1819 acc_train: 0.8886 acc_val: 0.9800\n",
      "Epoch: 3029 loss_train: 0.1830 acc_train: 0.8886 acc_val: 0.9800\n",
      "Epoch: 3030 loss_train: 0.1865 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 3031 loss_train: 0.1703 acc_train: 0.9050 acc_val: 0.9800\n",
      "Epoch: 3032 loss_train: 0.2067 acc_train: 0.8738 acc_val: 0.9800\n",
      "Epoch: 3033 loss_train: 0.1911 acc_train: 0.8775 acc_val: 0.9800\n",
      "Epoch: 3034 loss_train: 0.1868 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 3035 loss_train: 0.1986 acc_train: 0.8775 acc_val: 0.9800\n",
      "Epoch: 3036 loss_train: 0.1921 acc_train: 0.8812 acc_val: 0.9800\n",
      "Epoch: 3037 loss_train: 0.1810 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 3038 loss_train: 0.1770 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 3039 loss_train: 0.1695 acc_train: 0.9027 acc_val: 0.9800\n",
      "Epoch: 3040 loss_train: 0.1906 acc_train: 0.8864 acc_val: 0.9800\n",
      "Epoch: 3041 loss_train: 0.1996 acc_train: 0.8827 acc_val: 0.9800\n",
      "Epoch: 3042 loss_train: 0.1733 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 3043 loss_train: 0.1771 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 3044 loss_train: 0.1765 acc_train: 0.8990 acc_val: 0.9800\n",
      "Epoch: 3045 loss_train: 0.1899 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 3046 loss_train: 0.1860 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 3047 loss_train: 0.1775 acc_train: 0.8961 acc_val: 0.9800\n",
      "Epoch: 3048 loss_train: 0.1833 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 3049 loss_train: 0.2127 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 3050 loss_train: 0.1882 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 3051 loss_train: 0.1724 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 3052 loss_train: 0.2015 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 3053 loss_train: 0.1853 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 3054 loss_train: 0.1836 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 3055 loss_train: 0.1915 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 3056 loss_train: 0.2194 acc_train: 0.8731 acc_val: 0.9800\n",
      "Epoch: 3057 loss_train: 0.2054 acc_train: 0.8834 acc_val: 0.9800\n",
      "Epoch: 3058 loss_train: 0.1771 acc_train: 0.9027 acc_val: 0.9800\n",
      "Epoch: 3059 loss_train: 0.1884 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 3060 loss_train: 0.1828 acc_train: 0.8790 acc_val: 0.9800\n",
      "Epoch: 3061 loss_train: 0.1727 acc_train: 0.8990 acc_val: 0.9800\n",
      "Epoch: 3062 loss_train: 0.1649 acc_train: 0.9042 acc_val: 0.9800\n",
      "Epoch: 3063 loss_train: 0.1706 acc_train: 0.8998 acc_val: 0.9800\n",
      "Epoch: 3064 loss_train: 0.1837 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 3065 loss_train: 0.1846 acc_train: 0.8820 acc_val: 0.9800\n",
      "Epoch: 3066 loss_train: 0.1884 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 3067 loss_train: 0.1852 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 3068 loss_train: 0.1779 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 3069 loss_train: 0.1967 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 3070 loss_train: 0.1950 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 3071 loss_train: 0.1720 acc_train: 0.8998 acc_val: 0.9800\n",
      "Epoch: 3072 loss_train: 0.2098 acc_train: 0.8782 acc_val: 0.9800\n",
      "Epoch: 3073 loss_train: 0.1921 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 3074 loss_train: 0.1994 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 3075 loss_train: 0.1880 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 3076 loss_train: 0.2068 acc_train: 0.8760 acc_val: 0.9800\n",
      "Epoch: 3077 loss_train: 0.1723 acc_train: 0.9013 acc_val: 0.9800\n",
      "Epoch: 3078 loss_train: 0.1970 acc_train: 0.8961 acc_val: 0.9800\n",
      "Epoch: 3079 loss_train: 0.1753 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 3080 loss_train: 0.1820 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 3081 loss_train: 0.1967 acc_train: 0.8820 acc_val: 0.9800\n",
      "Epoch: 3082 loss_train: 0.1964 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 3083 loss_train: 0.1978 acc_train: 0.8886 acc_val: 0.9800\n",
      "Epoch: 3084 loss_train: 0.1912 acc_train: 0.8834 acc_val: 0.9800\n",
      "Epoch: 3085 loss_train: 0.1841 acc_train: 0.8968 acc_val: 0.9800\n",
      "Epoch: 3086 loss_train: 0.2004 acc_train: 0.8820 acc_val: 0.9800\n",
      "Epoch: 3087 loss_train: 0.1780 acc_train: 0.8976 acc_val: 0.9800\n",
      "Epoch: 3088 loss_train: 0.1724 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 3089 loss_train: 0.1804 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 3090 loss_train: 0.1734 acc_train: 0.8961 acc_val: 0.9800\n",
      "Epoch: 3091 loss_train: 0.1949 acc_train: 0.8834 acc_val: 0.9800\n",
      "Epoch: 3092 loss_train: 0.1950 acc_train: 0.8812 acc_val: 0.9800\n",
      "Epoch: 3093 loss_train: 0.1935 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 3094 loss_train: 0.1805 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 3095 loss_train: 0.1828 acc_train: 0.8834 acc_val: 0.9800\n",
      "Epoch: 3096 loss_train: 0.1896 acc_train: 0.8812 acc_val: 0.9800\n",
      "Epoch: 3097 loss_train: 0.2004 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 3098 loss_train: 0.1840 acc_train: 0.8968 acc_val: 0.9800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3099 loss_train: 0.1918 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 3100 loss_train: 0.1795 acc_train: 0.8961 acc_val: 0.9800\n",
      "Epoch: 3101 loss_train: 0.1694 acc_train: 0.9072 acc_val: 0.9800\n",
      "Epoch: 3102 loss_train: 0.1889 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 3103 loss_train: 0.1576 acc_train: 0.9094 acc_val: 0.9800\n",
      "Epoch: 3104 loss_train: 0.2034 acc_train: 0.8768 acc_val: 0.9800\n",
      "Epoch: 3105 loss_train: 0.1965 acc_train: 0.8820 acc_val: 0.9800\n",
      "Epoch: 3106 loss_train: 0.1752 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 3107 loss_train: 0.1921 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 3108 loss_train: 0.1803 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 3109 loss_train: 0.1907 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 3110 loss_train: 0.1924 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 3111 loss_train: 0.2191 acc_train: 0.8723 acc_val: 0.9800\n",
      "Epoch: 3112 loss_train: 0.1661 acc_train: 0.8968 acc_val: 0.9800\n",
      "Epoch: 3113 loss_train: 0.1972 acc_train: 0.8723 acc_val: 0.9800\n",
      "Epoch: 3114 loss_train: 0.1896 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 3115 loss_train: 0.1784 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 3116 loss_train: 0.2010 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 3117 loss_train: 0.1725 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 3118 loss_train: 0.1726 acc_train: 0.8983 acc_val: 0.9800\n",
      "Epoch: 3119 loss_train: 0.1931 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 3120 loss_train: 0.2040 acc_train: 0.8782 acc_val: 0.9800\n",
      "Epoch: 3121 loss_train: 0.1978 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 3122 loss_train: 0.1823 acc_train: 0.8864 acc_val: 0.9800\n",
      "Epoch: 3123 loss_train: 0.1896 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 3124 loss_train: 0.1957 acc_train: 0.8797 acc_val: 0.9800\n",
      "Epoch: 3125 loss_train: 0.1984 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 3126 loss_train: 0.1667 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 3127 loss_train: 0.1916 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 3128 loss_train: 0.1982 acc_train: 0.8745 acc_val: 0.9800\n",
      "Epoch: 3129 loss_train: 0.2013 acc_train: 0.8768 acc_val: 0.9800\n",
      "Epoch: 3130 loss_train: 0.1729 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 3131 loss_train: 0.1781 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 3132 loss_train: 0.1935 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 3133 loss_train: 0.1749 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 3134 loss_train: 0.1798 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 3135 loss_train: 0.1873 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 3136 loss_train: 0.1861 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 3137 loss_train: 0.1748 acc_train: 0.8983 acc_val: 0.9800\n",
      "Epoch: 3138 loss_train: 0.2066 acc_train: 0.8775 acc_val: 0.9800\n",
      "Epoch: 3139 loss_train: 0.1919 acc_train: 0.8834 acc_val: 0.9800\n",
      "Epoch: 3140 loss_train: 0.1948 acc_train: 0.8805 acc_val: 0.9800\n",
      "Epoch: 3141 loss_train: 0.1845 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 3142 loss_train: 0.1722 acc_train: 0.9020 acc_val: 0.9800\n",
      "Epoch: 3143 loss_train: 0.1860 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 3144 loss_train: 0.1713 acc_train: 0.8990 acc_val: 0.9800\n",
      "Epoch: 3145 loss_train: 0.1882 acc_train: 0.8834 acc_val: 0.9800\n",
      "Epoch: 3146 loss_train: 0.1808 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 3147 loss_train: 0.1952 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 3148 loss_train: 0.1878 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 3149 loss_train: 0.1757 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 3150 loss_train: 0.1912 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 3151 loss_train: 0.1953 acc_train: 0.8812 acc_val: 0.9800\n",
      "Epoch: 3152 loss_train: 0.1767 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 3153 loss_train: 0.1760 acc_train: 0.8961 acc_val: 0.9800\n",
      "Epoch: 3154 loss_train: 0.1759 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 3155 loss_train: 0.1677 acc_train: 0.9005 acc_val: 0.9800\n",
      "Epoch: 3156 loss_train: 0.1895 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 3157 loss_train: 0.1821 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 3158 loss_train: 0.1934 acc_train: 0.8738 acc_val: 0.9800\n",
      "Epoch: 3159 loss_train: 0.1928 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 3160 loss_train: 0.1950 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 3161 loss_train: 0.1932 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 3162 loss_train: 0.1684 acc_train: 0.9072 acc_val: 0.9800\n",
      "Epoch: 3163 loss_train: 0.1874 acc_train: 0.8812 acc_val: 0.9800\n",
      "Epoch: 3164 loss_train: 0.1977 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 3165 loss_train: 0.1808 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 3166 loss_train: 0.1748 acc_train: 0.8976 acc_val: 0.9800\n",
      "Epoch: 3167 loss_train: 0.1882 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 3168 loss_train: 0.2006 acc_train: 0.8886 acc_val: 0.9800\n",
      "Epoch: 3169 loss_train: 0.1819 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 3170 loss_train: 0.1798 acc_train: 0.8976 acc_val: 0.9800\n",
      "Epoch: 3171 loss_train: 0.1752 acc_train: 0.8953 acc_val: 0.9800\n",
      "Epoch: 3172 loss_train: 0.2027 acc_train: 0.8842 acc_val: 0.9800\n",
      "Epoch: 3173 loss_train: 0.1680 acc_train: 0.8998 acc_val: 0.9800\n",
      "Epoch: 3174 loss_train: 0.2009 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 3175 loss_train: 0.1982 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 3176 loss_train: 0.1696 acc_train: 0.9124 acc_val: 0.9800\n",
      "Epoch: 3177 loss_train: 0.1880 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 3178 loss_train: 0.1776 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 3179 loss_train: 0.1836 acc_train: 0.8976 acc_val: 0.9800\n",
      "Epoch: 3180 loss_train: 0.1913 acc_train: 0.8827 acc_val: 0.9800\n",
      "Epoch: 3181 loss_train: 0.1997 acc_train: 0.8731 acc_val: 0.9800\n",
      "Epoch: 3182 loss_train: 0.1893 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 3183 loss_train: 0.1828 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 3184 loss_train: 0.1909 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 3185 loss_train: 0.1854 acc_train: 0.8842 acc_val: 0.9800\n",
      "Epoch: 3186 loss_train: 0.1767 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 3187 loss_train: 0.1756 acc_train: 0.9005 acc_val: 0.9800\n",
      "Epoch: 3188 loss_train: 0.1573 acc_train: 0.9117 acc_val: 0.9800\n",
      "Epoch: 3189 loss_train: 0.1724 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 3190 loss_train: 0.1906 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 3191 loss_train: 0.1745 acc_train: 0.8953 acc_val: 0.9800\n",
      "Epoch: 3192 loss_train: 0.1810 acc_train: 0.9013 acc_val: 0.9800\n",
      "Epoch: 3193 loss_train: 0.2021 acc_train: 0.8731 acc_val: 0.9800\n",
      "Epoch: 3194 loss_train: 0.1872 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 3195 loss_train: 0.2142 acc_train: 0.8797 acc_val: 0.9800\n",
      "Epoch: 3196 loss_train: 0.1718 acc_train: 0.9035 acc_val: 0.9800\n",
      "Epoch: 3197 loss_train: 0.1969 acc_train: 0.8775 acc_val: 0.9800\n",
      "Epoch: 3198 loss_train: 0.1838 acc_train: 0.8834 acc_val: 0.9800\n",
      "Epoch: 3199 loss_train: 0.1808 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 3200 loss_train: 0.1749 acc_train: 0.9013 acc_val: 0.9800\n",
      "Epoch: 3201 loss_train: 0.1935 acc_train: 0.8775 acc_val: 0.9800\n",
      "Epoch: 3202 loss_train: 0.1916 acc_train: 0.8790 acc_val: 0.9800\n",
      "Epoch: 3203 loss_train: 0.1706 acc_train: 0.9013 acc_val: 0.9800\n",
      "Epoch: 3204 loss_train: 0.1847 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 3205 loss_train: 0.1828 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 3206 loss_train: 0.2041 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 3207 loss_train: 0.1758 acc_train: 0.8968 acc_val: 0.9800\n",
      "Epoch: 3208 loss_train: 0.1979 acc_train: 0.8834 acc_val: 0.9800\n",
      "Epoch: 3209 loss_train: 0.1938 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 3210 loss_train: 0.1726 acc_train: 0.8961 acc_val: 0.9800\n",
      "Epoch: 3211 loss_train: 0.1874 acc_train: 0.8834 acc_val: 0.9800\n",
      "Epoch: 3212 loss_train: 0.1894 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 3213 loss_train: 0.1981 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 3214 loss_train: 0.1894 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 3215 loss_train: 0.1765 acc_train: 0.8990 acc_val: 0.9800\n",
      "Epoch: 3216 loss_train: 0.1870 acc_train: 0.8834 acc_val: 0.9800\n",
      "Epoch: 3217 loss_train: 0.1619 acc_train: 0.9072 acc_val: 0.9800\n",
      "Epoch: 3218 loss_train: 0.1791 acc_train: 0.8968 acc_val: 0.9800\n",
      "Epoch: 3219 loss_train: 0.1667 acc_train: 0.9065 acc_val: 0.9800\n",
      "Epoch: 3220 loss_train: 0.1879 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 3221 loss_train: 0.1949 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 3222 loss_train: 0.2131 acc_train: 0.8760 acc_val: 0.9800\n",
      "Epoch: 3223 loss_train: 0.1905 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 3224 loss_train: 0.1985 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 3225 loss_train: 0.1882 acc_train: 0.9057 acc_val: 0.9800\n",
      "Epoch: 3226 loss_train: 0.1948 acc_train: 0.8872 acc_val: 0.9800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3227 loss_train: 0.1988 acc_train: 0.8886 acc_val: 0.9800\n",
      "Epoch: 3228 loss_train: 0.1801 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 3229 loss_train: 0.1705 acc_train: 0.9013 acc_val: 0.9800\n",
      "Epoch: 3230 loss_train: 0.1845 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 3231 loss_train: 0.1971 acc_train: 0.8768 acc_val: 0.9800\n",
      "Epoch: 3232 loss_train: 0.1741 acc_train: 0.8961 acc_val: 0.9800\n",
      "Epoch: 3233 loss_train: 0.1712 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 3234 loss_train: 0.1873 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 3235 loss_train: 0.1921 acc_train: 0.8886 acc_val: 0.9800\n",
      "Epoch: 3236 loss_train: 0.1961 acc_train: 0.8886 acc_val: 0.9800\n",
      "Epoch: 3237 loss_train: 0.1963 acc_train: 0.8842 acc_val: 0.9800\n",
      "Epoch: 3238 loss_train: 0.1800 acc_train: 0.8983 acc_val: 0.9800\n",
      "Epoch: 3239 loss_train: 0.1927 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 3240 loss_train: 0.2003 acc_train: 0.8738 acc_val: 0.9800\n",
      "Epoch: 3241 loss_train: 0.2086 acc_train: 0.8842 acc_val: 0.9800\n",
      "Epoch: 3242 loss_train: 0.1879 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 3243 loss_train: 0.1891 acc_train: 0.8782 acc_val: 0.9800\n",
      "Epoch: 3244 loss_train: 0.1723 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 3245 loss_train: 0.1952 acc_train: 0.8968 acc_val: 0.9800\n",
      "Epoch: 3246 loss_train: 0.1837 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 3247 loss_train: 0.2000 acc_train: 0.8864 acc_val: 0.9800\n",
      "Epoch: 3248 loss_train: 0.1678 acc_train: 0.9020 acc_val: 0.9800\n",
      "Epoch: 3249 loss_train: 0.1964 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 3250 loss_train: 0.1739 acc_train: 0.8998 acc_val: 0.9800\n",
      "Epoch: 3251 loss_train: 0.1969 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 3252 loss_train: 0.1931 acc_train: 0.8983 acc_val: 0.9800\n",
      "Epoch: 3253 loss_train: 0.1942 acc_train: 0.8864 acc_val: 0.9800\n",
      "Epoch: 3254 loss_train: 0.1811 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 3255 loss_train: 0.1958 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 3256 loss_train: 0.1869 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 3257 loss_train: 0.1811 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 3258 loss_train: 0.1711 acc_train: 0.9050 acc_val: 0.9800\n",
      "Epoch: 3259 loss_train: 0.1826 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 3260 loss_train: 0.1912 acc_train: 0.8760 acc_val: 0.9800\n",
      "Epoch: 3261 loss_train: 0.1808 acc_train: 0.8820 acc_val: 0.9800\n",
      "Epoch: 3262 loss_train: 0.2025 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 3263 loss_train: 0.1741 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 3264 loss_train: 0.2019 acc_train: 0.8834 acc_val: 0.9800\n",
      "Epoch: 3265 loss_train: 0.1962 acc_train: 0.8886 acc_val: 0.9800\n",
      "Epoch: 3266 loss_train: 0.1989 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 3267 loss_train: 0.1894 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 3268 loss_train: 0.1984 acc_train: 0.8886 acc_val: 0.9800\n",
      "Epoch: 3269 loss_train: 0.1964 acc_train: 0.8790 acc_val: 0.9800\n",
      "Epoch: 3270 loss_train: 0.1824 acc_train: 0.8953 acc_val: 0.9800\n",
      "Epoch: 3271 loss_train: 0.1655 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 3272 loss_train: 0.1817 acc_train: 0.8953 acc_val: 0.9800\n",
      "Epoch: 3273 loss_train: 0.1868 acc_train: 0.8961 acc_val: 0.9800\n",
      "Epoch: 3274 loss_train: 0.1798 acc_train: 0.8968 acc_val: 0.9800\n",
      "Epoch: 3275 loss_train: 0.1937 acc_train: 0.8864 acc_val: 0.9800\n",
      "Epoch: 3276 loss_train: 0.2000 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 3277 loss_train: 0.2001 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 3278 loss_train: 0.1856 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 3279 loss_train: 0.1620 acc_train: 0.8998 acc_val: 0.9800\n",
      "Epoch: 3280 loss_train: 0.1681 acc_train: 0.9020 acc_val: 0.9800\n",
      "Epoch: 3281 loss_train: 0.1900 acc_train: 0.8834 acc_val: 0.9800\n",
      "Epoch: 3282 loss_train: 0.1831 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 3283 loss_train: 0.1847 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 3284 loss_train: 0.1659 acc_train: 0.8968 acc_val: 0.9800\n",
      "Epoch: 3285 loss_train: 0.1952 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 3286 loss_train: 0.1925 acc_train: 0.8812 acc_val: 0.9800\n",
      "Epoch: 3287 loss_train: 0.2106 acc_train: 0.8827 acc_val: 0.9800\n",
      "Epoch: 3288 loss_train: 0.2006 acc_train: 0.8812 acc_val: 0.9800\n",
      "Epoch: 3289 loss_train: 0.1829 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 3290 loss_train: 0.1952 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 3291 loss_train: 0.1904 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 3292 loss_train: 0.1987 acc_train: 0.8812 acc_val: 0.9800\n",
      "Epoch: 3293 loss_train: 0.1759 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 3294 loss_train: 0.1826 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 3295 loss_train: 0.1889 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 3296 loss_train: 0.1862 acc_train: 0.8842 acc_val: 0.9800\n",
      "Epoch: 3297 loss_train: 0.1819 acc_train: 0.8834 acc_val: 0.9800\n",
      "Epoch: 3298 loss_train: 0.1749 acc_train: 0.8968 acc_val: 0.9800\n",
      "Epoch: 3299 loss_train: 0.1956 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 3300 loss_train: 0.1901 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 3301 loss_train: 0.1794 acc_train: 0.9005 acc_val: 0.9800\n",
      "Epoch: 3302 loss_train: 0.1715 acc_train: 0.8961 acc_val: 0.9800\n",
      "Epoch: 3303 loss_train: 0.1998 acc_train: 0.8886 acc_val: 0.9800\n",
      "Epoch: 3304 loss_train: 0.1754 acc_train: 0.8998 acc_val: 0.9800\n",
      "Epoch: 3305 loss_train: 0.1834 acc_train: 0.8864 acc_val: 0.9800\n",
      "Epoch: 3306 loss_train: 0.1925 acc_train: 0.8842 acc_val: 0.9800\n",
      "Epoch: 3307 loss_train: 0.1724 acc_train: 0.8998 acc_val: 0.9800\n",
      "Epoch: 3308 loss_train: 0.1661 acc_train: 0.8990 acc_val: 0.9800\n",
      "Epoch: 3309 loss_train: 0.1847 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 3310 loss_train: 0.1795 acc_train: 0.9035 acc_val: 0.9800\n",
      "Epoch: 3311 loss_train: 0.1854 acc_train: 0.8834 acc_val: 0.9800\n",
      "Epoch: 3312 loss_train: 0.1872 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 3313 loss_train: 0.1664 acc_train: 0.9042 acc_val: 0.9800\n",
      "Epoch: 3314 loss_train: 0.1822 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 3315 loss_train: 0.1910 acc_train: 0.8953 acc_val: 0.9800\n",
      "Epoch: 3316 loss_train: 0.1775 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 3317 loss_train: 0.1903 acc_train: 0.8864 acc_val: 0.9800\n",
      "Epoch: 3318 loss_train: 0.1908 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 3319 loss_train: 0.1881 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 3320 loss_train: 0.1661 acc_train: 0.9027 acc_val: 0.9800\n",
      "Epoch: 3321 loss_train: 0.1913 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 3322 loss_train: 0.1654 acc_train: 0.9005 acc_val: 0.9800\n",
      "Epoch: 3323 loss_train: 0.1786 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 3324 loss_train: 0.2168 acc_train: 0.8671 acc_val: 0.9800\n",
      "Epoch: 3325 loss_train: 0.1894 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 3326 loss_train: 0.1720 acc_train: 0.9027 acc_val: 0.9800\n",
      "Epoch: 3327 loss_train: 0.1864 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 3328 loss_train: 0.2024 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 3329 loss_train: 0.1852 acc_train: 0.8953 acc_val: 0.9800\n",
      "Epoch: 3330 loss_train: 0.1772 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 3331 loss_train: 0.1818 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 3332 loss_train: 0.2066 acc_train: 0.8768 acc_val: 0.9800\n",
      "Epoch: 3333 loss_train: 0.1584 acc_train: 0.9094 acc_val: 0.9800\n",
      "Epoch: 3334 loss_train: 0.2121 acc_train: 0.8731 acc_val: 0.9800\n",
      "Epoch: 3335 loss_train: 0.1677 acc_train: 0.9020 acc_val: 0.9800\n",
      "Epoch: 3336 loss_train: 0.1929 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 3337 loss_train: 0.1936 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 3338 loss_train: 0.1753 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 3339 loss_train: 0.2039 acc_train: 0.8745 acc_val: 0.9800\n",
      "Epoch: 3340 loss_train: 0.1687 acc_train: 0.8998 acc_val: 0.9800\n",
      "Epoch: 3341 loss_train: 0.1825 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 3342 loss_train: 0.1984 acc_train: 0.8842 acc_val: 0.9800\n",
      "Epoch: 3343 loss_train: 0.1923 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 3344 loss_train: 0.1897 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 3345 loss_train: 0.1732 acc_train: 0.8990 acc_val: 0.9800\n",
      "Epoch: 3346 loss_train: 0.1850 acc_train: 0.9057 acc_val: 0.9800\n",
      "Epoch: 3347 loss_train: 0.1865 acc_train: 0.9005 acc_val: 0.9800\n",
      "Epoch: 3348 loss_train: 0.2002 acc_train: 0.8820 acc_val: 0.9800\n",
      "Epoch: 3349 loss_train: 0.1973 acc_train: 0.8827 acc_val: 0.9800\n",
      "Epoch: 3350 loss_train: 0.1837 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 3351 loss_train: 0.2104 acc_train: 0.8790 acc_val: 0.9800\n",
      "Epoch: 3352 loss_train: 0.1862 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 3353 loss_train: 0.1661 acc_train: 0.9065 acc_val: 0.9800\n",
      "Epoch: 3354 loss_train: 0.1783 acc_train: 0.8961 acc_val: 0.9800\n",
      "Epoch: 3355 loss_train: 0.1883 acc_train: 0.8842 acc_val: 0.9800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3356 loss_train: 0.1865 acc_train: 0.8886 acc_val: 0.9800\n",
      "Epoch: 3357 loss_train: 0.1829 acc_train: 0.8886 acc_val: 0.9800\n",
      "Epoch: 3358 loss_train: 0.1790 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 3359 loss_train: 0.1977 acc_train: 0.8731 acc_val: 0.9800\n",
      "Epoch: 3360 loss_train: 0.1730 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 3361 loss_train: 0.1833 acc_train: 0.8864 acc_val: 0.9800\n",
      "Epoch: 3362 loss_train: 0.1910 acc_train: 0.8864 acc_val: 0.9800\n",
      "Epoch: 3363 loss_train: 0.1765 acc_train: 0.8961 acc_val: 0.9800\n",
      "Epoch: 3364 loss_train: 0.2035 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 3365 loss_train: 0.1909 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 3366 loss_train: 0.1946 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 3367 loss_train: 0.1851 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 3368 loss_train: 0.1868 acc_train: 0.8842 acc_val: 0.9800\n",
      "Epoch: 3369 loss_train: 0.1864 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 3370 loss_train: 0.1688 acc_train: 0.8983 acc_val: 0.9800\n",
      "Epoch: 3371 loss_train: 0.1978 acc_train: 0.8864 acc_val: 0.9800\n",
      "Epoch: 3372 loss_train: 0.1702 acc_train: 0.9020 acc_val: 0.9800\n",
      "Epoch: 3373 loss_train: 0.1936 acc_train: 0.8820 acc_val: 0.9800\n",
      "Epoch: 3374 loss_train: 0.1613 acc_train: 0.8998 acc_val: 0.9800\n",
      "Epoch: 3375 loss_train: 0.1787 acc_train: 0.8990 acc_val: 0.9800\n",
      "Epoch: 3376 loss_train: 0.1858 acc_train: 0.8953 acc_val: 0.9800\n",
      "Epoch: 3377 loss_train: 0.1745 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 3378 loss_train: 0.1861 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 3379 loss_train: 0.1737 acc_train: 0.9027 acc_val: 0.9800\n",
      "Epoch: 3380 loss_train: 0.1912 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 3381 loss_train: 0.1785 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 3382 loss_train: 0.1873 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 3383 loss_train: 0.1761 acc_train: 0.9102 acc_val: 0.9800\n",
      "Epoch: 3384 loss_train: 0.1620 acc_train: 0.9020 acc_val: 0.9800\n",
      "Epoch: 3385 loss_train: 0.1778 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 3386 loss_train: 0.1780 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 3387 loss_train: 0.1713 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 3388 loss_train: 0.1781 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 3389 loss_train: 0.1859 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 3390 loss_train: 0.1795 acc_train: 0.8864 acc_val: 0.9800\n",
      "Epoch: 3391 loss_train: 0.1873 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 3392 loss_train: 0.1721 acc_train: 0.8998 acc_val: 0.9800\n",
      "Epoch: 3393 loss_train: 0.1839 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 3394 loss_train: 0.1946 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 3395 loss_train: 0.1972 acc_train: 0.8953 acc_val: 0.9800\n",
      "Epoch: 3396 loss_train: 0.1741 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 3397 loss_train: 0.1925 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 3398 loss_train: 0.1839 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 3399 loss_train: 0.1714 acc_train: 0.9020 acc_val: 0.9800\n",
      "Epoch: 3400 loss_train: 0.2045 acc_train: 0.8805 acc_val: 0.9800\n",
      "Epoch: 3401 loss_train: 0.2096 acc_train: 0.8790 acc_val: 0.9800\n",
      "Epoch: 3402 loss_train: 0.1767 acc_train: 0.8976 acc_val: 0.9800\n",
      "Epoch: 3403 loss_train: 0.1859 acc_train: 0.8864 acc_val: 0.9800\n",
      "Epoch: 3404 loss_train: 0.1925 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 3405 loss_train: 0.1775 acc_train: 0.8953 acc_val: 0.9800\n",
      "Epoch: 3406 loss_train: 0.1727 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 3407 loss_train: 0.1774 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 3408 loss_train: 0.1850 acc_train: 0.8953 acc_val: 0.9800\n",
      "Epoch: 3409 loss_train: 0.1953 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 3410 loss_train: 0.1853 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 3411 loss_train: 0.1863 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 3412 loss_train: 0.1861 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 3413 loss_train: 0.1800 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 3414 loss_train: 0.1948 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 3415 loss_train: 0.1734 acc_train: 0.9072 acc_val: 0.9800\n",
      "Epoch: 3416 loss_train: 0.1764 acc_train: 0.8998 acc_val: 0.9800\n",
      "Epoch: 3417 loss_train: 0.1951 acc_train: 0.8790 acc_val: 0.9800\n",
      "Epoch: 3418 loss_train: 0.2055 acc_train: 0.8812 acc_val: 0.9800\n",
      "Epoch: 3419 loss_train: 0.1852 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 3420 loss_train: 0.2164 acc_train: 0.8805 acc_val: 0.9800\n",
      "Epoch: 3421 loss_train: 0.1978 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 3422 loss_train: 0.1814 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 3423 loss_train: 0.1932 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 3424 loss_train: 0.1747 acc_train: 0.8983 acc_val: 0.9800\n",
      "Epoch: 3425 loss_train: 0.1944 acc_train: 0.8864 acc_val: 0.9800\n",
      "Epoch: 3426 loss_train: 0.1869 acc_train: 0.8820 acc_val: 0.9800\n",
      "Epoch: 3427 loss_train: 0.1986 acc_train: 0.8820 acc_val: 0.9800\n",
      "Epoch: 3428 loss_train: 0.1822 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 3429 loss_train: 0.1571 acc_train: 0.9094 acc_val: 0.9800\n",
      "Epoch: 3430 loss_train: 0.1955 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 3431 loss_train: 0.1777 acc_train: 0.8968 acc_val: 0.9800\n",
      "Epoch: 3432 loss_train: 0.1983 acc_train: 0.8820 acc_val: 0.9800\n",
      "Epoch: 3433 loss_train: 0.1640 acc_train: 0.9087 acc_val: 0.9800\n",
      "Epoch: 3434 loss_train: 0.1936 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 3435 loss_train: 0.1823 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 3436 loss_train: 0.1952 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 3437 loss_train: 0.2043 acc_train: 0.8775 acc_val: 0.9800\n",
      "Epoch: 3438 loss_train: 0.1771 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 3439 loss_train: 0.1697 acc_train: 0.9035 acc_val: 0.9800\n",
      "Epoch: 3440 loss_train: 0.1959 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 3441 loss_train: 0.1914 acc_train: 0.8953 acc_val: 0.9800\n",
      "Epoch: 3442 loss_train: 0.1776 acc_train: 0.9020 acc_val: 0.9800\n",
      "Epoch: 3443 loss_train: 0.1758 acc_train: 0.8976 acc_val: 0.9800\n",
      "Epoch: 3444 loss_train: 0.1789 acc_train: 0.9013 acc_val: 0.9800\n",
      "Epoch: 3445 loss_train: 0.1874 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 3446 loss_train: 0.2050 acc_train: 0.8753 acc_val: 0.9800\n",
      "Epoch: 3447 loss_train: 0.1895 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 3448 loss_train: 0.1892 acc_train: 0.8834 acc_val: 0.9800\n",
      "Epoch: 3449 loss_train: 0.1943 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 3450 loss_train: 0.2009 acc_train: 0.8782 acc_val: 0.9800\n",
      "Epoch: 3451 loss_train: 0.1777 acc_train: 0.8990 acc_val: 0.9800\n",
      "Epoch: 3452 loss_train: 0.1735 acc_train: 0.9027 acc_val: 0.9800\n",
      "Epoch: 3453 loss_train: 0.1980 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 3454 loss_train: 0.1785 acc_train: 0.9013 acc_val: 0.9800\n",
      "Epoch: 3455 loss_train: 0.1847 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 3456 loss_train: 0.1820 acc_train: 0.8983 acc_val: 0.9800\n",
      "Epoch: 3457 loss_train: 0.1991 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 3458 loss_train: 0.1850 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 3459 loss_train: 0.1820 acc_train: 0.8961 acc_val: 0.9800\n",
      "Epoch: 3460 loss_train: 0.1874 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 3461 loss_train: 0.1656 acc_train: 0.8968 acc_val: 0.9800\n",
      "Epoch: 3462 loss_train: 0.1754 acc_train: 0.9005 acc_val: 0.9800\n",
      "Epoch: 3463 loss_train: 0.1903 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 3464 loss_train: 0.1901 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 3465 loss_train: 0.2058 acc_train: 0.8834 acc_val: 0.9800\n",
      "Epoch: 3466 loss_train: 0.1886 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 3467 loss_train: 0.1776 acc_train: 0.8953 acc_val: 0.9800\n",
      "Epoch: 3468 loss_train: 0.1903 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 3469 loss_train: 0.1741 acc_train: 0.9027 acc_val: 0.9800\n",
      "Epoch: 3470 loss_train: 0.2017 acc_train: 0.8775 acc_val: 0.9800\n",
      "Epoch: 3471 loss_train: 0.1823 acc_train: 0.8961 acc_val: 0.9800\n",
      "Epoch: 3472 loss_train: 0.1975 acc_train: 0.8693 acc_val: 0.9800\n",
      "Epoch: 3473 loss_train: 0.1659 acc_train: 0.9087 acc_val: 0.9800\n",
      "Epoch: 3474 loss_train: 0.1763 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 3475 loss_train: 0.2019 acc_train: 0.8886 acc_val: 0.9800\n",
      "Epoch: 3476 loss_train: 0.1888 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 3477 loss_train: 0.2206 acc_train: 0.8671 acc_val: 0.9800\n",
      "Epoch: 3478 loss_train: 0.1901 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 3479 loss_train: 0.1982 acc_train: 0.8886 acc_val: 0.9800\n",
      "Epoch: 3480 loss_train: 0.2029 acc_train: 0.8805 acc_val: 0.9800\n",
      "Epoch: 3481 loss_train: 0.1722 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 3482 loss_train: 0.1963 acc_train: 0.8864 acc_val: 0.9800\n",
      "Epoch: 3483 loss_train: 0.1954 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 3484 loss_train: 0.1726 acc_train: 0.9005 acc_val: 0.9800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3485 loss_train: 0.1768 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 3486 loss_train: 0.1840 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 3487 loss_train: 0.1732 acc_train: 0.8961 acc_val: 0.9800\n",
      "Epoch: 3488 loss_train: 0.1782 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 3489 loss_train: 0.1989 acc_train: 0.8842 acc_val: 0.9800\n",
      "Epoch: 3490 loss_train: 0.1890 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 3491 loss_train: 0.1974 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 3492 loss_train: 0.1691 acc_train: 0.9035 acc_val: 0.9800\n",
      "Epoch: 3493 loss_train: 0.1751 acc_train: 0.9020 acc_val: 0.9800\n",
      "Epoch: 3494 loss_train: 0.2104 acc_train: 0.8641 acc_val: 0.9800\n",
      "Epoch: 3495 loss_train: 0.1722 acc_train: 0.9035 acc_val: 0.9800\n",
      "Epoch: 3496 loss_train: 0.1714 acc_train: 0.8961 acc_val: 0.9800\n",
      "Epoch: 3497 loss_train: 0.1831 acc_train: 0.8953 acc_val: 0.9800\n",
      "Epoch: 3498 loss_train: 0.1781 acc_train: 0.8909 acc_val: 0.9800\n",
      "Epoch: 3499 loss_train: 0.1771 acc_train: 0.8968 acc_val: 0.9800\n",
      "Epoch: 3500 loss_train: 0.1891 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 3501 loss_train: 0.1928 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 3502 loss_train: 0.1892 acc_train: 0.8820 acc_val: 0.9800\n",
      "Epoch: 3503 loss_train: 0.1716 acc_train: 0.9013 acc_val: 0.9800\n",
      "Epoch: 3504 loss_train: 0.1969 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 3505 loss_train: 0.1943 acc_train: 0.8805 acc_val: 0.9800\n",
      "Epoch: 3506 loss_train: 0.2003 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 3507 loss_train: 0.1694 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 3508 loss_train: 0.1820 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 3509 loss_train: 0.2182 acc_train: 0.8649 acc_val: 0.9800\n",
      "Epoch: 3510 loss_train: 0.2062 acc_train: 0.8805 acc_val: 0.9800\n",
      "Epoch: 3511 loss_train: 0.1943 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 3512 loss_train: 0.1688 acc_train: 0.8961 acc_val: 0.9800\n",
      "Epoch: 3513 loss_train: 0.1776 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 3514 loss_train: 0.1577 acc_train: 0.9013 acc_val: 0.9756\n",
      "Epoch: 3515 loss_train: 0.1831 acc_train: 0.8916 acc_val: 0.9756\n",
      "Epoch: 3516 loss_train: 0.1720 acc_train: 0.9102 acc_val: 0.9756\n",
      "Epoch: 3517 loss_train: 0.1855 acc_train: 0.8879 acc_val: 0.9756\n",
      "Epoch: 3518 loss_train: 0.1865 acc_train: 0.8901 acc_val: 0.9756\n",
      "Epoch: 3519 loss_train: 0.2002 acc_train: 0.8820 acc_val: 0.9756\n",
      "Epoch: 3520 loss_train: 0.1859 acc_train: 0.8901 acc_val: 0.9756\n",
      "Epoch: 3521 loss_train: 0.1847 acc_train: 0.8983 acc_val: 0.9756\n",
      "Epoch: 3522 loss_train: 0.1863 acc_train: 0.8901 acc_val: 0.9756\n",
      "Epoch: 3523 loss_train: 0.1889 acc_train: 0.8976 acc_val: 0.9756\n",
      "Epoch: 3524 loss_train: 0.1719 acc_train: 0.8976 acc_val: 0.9756\n",
      "Epoch: 3525 loss_train: 0.1602 acc_train: 0.9094 acc_val: 0.9756\n",
      "Epoch: 3526 loss_train: 0.1783 acc_train: 0.8924 acc_val: 0.9756\n",
      "Epoch: 3527 loss_train: 0.1792 acc_train: 0.8924 acc_val: 0.9756\n",
      "Epoch: 3528 loss_train: 0.2043 acc_train: 0.8827 acc_val: 0.9756\n",
      "Epoch: 3529 loss_train: 0.1780 acc_train: 0.8864 acc_val: 0.9756\n",
      "Epoch: 3530 loss_train: 0.1834 acc_train: 0.8894 acc_val: 0.9756\n",
      "Epoch: 3531 loss_train: 0.1931 acc_train: 0.8849 acc_val: 0.9756\n",
      "Epoch: 3532 loss_train: 0.1673 acc_train: 0.8931 acc_val: 0.9756\n",
      "Epoch: 3533 loss_train: 0.1887 acc_train: 0.8857 acc_val: 0.9756\n",
      "Epoch: 3534 loss_train: 0.1877 acc_train: 0.8879 acc_val: 0.9756\n",
      "Epoch: 3535 loss_train: 0.1835 acc_train: 0.8938 acc_val: 0.9756\n",
      "Epoch: 3536 loss_train: 0.1677 acc_train: 0.8990 acc_val: 0.9756\n",
      "Epoch: 3537 loss_train: 0.1768 acc_train: 0.8909 acc_val: 0.9756\n",
      "Epoch: 3538 loss_train: 0.1727 acc_train: 0.8946 acc_val: 0.9756\n",
      "Epoch: 3539 loss_train: 0.1922 acc_train: 0.8857 acc_val: 0.9756\n",
      "Epoch: 3540 loss_train: 0.1831 acc_train: 0.8946 acc_val: 0.9756\n",
      "Epoch: 3541 loss_train: 0.1801 acc_train: 0.8990 acc_val: 0.9756\n",
      "Epoch: 3542 loss_train: 0.1946 acc_train: 0.8849 acc_val: 0.9756\n",
      "Epoch: 3543 loss_train: 0.1821 acc_train: 0.8953 acc_val: 0.9756\n",
      "Epoch: 3544 loss_train: 0.2009 acc_train: 0.8857 acc_val: 0.9756\n",
      "Epoch: 3545 loss_train: 0.1823 acc_train: 0.8961 acc_val: 0.9756\n",
      "Epoch: 3546 loss_train: 0.1825 acc_train: 0.8857 acc_val: 0.9756\n",
      "Epoch: 3547 loss_train: 0.1857 acc_train: 0.8834 acc_val: 0.9756\n",
      "Epoch: 3548 loss_train: 0.1872 acc_train: 0.8909 acc_val: 0.9756\n",
      "Epoch: 3549 loss_train: 0.1485 acc_train: 0.9102 acc_val: 0.9756\n",
      "Epoch: 3550 loss_train: 0.2051 acc_train: 0.8768 acc_val: 0.9756\n",
      "Epoch: 3551 loss_train: 0.1937 acc_train: 0.8857 acc_val: 0.9756\n",
      "Epoch: 3552 loss_train: 0.2008 acc_train: 0.8782 acc_val: 0.9756\n",
      "Epoch: 3553 loss_train: 0.1838 acc_train: 0.8886 acc_val: 0.9756\n",
      "Epoch: 3554 loss_train: 0.1844 acc_train: 0.8916 acc_val: 0.9756\n",
      "Epoch: 3555 loss_train: 0.1820 acc_train: 0.9013 acc_val: 0.9756\n",
      "Epoch: 3556 loss_train: 0.1788 acc_train: 0.8990 acc_val: 0.9756\n",
      "Epoch: 3557 loss_train: 0.1850 acc_train: 0.8894 acc_val: 0.9756\n",
      "Epoch: 3558 loss_train: 0.1813 acc_train: 0.8849 acc_val: 0.9756\n",
      "Epoch: 3559 loss_train: 0.1744 acc_train: 0.8990 acc_val: 0.9756\n",
      "Epoch: 3560 loss_train: 0.1678 acc_train: 0.9027 acc_val: 0.9756\n",
      "Epoch: 3561 loss_train: 0.1705 acc_train: 0.8961 acc_val: 0.9756\n",
      "Epoch: 3562 loss_train: 0.1759 acc_train: 0.8968 acc_val: 0.9756\n",
      "Epoch: 3563 loss_train: 0.1936 acc_train: 0.8857 acc_val: 0.9756\n",
      "Epoch: 3564 loss_train: 0.1711 acc_train: 0.8983 acc_val: 0.9756\n",
      "Epoch: 3565 loss_train: 0.1843 acc_train: 0.8998 acc_val: 0.9756\n",
      "Epoch: 3566 loss_train: 0.1925 acc_train: 0.8782 acc_val: 0.9756\n",
      "Epoch: 3567 loss_train: 0.1967 acc_train: 0.8805 acc_val: 0.9756\n",
      "Epoch: 3568 loss_train: 0.1898 acc_train: 0.8834 acc_val: 0.9756\n",
      "Epoch: 3569 loss_train: 0.1863 acc_train: 0.8894 acc_val: 0.9756\n",
      "Epoch: 3570 loss_train: 0.1745 acc_train: 0.9020 acc_val: 0.9756\n",
      "Epoch: 3571 loss_train: 0.1932 acc_train: 0.8872 acc_val: 0.9756\n",
      "Epoch: 3572 loss_train: 0.1917 acc_train: 0.8797 acc_val: 0.9756\n",
      "Epoch: 3573 loss_train: 0.1895 acc_train: 0.8938 acc_val: 0.9756\n",
      "Epoch: 3574 loss_train: 0.1842 acc_train: 0.8983 acc_val: 0.9756\n",
      "Epoch: 3575 loss_train: 0.1917 acc_train: 0.8938 acc_val: 0.9756\n",
      "Epoch: 3576 loss_train: 0.1849 acc_train: 0.8909 acc_val: 0.9756\n",
      "Epoch: 3577 loss_train: 0.1814 acc_train: 0.8901 acc_val: 0.9756\n",
      "Epoch: 3578 loss_train: 0.2000 acc_train: 0.8723 acc_val: 0.9756\n",
      "Epoch: 3579 loss_train: 0.1716 acc_train: 0.8916 acc_val: 0.9756\n",
      "Epoch: 3580 loss_train: 0.1715 acc_train: 0.8938 acc_val: 0.9756\n",
      "Epoch: 3581 loss_train: 0.1765 acc_train: 0.8983 acc_val: 0.9756\n",
      "Epoch: 3582 loss_train: 0.1977 acc_train: 0.8805 acc_val: 0.9756\n",
      "Epoch: 3583 loss_train: 0.1989 acc_train: 0.8857 acc_val: 0.9756\n",
      "Epoch: 3584 loss_train: 0.1948 acc_train: 0.8812 acc_val: 0.9756\n",
      "Epoch: 3585 loss_train: 0.1826 acc_train: 0.8909 acc_val: 0.9756\n",
      "Epoch: 3586 loss_train: 0.1931 acc_train: 0.8879 acc_val: 0.9756\n",
      "Epoch: 3587 loss_train: 0.1867 acc_train: 0.8886 acc_val: 0.9756\n",
      "Epoch: 3588 loss_train: 0.2059 acc_train: 0.8775 acc_val: 0.9756\n",
      "Epoch: 3589 loss_train: 0.1926 acc_train: 0.8805 acc_val: 0.9756\n",
      "Epoch: 3590 loss_train: 0.1768 acc_train: 0.8998 acc_val: 0.9756\n",
      "Epoch: 3591 loss_train: 0.1795 acc_train: 0.8938 acc_val: 0.9756\n",
      "Epoch: 3592 loss_train: 0.2042 acc_train: 0.8797 acc_val: 0.9756\n",
      "Epoch: 3593 loss_train: 0.1878 acc_train: 0.8827 acc_val: 0.9756\n",
      "Epoch: 3594 loss_train: 0.1679 acc_train: 0.9094 acc_val: 0.9756\n",
      "Epoch: 3595 loss_train: 0.1919 acc_train: 0.8924 acc_val: 0.9756\n",
      "Epoch: 3596 loss_train: 0.1766 acc_train: 0.8990 acc_val: 0.9756\n",
      "Epoch: 3597 loss_train: 0.1771 acc_train: 0.8961 acc_val: 0.9756\n",
      "Epoch: 3598 loss_train: 0.1986 acc_train: 0.8745 acc_val: 0.9756\n",
      "Epoch: 3599 loss_train: 0.2114 acc_train: 0.8834 acc_val: 0.9756\n",
      "Epoch: 3600 loss_train: 0.1742 acc_train: 0.8998 acc_val: 0.9756\n",
      "Epoch: 3601 loss_train: 0.1957 acc_train: 0.8894 acc_val: 0.9756\n",
      "Epoch: 3602 loss_train: 0.1978 acc_train: 0.8812 acc_val: 0.9756\n",
      "Epoch: 3603 loss_train: 0.1754 acc_train: 0.8938 acc_val: 0.9756\n",
      "Epoch: 3604 loss_train: 0.1785 acc_train: 0.8931 acc_val: 0.9756\n",
      "Epoch: 3605 loss_train: 0.1708 acc_train: 0.8916 acc_val: 0.9756\n",
      "Epoch: 3606 loss_train: 0.2002 acc_train: 0.8775 acc_val: 0.9756\n",
      "Epoch: 3607 loss_train: 0.1891 acc_train: 0.9013 acc_val: 0.9756\n",
      "Epoch: 3608 loss_train: 0.2137 acc_train: 0.8768 acc_val: 0.9756\n",
      "Epoch: 3609 loss_train: 0.1810 acc_train: 0.9035 acc_val: 0.9756\n",
      "Epoch: 3610 loss_train: 0.1798 acc_train: 0.8953 acc_val: 0.9756\n",
      "Epoch: 3611 loss_train: 0.1949 acc_train: 0.8998 acc_val: 0.9756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3612 loss_train: 0.1846 acc_train: 0.8790 acc_val: 0.9756\n",
      "Epoch: 3613 loss_train: 0.1750 acc_train: 0.8894 acc_val: 0.9756\n",
      "Epoch: 3614 loss_train: 0.1783 acc_train: 0.8805 acc_val: 0.9756\n",
      "Epoch: 3615 loss_train: 0.1984 acc_train: 0.8834 acc_val: 0.9756\n",
      "Epoch: 3616 loss_train: 0.1910 acc_train: 0.8886 acc_val: 0.9756\n",
      "Epoch: 3617 loss_train: 0.1739 acc_train: 0.9013 acc_val: 0.9756\n",
      "Epoch: 3618 loss_train: 0.1806 acc_train: 0.8886 acc_val: 0.9756\n",
      "Epoch: 3619 loss_train: 0.1689 acc_train: 0.9087 acc_val: 0.9756\n",
      "Epoch: 3620 loss_train: 0.1826 acc_train: 0.8931 acc_val: 0.9756\n",
      "Epoch: 3621 loss_train: 0.1730 acc_train: 0.9005 acc_val: 0.9756\n",
      "Epoch: 3622 loss_train: 0.1771 acc_train: 0.9035 acc_val: 0.9756\n",
      "Epoch: 3623 loss_train: 0.1672 acc_train: 0.9042 acc_val: 0.9756\n",
      "Epoch: 3624 loss_train: 0.1717 acc_train: 0.8968 acc_val: 0.9756\n",
      "Epoch: 3625 loss_train: 0.1944 acc_train: 0.8879 acc_val: 0.9756\n",
      "Epoch: 3626 loss_train: 0.1836 acc_train: 0.8872 acc_val: 0.9756\n",
      "Epoch: 3627 loss_train: 0.1953 acc_train: 0.8938 acc_val: 0.9756\n",
      "Epoch: 3628 loss_train: 0.1931 acc_train: 0.8834 acc_val: 0.9756\n",
      "Epoch: 3629 loss_train: 0.1832 acc_train: 0.8894 acc_val: 0.9756\n",
      "Epoch: 3630 loss_train: 0.1723 acc_train: 0.8894 acc_val: 0.9756\n",
      "Epoch: 3631 loss_train: 0.2167 acc_train: 0.8753 acc_val: 0.9756\n",
      "Epoch: 3632 loss_train: 0.1860 acc_train: 0.8924 acc_val: 0.9756\n",
      "Epoch: 3633 loss_train: 0.1815 acc_train: 0.8968 acc_val: 0.9756\n",
      "Epoch: 3634 loss_train: 0.1868 acc_train: 0.8842 acc_val: 0.9756\n",
      "Epoch: 3635 loss_train: 0.2021 acc_train: 0.8827 acc_val: 0.9756\n",
      "Epoch: 3636 loss_train: 0.1797 acc_train: 0.8864 acc_val: 0.9756\n",
      "Epoch: 3637 loss_train: 0.1797 acc_train: 0.8953 acc_val: 0.9756\n",
      "Epoch: 3638 loss_train: 0.1847 acc_train: 0.8879 acc_val: 0.9756\n",
      "Epoch: 3639 loss_train: 0.1858 acc_train: 0.8916 acc_val: 0.9756\n",
      "Epoch: 3640 loss_train: 0.1917 acc_train: 0.8812 acc_val: 0.9756\n",
      "Epoch: 3641 loss_train: 0.1993 acc_train: 0.8797 acc_val: 0.9756\n",
      "Epoch: 3642 loss_train: 0.1743 acc_train: 0.8983 acc_val: 0.9756\n",
      "Epoch: 3643 loss_train: 0.1933 acc_train: 0.8849 acc_val: 0.9756\n",
      "Epoch: 3644 loss_train: 0.1915 acc_train: 0.8834 acc_val: 0.9756\n",
      "Epoch: 3645 loss_train: 0.1846 acc_train: 0.8953 acc_val: 0.9756\n",
      "Epoch: 3646 loss_train: 0.1622 acc_train: 0.9065 acc_val: 0.9756\n",
      "Epoch: 3647 loss_train: 0.1859 acc_train: 0.8857 acc_val: 0.9756\n",
      "Epoch: 3648 loss_train: 0.2089 acc_train: 0.8842 acc_val: 0.9756\n",
      "Epoch: 3649 loss_train: 0.1900 acc_train: 0.8916 acc_val: 0.9756\n",
      "Epoch: 3650 loss_train: 0.1725 acc_train: 0.9005 acc_val: 0.9756\n",
      "Epoch: 3651 loss_train: 0.1894 acc_train: 0.8916 acc_val: 0.9756\n",
      "Epoch: 3652 loss_train: 0.1585 acc_train: 0.9050 acc_val: 0.9756\n",
      "Epoch: 3653 loss_train: 0.1924 acc_train: 0.8753 acc_val: 0.9756\n",
      "Epoch: 3654 loss_train: 0.1781 acc_train: 0.8931 acc_val: 0.9756\n",
      "Epoch: 3655 loss_train: 0.1747 acc_train: 0.8946 acc_val: 0.9756\n",
      "Epoch: 3656 loss_train: 0.1752 acc_train: 0.8938 acc_val: 0.9756\n",
      "Epoch: 3657 loss_train: 0.1912 acc_train: 0.8909 acc_val: 0.9756\n",
      "Epoch: 3658 loss_train: 0.1769 acc_train: 0.9013 acc_val: 0.9756\n",
      "Epoch: 3659 loss_train: 0.1774 acc_train: 0.8938 acc_val: 0.9756\n",
      "Epoch: 3660 loss_train: 0.1861 acc_train: 0.8872 acc_val: 0.9756\n",
      "Epoch: 3661 loss_train: 0.1896 acc_train: 0.8901 acc_val: 0.9756\n",
      "Epoch: 3662 loss_train: 0.2023 acc_train: 0.8901 acc_val: 0.9756\n",
      "Epoch: 3663 loss_train: 0.1682 acc_train: 0.9005 acc_val: 0.9756\n",
      "Epoch: 3664 loss_train: 0.1692 acc_train: 0.8968 acc_val: 0.9756\n",
      "Epoch: 3665 loss_train: 0.1661 acc_train: 0.9027 acc_val: 0.9756\n",
      "Epoch: 3666 loss_train: 0.1963 acc_train: 0.8723 acc_val: 0.9756\n",
      "Epoch: 3667 loss_train: 0.1825 acc_train: 0.8931 acc_val: 0.9756\n",
      "Epoch: 3668 loss_train: 0.1964 acc_train: 0.8909 acc_val: 0.9756\n",
      "Epoch: 3669 loss_train: 0.1979 acc_train: 0.8857 acc_val: 0.9756\n",
      "Epoch: 3670 loss_train: 0.1873 acc_train: 0.8886 acc_val: 0.9756\n",
      "Epoch: 3671 loss_train: 0.1875 acc_train: 0.8834 acc_val: 0.9756\n",
      "Epoch: 3672 loss_train: 0.1776 acc_train: 0.8924 acc_val: 0.9756\n",
      "Epoch: 3673 loss_train: 0.1623 acc_train: 0.9079 acc_val: 0.9756\n",
      "Epoch: 3674 loss_train: 0.1919 acc_train: 0.8894 acc_val: 0.9756\n",
      "Epoch: 3675 loss_train: 0.1677 acc_train: 0.9035 acc_val: 0.9756\n",
      "Epoch: 3676 loss_train: 0.1845 acc_train: 0.8901 acc_val: 0.9756\n",
      "Epoch: 3677 loss_train: 0.1879 acc_train: 0.8961 acc_val: 0.9756\n",
      "Epoch: 3678 loss_train: 0.1828 acc_train: 0.8909 acc_val: 0.9756\n",
      "Epoch: 3679 loss_train: 0.1876 acc_train: 0.8872 acc_val: 0.9756\n",
      "Epoch: 3680 loss_train: 0.1909 acc_train: 0.8842 acc_val: 0.9756\n",
      "Epoch: 3681 loss_train: 0.1974 acc_train: 0.8857 acc_val: 0.9756\n",
      "Epoch: 3682 loss_train: 0.1708 acc_train: 0.8894 acc_val: 0.9756\n",
      "Epoch: 3683 loss_train: 0.1754 acc_train: 0.8961 acc_val: 0.9756\n",
      "Epoch: 3684 loss_train: 0.1833 acc_train: 0.8812 acc_val: 0.9756\n",
      "Epoch: 3685 loss_train: 0.1637 acc_train: 0.9013 acc_val: 0.9756\n",
      "Epoch: 3686 loss_train: 0.1805 acc_train: 0.8872 acc_val: 0.9756\n",
      "Epoch: 3687 loss_train: 0.1962 acc_train: 0.8827 acc_val: 0.9756\n",
      "Epoch: 3688 loss_train: 0.1858 acc_train: 0.8916 acc_val: 0.9756\n",
      "Epoch: 3689 loss_train: 0.1757 acc_train: 0.8968 acc_val: 0.9756\n",
      "Epoch: 3690 loss_train: 0.1739 acc_train: 0.8990 acc_val: 0.9756\n",
      "Epoch: 3691 loss_train: 0.1839 acc_train: 0.8968 acc_val: 0.9756\n",
      "Epoch: 3692 loss_train: 0.1984 acc_train: 0.8797 acc_val: 0.9756\n",
      "Epoch: 3693 loss_train: 0.1774 acc_train: 0.8961 acc_val: 0.9756\n",
      "Epoch: 3694 loss_train: 0.1818 acc_train: 0.8842 acc_val: 0.9756\n",
      "Epoch: 3695 loss_train: 0.1865 acc_train: 0.8872 acc_val: 0.9756\n",
      "Epoch: 3696 loss_train: 0.1779 acc_train: 0.8909 acc_val: 0.9756\n",
      "Epoch: 3697 loss_train: 0.1745 acc_train: 0.8886 acc_val: 0.9756\n",
      "Epoch: 3698 loss_train: 0.1824 acc_train: 0.8894 acc_val: 0.9756\n",
      "Epoch: 3699 loss_train: 0.1885 acc_train: 0.8842 acc_val: 0.9756\n",
      "Epoch: 3700 loss_train: 0.1860 acc_train: 0.8916 acc_val: 0.9756\n",
      "Epoch: 3701 loss_train: 0.1569 acc_train: 0.9020 acc_val: 0.9756\n",
      "Epoch: 3702 loss_train: 0.1803 acc_train: 0.8983 acc_val: 0.9756\n",
      "Epoch: 3703 loss_train: 0.1805 acc_train: 0.8916 acc_val: 0.9756\n",
      "Epoch: 3704 loss_train: 0.1905 acc_train: 0.8864 acc_val: 0.9756\n",
      "Epoch: 3705 loss_train: 0.1947 acc_train: 0.8820 acc_val: 0.9756\n",
      "Epoch: 3706 loss_train: 0.2121 acc_train: 0.8805 acc_val: 0.9756\n",
      "Epoch: 3707 loss_train: 0.1877 acc_train: 0.8797 acc_val: 0.9756\n",
      "Epoch: 3708 loss_train: 0.1783 acc_train: 0.9020 acc_val: 0.9756\n",
      "Epoch: 3709 loss_train: 0.1906 acc_train: 0.8946 acc_val: 0.9756\n",
      "Epoch: 3710 loss_train: 0.1856 acc_train: 0.8946 acc_val: 0.9756\n",
      "Epoch: 3711 loss_train: 0.1859 acc_train: 0.8842 acc_val: 0.9756\n",
      "Epoch: 3712 loss_train: 0.2108 acc_train: 0.8797 acc_val: 0.9756\n",
      "Epoch: 3713 loss_train: 0.1923 acc_train: 0.8834 acc_val: 0.9756\n",
      "Epoch: 3714 loss_train: 0.1966 acc_train: 0.8849 acc_val: 0.9756\n",
      "Epoch: 3715 loss_train: 0.1755 acc_train: 0.8961 acc_val: 0.9756\n",
      "Epoch: 3716 loss_train: 0.2035 acc_train: 0.8872 acc_val: 0.9756\n",
      "Epoch: 3717 loss_train: 0.1698 acc_train: 0.9005 acc_val: 0.9756\n",
      "Epoch: 3718 loss_train: 0.1924 acc_train: 0.8901 acc_val: 0.9756\n",
      "Epoch: 3719 loss_train: 0.1924 acc_train: 0.8760 acc_val: 0.9756\n",
      "Epoch: 3720 loss_train: 0.1971 acc_train: 0.8805 acc_val: 0.9756\n",
      "Epoch: 3721 loss_train: 0.1735 acc_train: 0.9042 acc_val: 0.9756\n",
      "Epoch: 3722 loss_train: 0.1769 acc_train: 0.8872 acc_val: 0.9756\n",
      "Epoch: 3723 loss_train: 0.1929 acc_train: 0.8857 acc_val: 0.9756\n",
      "Epoch: 3724 loss_train: 0.1885 acc_train: 0.8931 acc_val: 0.9756\n",
      "Epoch: 3725 loss_train: 0.1959 acc_train: 0.8879 acc_val: 0.9756\n",
      "Epoch: 3726 loss_train: 0.1742 acc_train: 0.8946 acc_val: 0.9756\n",
      "Epoch: 3727 loss_train: 0.1890 acc_train: 0.8894 acc_val: 0.9756\n",
      "Epoch: 3728 loss_train: 0.1959 acc_train: 0.8886 acc_val: 0.9756\n",
      "Epoch: 3729 loss_train: 0.1857 acc_train: 0.8938 acc_val: 0.9756\n",
      "Epoch: 3730 loss_train: 0.1788 acc_train: 0.8990 acc_val: 0.9756\n",
      "Epoch: 3731 loss_train: 0.1858 acc_train: 0.8901 acc_val: 0.9756\n",
      "Epoch: 3732 loss_train: 0.1861 acc_train: 0.8916 acc_val: 0.9756\n",
      "Epoch: 3733 loss_train: 0.1778 acc_train: 0.8886 acc_val: 0.9756\n",
      "Epoch: 3734 loss_train: 0.1920 acc_train: 0.8886 acc_val: 0.9756\n",
      "Epoch: 3735 loss_train: 0.1910 acc_train: 0.8879 acc_val: 0.9756\n",
      "Epoch: 3736 loss_train: 0.1803 acc_train: 0.8983 acc_val: 0.9756\n",
      "Epoch: 3737 loss_train: 0.1929 acc_train: 0.8775 acc_val: 0.9756\n",
      "Epoch: 3738 loss_train: 0.1929 acc_train: 0.8879 acc_val: 0.9756\n",
      "Epoch: 3739 loss_train: 0.1872 acc_train: 0.8857 acc_val: 0.9756\n",
      "Epoch: 3740 loss_train: 0.1798 acc_train: 0.8864 acc_val: 0.9756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3741 loss_train: 0.1585 acc_train: 0.9057 acc_val: 0.9756\n",
      "Epoch: 3742 loss_train: 0.1960 acc_train: 0.8820 acc_val: 0.9756\n",
      "Epoch: 3743 loss_train: 0.1851 acc_train: 0.8857 acc_val: 0.9756\n",
      "Epoch: 3744 loss_train: 0.1902 acc_train: 0.8827 acc_val: 0.9756\n",
      "Epoch: 3745 loss_train: 0.1830 acc_train: 0.8879 acc_val: 0.9756\n",
      "Epoch: 3746 loss_train: 0.3737 acc_train: 0.8879 acc_val: 0.9756\n",
      "Epoch: 3747 loss_train: 0.1824 acc_train: 0.8968 acc_val: 0.9756\n",
      "Epoch: 3748 loss_train: 0.3165 acc_train: 0.8983 acc_val: 0.9756\n",
      "Epoch: 3749 loss_train: 0.1582 acc_train: 0.9020 acc_val: 0.9756\n",
      "Epoch: 3750 loss_train: 0.1761 acc_train: 0.8953 acc_val: 0.9756\n",
      "Epoch: 3751 loss_train: 0.1549 acc_train: 0.8983 acc_val: 0.9756\n",
      "Epoch: 3752 loss_train: 0.1739 acc_train: 0.8886 acc_val: 0.9756\n",
      "Epoch: 3753 loss_train: 2.2698 acc_train: 0.8901 acc_val: 0.9756\n",
      "Epoch: 3754 loss_train: 0.1966 acc_train: 0.8894 acc_val: 0.9778\n",
      "Epoch: 3755 loss_train: 2.1476 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 3756 loss_train: 16.9689 acc_train: 0.8953 acc_val: 0.9778\n",
      "Epoch: 3757 loss_train: 0.4752 acc_train: 0.9035 acc_val: 0.9756\n",
      "Epoch: 3758 loss_train: 6.8983 acc_train: 0.9020 acc_val: 0.9756\n",
      "Epoch: 3759 loss_train: 13.7623 acc_train: 0.8849 acc_val: 0.9778\n",
      "Epoch: 3760 loss_train: 0.1842 acc_train: 0.8998 acc_val: 0.9756\n",
      "Epoch: 3761 loss_train: 12.6041 acc_train: 0.8931 acc_val: 0.9756\n",
      "Epoch: 3762 loss_train: 4.4419 acc_train: 0.9035 acc_val: 0.9778\n",
      "Epoch: 3763 loss_train: 9.4844 acc_train: 0.8894 acc_val: 0.9778\n",
      "Epoch: 3764 loss_train: 3.3447 acc_train: 0.8827 acc_val: 0.9778\n",
      "Epoch: 3765 loss_train: 15.7906 acc_train: 0.8901 acc_val: 0.9778\n",
      "Epoch: 3766 loss_train: 32.0586 acc_train: 0.8827 acc_val: 0.9800\n",
      "Epoch: 3767 loss_train: 5.7448 acc_train: 0.8894 acc_val: 0.9733\n",
      "Epoch: 3768 loss_train: 33.0708 acc_train: 0.8938 acc_val: 0.9733\n",
      "Epoch: 3769 loss_train: 8.0863 acc_train: 0.8879 acc_val: 0.9778\n",
      "Epoch: 3770 loss_train: 3.8671 acc_train: 0.8976 acc_val: 0.9756\n",
      "Epoch: 3771 loss_train: 28.2882 acc_train: 0.8990 acc_val: 0.9733\n",
      "Epoch: 3772 loss_train: 5.1182 acc_train: 0.8834 acc_val: 0.9756\n",
      "Epoch: 3773 loss_train: 1.3643 acc_train: 0.8946 acc_val: 0.9756\n",
      "Epoch: 3774 loss_train: 6.0341 acc_train: 0.8805 acc_val: 0.9733\n",
      "Epoch: 3775 loss_train: 0.1940 acc_train: 0.8857 acc_val: 0.9733\n",
      "Epoch: 3776 loss_train: 0.1993 acc_train: 0.8775 acc_val: 0.9733\n",
      "Epoch: 3777 loss_train: 18.6152 acc_train: 0.8894 acc_val: 0.9756\n",
      "Epoch: 3778 loss_train: 9.6916 acc_train: 0.8872 acc_val: 0.9756\n",
      "Epoch: 3779 loss_train: 28.9954 acc_train: 0.8909 acc_val: 0.9756\n",
      "Epoch: 3780 loss_train: 4.6875 acc_train: 0.8716 acc_val: 0.9733\n",
      "Epoch: 3781 loss_train: 0.3641 acc_train: 0.8879 acc_val: 0.9756\n",
      "Epoch: 3782 loss_train: 13.8416 acc_train: 0.8886 acc_val: 0.9756\n",
      "Epoch: 3783 loss_train: 5.4545 acc_train: 0.8760 acc_val: 0.9778\n",
      "Epoch: 3784 loss_train: 13.8010 acc_train: 0.8797 acc_val: 0.9778\n",
      "Epoch: 3785 loss_train: 1.2383 acc_train: 0.8953 acc_val: 0.9778\n",
      "Epoch: 3786 loss_train: 5.7403 acc_train: 0.8782 acc_val: 0.9778\n",
      "Epoch: 3787 loss_train: 22.0497 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 3788 loss_train: 0.1940 acc_train: 0.8886 acc_val: 0.9756\n",
      "Epoch: 3789 loss_train: 11.7100 acc_train: 0.8827 acc_val: 0.9778\n",
      "Epoch: 3790 loss_train: 15.0792 acc_train: 0.8849 acc_val: 0.9778\n",
      "Epoch: 3791 loss_train: 2.5353 acc_train: 0.8872 acc_val: 0.9778\n",
      "Epoch: 3792 loss_train: 3.0019 acc_train: 0.8864 acc_val: 0.9778\n",
      "Epoch: 3793 loss_train: 0.1900 acc_train: 0.8812 acc_val: 0.9800\n",
      "Epoch: 3794 loss_train: 3.2922 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 3795 loss_train: 8.4239 acc_train: 0.8753 acc_val: 0.9800\n",
      "Epoch: 3796 loss_train: 2.0671 acc_train: 0.8953 acc_val: 0.9778\n",
      "Epoch: 3797 loss_train: 0.1866 acc_train: 0.8901 acc_val: 0.9778\n",
      "Epoch: 3798 loss_train: 0.7509 acc_train: 0.9079 acc_val: 0.9778\n",
      "Epoch: 3799 loss_train: 13.8010 acc_train: 0.8857 acc_val: 0.9778\n",
      "Epoch: 3800 loss_train: 0.1896 acc_train: 0.8990 acc_val: 0.9778\n",
      "Epoch: 3801 loss_train: 1.1999 acc_train: 0.8938 acc_val: 0.9778\n",
      "Epoch: 3802 loss_train: 0.2031 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 3803 loss_train: 1.2682 acc_train: 0.9050 acc_val: 0.9778\n",
      "Epoch: 3804 loss_train: 2.5125 acc_train: 0.8797 acc_val: 0.9800\n",
      "Epoch: 3805 loss_train: 0.1679 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 3806 loss_train: 0.1729 acc_train: 0.8953 acc_val: 0.9800\n",
      "Epoch: 3807 loss_train: 0.2026 acc_train: 0.8797 acc_val: 0.9800\n",
      "Epoch: 3808 loss_train: 0.1930 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 3809 loss_train: 0.2998 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 3810 loss_train: 0.1878 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 3811 loss_train: 0.1960 acc_train: 0.8820 acc_val: 0.9800\n",
      "Epoch: 3812 loss_train: 0.1966 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 3813 loss_train: 0.2034 acc_train: 0.8805 acc_val: 0.9800\n",
      "Epoch: 3814 loss_train: 0.1958 acc_train: 0.8924 acc_val: 0.9800\n",
      "Epoch: 3815 loss_train: 0.1820 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 3816 loss_train: 0.8542 acc_train: 0.8879 acc_val: 0.9800\n",
      "Epoch: 3817 loss_train: 0.1659 acc_train: 0.9057 acc_val: 0.9800\n",
      "Epoch: 3818 loss_train: 1.4189 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 3819 loss_train: 0.2062 acc_train: 0.8745 acc_val: 0.9800\n",
      "Epoch: 3820 loss_train: 0.3076 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 3821 loss_train: 0.1755 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 3822 loss_train: 0.1994 acc_train: 0.8820 acc_val: 0.9800\n",
      "Epoch: 3823 loss_train: 0.1833 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 3824 loss_train: 0.1754 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 3825 loss_train: 0.1922 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 3826 loss_train: 0.1915 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 3827 loss_train: 0.1658 acc_train: 0.9124 acc_val: 0.9800\n",
      "Epoch: 3828 loss_train: 0.1639 acc_train: 0.8968 acc_val: 0.9800\n",
      "Epoch: 3829 loss_train: 0.1883 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 3830 loss_train: 0.1865 acc_train: 0.8842 acc_val: 0.9800\n",
      "Epoch: 3831 loss_train: 0.1856 acc_train: 0.8812 acc_val: 0.9800\n",
      "Epoch: 3832 loss_train: 0.1955 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 3833 loss_train: 0.1806 acc_train: 0.8976 acc_val: 0.9800\n",
      "Epoch: 3834 loss_train: 0.1717 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 3835 loss_train: 0.1860 acc_train: 0.8901 acc_val: 0.9800\n",
      "Epoch: 3836 loss_train: 0.1707 acc_train: 0.9065 acc_val: 0.9800\n",
      "Epoch: 3837 loss_train: 0.2101 acc_train: 0.8723 acc_val: 0.9800\n",
      "Epoch: 3838 loss_train: 0.1892 acc_train: 0.8931 acc_val: 0.9800\n",
      "Epoch: 3839 loss_train: 0.1813 acc_train: 0.8961 acc_val: 0.9800\n",
      "Epoch: 3840 loss_train: 0.1912 acc_train: 0.8886 acc_val: 0.9800\n",
      "Epoch: 3841 loss_train: 0.2071 acc_train: 0.8753 acc_val: 0.9800\n",
      "Epoch: 3842 loss_train: 0.1750 acc_train: 0.8953 acc_val: 0.9800\n",
      "Epoch: 3843 loss_train: 0.1903 acc_train: 0.8976 acc_val: 0.9800\n",
      "Epoch: 3844 loss_train: 0.2132 acc_train: 0.8701 acc_val: 0.9800\n",
      "Epoch: 3845 loss_train: 0.1747 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 3846 loss_train: 0.1914 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 3847 loss_train: 0.1977 acc_train: 0.8723 acc_val: 0.9800\n",
      "Epoch: 3848 loss_train: 0.2019 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 3849 loss_train: 0.1647 acc_train: 0.8946 acc_val: 0.9800\n",
      "Epoch: 3850 loss_train: 0.1882 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 3851 loss_train: 0.1985 acc_train: 0.8886 acc_val: 0.9800\n",
      "Epoch: 3852 loss_train: 0.1786 acc_train: 0.8864 acc_val: 0.9800\n",
      "Epoch: 3853 loss_train: 0.2029 acc_train: 0.8842 acc_val: 0.9800\n",
      "Epoch: 3854 loss_train: 0.1886 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 3855 loss_train: 0.1762 acc_train: 0.8998 acc_val: 0.9800\n",
      "Epoch: 3856 loss_train: 0.1837 acc_train: 0.8834 acc_val: 0.9800\n",
      "Epoch: 3857 loss_train: 0.2146 acc_train: 0.8664 acc_val: 0.9800\n",
      "Epoch: 3858 loss_train: 0.1800 acc_train: 0.8857 acc_val: 0.9800\n",
      "Epoch: 3859 loss_train: 0.2023 acc_train: 0.8805 acc_val: 0.9800\n",
      "Epoch: 3860 loss_train: 0.1773 acc_train: 0.9005 acc_val: 0.9800\n",
      "Epoch: 3861 loss_train: 0.1741 acc_train: 0.8901 acc_val: 0.9778\n",
      "Epoch: 3862 loss_train: 0.1832 acc_train: 0.8886 acc_val: 0.9778\n",
      "Epoch: 3863 loss_train: 0.1714 acc_train: 0.8983 acc_val: 0.9778\n",
      "Epoch: 3864 loss_train: 0.2014 acc_train: 0.8842 acc_val: 0.9778\n",
      "Epoch: 3865 loss_train: 0.1691 acc_train: 0.9005 acc_val: 0.9778\n",
      "Epoch: 3866 loss_train: 0.1803 acc_train: 0.8894 acc_val: 0.9778\n",
      "Epoch: 3867 loss_train: 0.1890 acc_train: 0.8879 acc_val: 0.9778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3868 loss_train: 0.1938 acc_train: 0.8864 acc_val: 0.9778\n",
      "Epoch: 3869 loss_train: 0.1720 acc_train: 0.9005 acc_val: 0.9778\n",
      "Epoch: 3870 loss_train: 0.1993 acc_train: 0.8849 acc_val: 0.9778\n",
      "Epoch: 3871 loss_train: 0.2005 acc_train: 0.8790 acc_val: 0.9778\n",
      "Epoch: 3872 loss_train: 0.1601 acc_train: 0.8998 acc_val: 0.9778\n",
      "Epoch: 3873 loss_train: 0.1917 acc_train: 0.8879 acc_val: 0.9778\n",
      "Epoch: 3874 loss_train: 0.1985 acc_train: 0.8872 acc_val: 0.9778\n",
      "Epoch: 3875 loss_train: 0.1925 acc_train: 0.8909 acc_val: 0.9778\n",
      "Epoch: 3876 loss_train: 0.2082 acc_train: 0.8827 acc_val: 0.9778\n",
      "Epoch: 3877 loss_train: 0.2120 acc_train: 0.8731 acc_val: 0.9778\n",
      "Epoch: 3878 loss_train: 0.1892 acc_train: 0.8864 acc_val: 0.9778\n",
      "Epoch: 3879 loss_train: 0.1782 acc_train: 0.8968 acc_val: 0.9778\n",
      "Epoch: 3880 loss_train: 0.2003 acc_train: 0.8849 acc_val: 0.9778\n",
      "Epoch: 3881 loss_train: 0.1968 acc_train: 0.8782 acc_val: 0.9778\n",
      "Epoch: 3882 loss_train: 0.1815 acc_train: 0.8901 acc_val: 0.9778\n",
      "Epoch: 3883 loss_train: 0.1873 acc_train: 0.8938 acc_val: 0.9778\n",
      "Epoch: 3884 loss_train: 0.1995 acc_train: 0.8782 acc_val: 0.9778\n",
      "Epoch: 3885 loss_train: 0.1900 acc_train: 0.8909 acc_val: 0.9778\n",
      "Epoch: 3886 loss_train: 0.1908 acc_train: 0.8983 acc_val: 0.9778\n",
      "Epoch: 3887 loss_train: 0.1845 acc_train: 0.8916 acc_val: 0.9778\n",
      "Epoch: 3888 loss_train: 0.2040 acc_train: 0.8872 acc_val: 0.9778\n",
      "Epoch: 3889 loss_train: 0.1848 acc_train: 0.8894 acc_val: 0.9778\n",
      "Epoch: 3890 loss_train: 0.2017 acc_train: 0.8834 acc_val: 0.9778\n",
      "Epoch: 3891 loss_train: 0.1853 acc_train: 0.8909 acc_val: 0.9778\n",
      "Epoch: 3892 loss_train: 0.1822 acc_train: 0.8931 acc_val: 0.9778\n",
      "Epoch: 3893 loss_train: 0.1667 acc_train: 0.8990 acc_val: 0.9778\n",
      "Epoch: 3894 loss_train: 0.1906 acc_train: 0.8872 acc_val: 0.9778\n",
      "Epoch: 3895 loss_train: 0.2049 acc_train: 0.8775 acc_val: 0.9778\n",
      "Epoch: 3896 loss_train: 0.1865 acc_train: 0.8797 acc_val: 0.9778\n",
      "Epoch: 3897 loss_train: 0.1789 acc_train: 0.8938 acc_val: 0.9778\n",
      "Epoch: 3898 loss_train: 0.1747 acc_train: 0.8924 acc_val: 0.9778\n",
      "Epoch: 3899 loss_train: 0.1878 acc_train: 0.8894 acc_val: 0.9778\n",
      "Epoch: 3900 loss_train: 0.1930 acc_train: 0.8879 acc_val: 0.9778\n",
      "Epoch: 3901 loss_train: 0.1931 acc_train: 0.8886 acc_val: 0.9778\n",
      "Epoch: 3902 loss_train: 0.1791 acc_train: 0.8968 acc_val: 0.9778\n",
      "Epoch: 3903 loss_train: 0.1791 acc_train: 0.8894 acc_val: 0.9778\n",
      "Epoch: 3904 loss_train: 0.2015 acc_train: 0.8768 acc_val: 0.9778\n",
      "Epoch: 3905 loss_train: 0.1918 acc_train: 0.8849 acc_val: 0.9778\n",
      "Epoch: 3906 loss_train: 0.2007 acc_train: 0.8775 acc_val: 0.9778\n",
      "Epoch: 3907 loss_train: 0.1636 acc_train: 0.8924 acc_val: 0.9778\n",
      "Epoch: 3908 loss_train: 0.1945 acc_train: 0.8849 acc_val: 0.9778\n",
      "Epoch: 3909 loss_train: 0.1972 acc_train: 0.8864 acc_val: 0.9778\n",
      "Epoch: 3910 loss_train: 0.1738 acc_train: 0.8953 acc_val: 0.9778\n",
      "Epoch: 3911 loss_train: 0.1721 acc_train: 0.8998 acc_val: 0.9778\n",
      "Epoch: 3912 loss_train: 0.1550 acc_train: 0.9169 acc_val: 0.9778\n",
      "Epoch: 3913 loss_train: 0.1647 acc_train: 0.9050 acc_val: 0.9778\n",
      "Epoch: 3914 loss_train: 0.1980 acc_train: 0.8894 acc_val: 0.9778\n",
      "Epoch: 3915 loss_train: 0.1979 acc_train: 0.8790 acc_val: 0.9778\n",
      "Epoch: 3916 loss_train: 0.1794 acc_train: 0.8872 acc_val: 0.9778\n",
      "Epoch: 3917 loss_train: 0.1960 acc_train: 0.8782 acc_val: 0.9778\n",
      "Epoch: 3918 loss_train: 0.1920 acc_train: 0.8931 acc_val: 0.9778\n",
      "Epoch: 3919 loss_train: 0.2051 acc_train: 0.8708 acc_val: 0.9778\n",
      "Epoch: 3920 loss_train: 0.1780 acc_train: 0.8946 acc_val: 0.9778\n",
      "Epoch: 3921 loss_train: 0.1830 acc_train: 0.8938 acc_val: 0.9778\n",
      "Epoch: 3922 loss_train: 0.1787 acc_train: 0.8909 acc_val: 0.9778\n",
      "Epoch: 3923 loss_train: 0.1737 acc_train: 0.8990 acc_val: 0.9778\n",
      "Epoch: 3924 loss_train: 0.2090 acc_train: 0.8782 acc_val: 0.9778\n",
      "Epoch: 3925 loss_train: 0.2005 acc_train: 0.8820 acc_val: 0.9778\n",
      "Epoch: 3926 loss_train: 0.2066 acc_train: 0.8790 acc_val: 0.9778\n",
      "Epoch: 3927 loss_train: 0.1608 acc_train: 0.9027 acc_val: 0.9778\n",
      "Epoch: 3928 loss_train: 0.1788 acc_train: 0.9094 acc_val: 0.9778\n",
      "Epoch: 3929 loss_train: 0.1940 acc_train: 0.8834 acc_val: 0.9778\n",
      "Epoch: 3930 loss_train: 0.1911 acc_train: 0.8782 acc_val: 0.9778\n",
      "Epoch: 3931 loss_train: 0.1902 acc_train: 0.8901 acc_val: 0.9778\n",
      "Epoch: 3932 loss_train: 0.1774 acc_train: 0.9027 acc_val: 0.9778\n",
      "Epoch: 3933 loss_train: 0.1763 acc_train: 0.8998 acc_val: 0.9778\n",
      "Epoch: 3934 loss_train: 0.1633 acc_train: 0.9057 acc_val: 0.9778\n",
      "Epoch: 3935 loss_train: 0.1911 acc_train: 0.8864 acc_val: 0.9778\n",
      "Epoch: 3936 loss_train: 0.1600 acc_train: 0.8990 acc_val: 0.9778\n",
      "Epoch: 3937 loss_train: 0.1809 acc_train: 0.8976 acc_val: 0.9778\n",
      "Epoch: 3938 loss_train: 0.1811 acc_train: 0.8953 acc_val: 0.9778\n",
      "Epoch: 3939 loss_train: 0.1878 acc_train: 0.8990 acc_val: 0.9778\n",
      "Epoch: 3940 loss_train: 0.1666 acc_train: 0.8976 acc_val: 0.9778\n",
      "Epoch: 3941 loss_train: 0.1950 acc_train: 0.8849 acc_val: 0.9778\n",
      "Epoch: 3942 loss_train: 0.1805 acc_train: 0.8931 acc_val: 0.9778\n",
      "Epoch: 3943 loss_train: 0.1827 acc_train: 0.8849 acc_val: 0.9778\n",
      "Epoch: 3944 loss_train: 0.1767 acc_train: 0.9020 acc_val: 0.9778\n",
      "Epoch: 3945 loss_train: 0.1880 acc_train: 0.8924 acc_val: 0.9778\n",
      "Epoch: 3946 loss_train: 0.1838 acc_train: 0.8931 acc_val: 0.9778\n",
      "Epoch: 3947 loss_train: 0.1966 acc_train: 0.8849 acc_val: 0.9778\n",
      "Epoch: 3948 loss_train: 0.1952 acc_train: 0.8886 acc_val: 0.9778\n",
      "Epoch: 3949 loss_train: 0.1788 acc_train: 0.8968 acc_val: 0.9778\n",
      "Epoch: 3950 loss_train: 0.1702 acc_train: 0.9117 acc_val: 0.9778\n",
      "Epoch: 3951 loss_train: 0.1827 acc_train: 0.8872 acc_val: 0.9778\n",
      "Epoch: 3952 loss_train: 0.1827 acc_train: 0.8924 acc_val: 0.9778\n",
      "Epoch: 3953 loss_train: 0.1725 acc_train: 0.8953 acc_val: 0.9778\n",
      "Epoch: 3954 loss_train: 0.1865 acc_train: 0.8879 acc_val: 0.9778\n",
      "Epoch: 3955 loss_train: 0.1824 acc_train: 0.8953 acc_val: 0.9778\n",
      "Epoch: 3956 loss_train: 0.1970 acc_train: 0.8820 acc_val: 0.9778\n",
      "Epoch: 3957 loss_train: 0.1874 acc_train: 0.8857 acc_val: 0.9778\n",
      "Epoch: 3958 loss_train: 0.1943 acc_train: 0.8797 acc_val: 0.9778\n",
      "Epoch: 3959 loss_train: 0.2040 acc_train: 0.8834 acc_val: 0.9778\n",
      "Epoch: 3960 loss_train: 0.1871 acc_train: 0.8953 acc_val: 0.9778\n",
      "Epoch: 3961 loss_train: 0.1649 acc_train: 0.9124 acc_val: 0.9778\n",
      "Epoch: 3962 loss_train: 0.1888 acc_train: 0.9013 acc_val: 0.9778\n",
      "Epoch: 3963 loss_train: 0.1906 acc_train: 0.8842 acc_val: 0.9778\n",
      "Epoch: 3964 loss_train: 0.1878 acc_train: 0.8909 acc_val: 0.9778\n",
      "Epoch: 3965 loss_train: 0.1721 acc_train: 0.8968 acc_val: 0.9778\n",
      "Epoch: 3966 loss_train: 0.1864 acc_train: 0.8938 acc_val: 0.9778\n",
      "Epoch: 3967 loss_train: 0.1861 acc_train: 0.8894 acc_val: 0.9778\n",
      "Epoch: 3968 loss_train: 0.1965 acc_train: 0.8849 acc_val: 0.9778\n",
      "Epoch: 3969 loss_train: 0.1924 acc_train: 0.8931 acc_val: 0.9778\n",
      "Epoch: 3970 loss_train: 0.1985 acc_train: 0.8909 acc_val: 0.9778\n",
      "Epoch: 3971 loss_train: 0.1888 acc_train: 0.8731 acc_val: 0.9778\n",
      "Epoch: 3972 loss_train: 0.1925 acc_train: 0.8827 acc_val: 0.9778\n",
      "Epoch: 3973 loss_train: 0.1715 acc_train: 0.9005 acc_val: 0.9778\n",
      "Epoch: 3974 loss_train: 0.1768 acc_train: 0.8901 acc_val: 0.9778\n",
      "Epoch: 3975 loss_train: 0.1891 acc_train: 0.8872 acc_val: 0.9778\n",
      "Epoch: 3976 loss_train: 0.1999 acc_train: 0.8834 acc_val: 0.9778\n",
      "Epoch: 3977 loss_train: 0.2079 acc_train: 0.8775 acc_val: 0.9778\n",
      "Epoch: 3978 loss_train: 0.1865 acc_train: 0.8916 acc_val: 0.9778\n",
      "Epoch: 3979 loss_train: 0.1749 acc_train: 0.8924 acc_val: 0.9778\n",
      "Epoch: 3980 loss_train: 0.2078 acc_train: 0.8753 acc_val: 0.9778\n",
      "Epoch: 3981 loss_train: 0.2064 acc_train: 0.8775 acc_val: 0.9778\n",
      "Epoch: 3982 loss_train: 0.1674 acc_train: 0.9035 acc_val: 0.9778\n",
      "Epoch: 3983 loss_train: 0.1690 acc_train: 0.8990 acc_val: 0.9778\n",
      "Epoch: 3984 loss_train: 0.1686 acc_train: 0.8990 acc_val: 0.9778\n",
      "Epoch: 3985 loss_train: 0.1815 acc_train: 0.8916 acc_val: 0.9778\n",
      "Epoch: 3986 loss_train: 0.1853 acc_train: 0.8872 acc_val: 0.9778\n",
      "Epoch: 3987 loss_train: 0.1728 acc_train: 0.8976 acc_val: 0.9778\n",
      "Epoch: 3988 loss_train: 0.1903 acc_train: 0.8857 acc_val: 0.9778\n",
      "Epoch: 3989 loss_train: 0.1873 acc_train: 0.8961 acc_val: 0.9778\n",
      "Epoch: 3990 loss_train: 0.1918 acc_train: 0.8805 acc_val: 0.9778\n",
      "Epoch: 3991 loss_train: 0.1985 acc_train: 0.8864 acc_val: 0.9778\n",
      "Epoch: 3992 loss_train: 0.1787 acc_train: 0.8857 acc_val: 0.9778\n",
      "Epoch: 3993 loss_train: 0.1912 acc_train: 0.8872 acc_val: 0.9778\n",
      "Epoch: 3994 loss_train: 0.1821 acc_train: 0.8946 acc_val: 0.9778\n",
      "Epoch: 3995 loss_train: 0.1860 acc_train: 0.8946 acc_val: 0.9778\n",
      "Epoch: 3996 loss_train: 0.1720 acc_train: 0.9035 acc_val: 0.9778\n",
      "Epoch: 3997 loss_train: 0.1843 acc_train: 0.8961 acc_val: 0.9778\n",
      "Epoch: 3998 loss_train: 0.1908 acc_train: 0.8857 acc_val: 0.9778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3999 loss_train: 0.1737 acc_train: 0.9035 acc_val: 0.9778\n",
      "Epoch: 4000 loss_train: 0.1954 acc_train: 0.8760 acc_val: 0.9778\n",
      "Epoch: 4001 loss_train: 0.1844 acc_train: 0.8946 acc_val: 0.9778\n",
      "Epoch: 4002 loss_train: 0.1870 acc_train: 0.8924 acc_val: 0.9778\n",
      "Epoch: 4003 loss_train: 0.1571 acc_train: 0.9020 acc_val: 0.9778\n",
      "Epoch: 4004 loss_train: 0.1908 acc_train: 0.8790 acc_val: 0.9778\n",
      "Epoch: 4005 loss_train: 0.1854 acc_train: 0.8976 acc_val: 0.9778\n",
      "Epoch: 4006 loss_train: 0.1902 acc_train: 0.8983 acc_val: 0.9778\n",
      "Epoch: 4007 loss_train: 0.1932 acc_train: 0.8849 acc_val: 0.9778\n",
      "Epoch: 4008 loss_train: 0.1969 acc_train: 0.8872 acc_val: 0.9778\n",
      "Epoch: 4009 loss_train: 0.1818 acc_train: 0.8924 acc_val: 0.9778\n",
      "Epoch: 4010 loss_train: 0.1840 acc_train: 0.8849 acc_val: 0.9778\n",
      "Epoch: 4011 loss_train: 0.2020 acc_train: 0.8849 acc_val: 0.9778\n",
      "Epoch: 4012 loss_train: 0.1896 acc_train: 0.8931 acc_val: 0.9778\n",
      "Epoch: 4013 loss_train: 0.1973 acc_train: 0.8864 acc_val: 0.9778\n",
      "Epoch: 4014 loss_train: 0.1752 acc_train: 0.8916 acc_val: 0.9778\n",
      "Epoch: 4015 loss_train: 0.1811 acc_train: 0.9005 acc_val: 0.9778\n",
      "Epoch: 4016 loss_train: 0.1640 acc_train: 0.8961 acc_val: 0.9778\n",
      "Epoch: 4017 loss_train: 0.1802 acc_train: 0.8916 acc_val: 0.9778\n",
      "Epoch: 4018 loss_train: 0.1877 acc_train: 0.9050 acc_val: 0.9778\n",
      "Epoch: 4019 loss_train: 0.2036 acc_train: 0.8745 acc_val: 0.9778\n",
      "Epoch: 4020 loss_train: 0.1890 acc_train: 0.8894 acc_val: 0.9778\n",
      "Epoch: 4021 loss_train: 0.1748 acc_train: 0.8953 acc_val: 0.9778\n",
      "Epoch: 4022 loss_train: 0.1957 acc_train: 0.8827 acc_val: 0.9778\n",
      "Epoch: 4023 loss_train: 0.1840 acc_train: 0.8938 acc_val: 0.9778\n",
      "Epoch: 4024 loss_train: 0.1816 acc_train: 0.9005 acc_val: 0.9778\n",
      "Epoch: 4025 loss_train: 0.1928 acc_train: 0.8834 acc_val: 0.9778\n",
      "Epoch: 4026 loss_train: 0.1730 acc_train: 0.8886 acc_val: 0.9778\n",
      "Epoch: 4027 loss_train: 0.1670 acc_train: 0.8938 acc_val: 0.9778\n",
      "Epoch: 4028 loss_train: 0.1818 acc_train: 0.8961 acc_val: 0.9778\n",
      "Epoch: 4029 loss_train: 0.1833 acc_train: 0.8931 acc_val: 0.9778\n",
      "Epoch: 4030 loss_train: 0.2042 acc_train: 0.8790 acc_val: 0.9778\n",
      "Epoch: 4031 loss_train: 0.1883 acc_train: 0.8886 acc_val: 0.9778\n",
      "Epoch: 4032 loss_train: 0.2028 acc_train: 0.8864 acc_val: 0.9778\n",
      "Epoch: 4033 loss_train: 0.1644 acc_train: 0.9042 acc_val: 0.9778\n",
      "Epoch: 4034 loss_train: 0.2051 acc_train: 0.8797 acc_val: 0.9778\n",
      "Epoch: 4035 loss_train: 0.1866 acc_train: 0.8805 acc_val: 0.9778\n",
      "Epoch: 4036 loss_train: 0.1952 acc_train: 0.8909 acc_val: 0.9778\n",
      "Epoch: 4037 loss_train: 0.1805 acc_train: 0.8953 acc_val: 0.9778\n",
      "Epoch: 4038 loss_train: 0.1875 acc_train: 0.8842 acc_val: 0.9778\n",
      "Epoch: 4039 loss_train: 0.1973 acc_train: 0.8857 acc_val: 0.9778\n",
      "Epoch: 4040 loss_train: 0.2005 acc_train: 0.8775 acc_val: 0.9778\n",
      "Epoch: 4041 loss_train: 0.1970 acc_train: 0.8834 acc_val: 0.9778\n",
      "Epoch: 4042 loss_train: 0.1878 acc_train: 0.8849 acc_val: 0.9778\n",
      "Epoch: 4043 loss_train: 0.1901 acc_train: 0.8938 acc_val: 0.9778\n",
      "Epoch: 4044 loss_train: 0.2185 acc_train: 0.8731 acc_val: 0.9778\n",
      "Epoch: 4045 loss_train: 0.1815 acc_train: 0.8931 acc_val: 0.9778\n",
      "Epoch: 4046 loss_train: 0.1843 acc_train: 0.8886 acc_val: 0.9778\n",
      "Epoch: 4047 loss_train: 0.1893 acc_train: 0.8931 acc_val: 0.9778\n",
      "Epoch: 4048 loss_train: 0.1674 acc_train: 0.8998 acc_val: 0.9778\n",
      "Epoch: 4049 loss_train: 0.1703 acc_train: 0.9072 acc_val: 0.9778\n",
      "Epoch: 4050 loss_train: 0.1912 acc_train: 0.8827 acc_val: 0.9778\n",
      "Epoch: 4051 loss_train: 0.2002 acc_train: 0.8827 acc_val: 0.9778\n",
      "Epoch: 4052 loss_train: 0.1981 acc_train: 0.8879 acc_val: 0.9778\n",
      "Epoch: 4053 loss_train: 0.1853 acc_train: 0.8990 acc_val: 0.9778\n",
      "Epoch: 4054 loss_train: 0.1937 acc_train: 0.8872 acc_val: 0.9778\n",
      "Epoch: 4055 loss_train: 0.1938 acc_train: 0.8879 acc_val: 0.9778\n",
      "Epoch: 4056 loss_train: 0.1798 acc_train: 0.8968 acc_val: 0.9778\n",
      "Epoch: 4057 loss_train: 0.1828 acc_train: 0.8938 acc_val: 0.9778\n",
      "Epoch: 4058 loss_train: 0.1876 acc_train: 0.8886 acc_val: 0.9778\n",
      "Epoch: 4059 loss_train: 0.1936 acc_train: 0.8894 acc_val: 0.9778\n",
      "Epoch: 4060 loss_train: 0.1611 acc_train: 0.8976 acc_val: 0.9778\n",
      "Epoch: 4061 loss_train: 0.1994 acc_train: 0.8834 acc_val: 0.9778\n",
      "Epoch: 4062 loss_train: 0.1905 acc_train: 0.8797 acc_val: 0.9778\n",
      "Epoch: 4063 loss_train: 0.1923 acc_train: 0.8864 acc_val: 0.9778\n",
      "Epoch: 4064 loss_train: 0.1808 acc_train: 0.8946 acc_val: 0.9778\n",
      "Epoch: 4065 loss_train: 0.1927 acc_train: 0.8820 acc_val: 0.9778\n",
      "Epoch: 4066 loss_train: 0.1773 acc_train: 0.8998 acc_val: 0.9778\n",
      "Epoch: 4067 loss_train: 0.1699 acc_train: 0.8894 acc_val: 0.9778\n",
      "Epoch: 4068 loss_train: 0.1863 acc_train: 0.8820 acc_val: 0.9778\n",
      "Epoch: 4069 loss_train: 0.1831 acc_train: 0.8849 acc_val: 0.9778\n",
      "Epoch: 4070 loss_train: 0.1678 acc_train: 0.8998 acc_val: 0.9778\n",
      "Epoch: 4071 loss_train: 0.1986 acc_train: 0.8656 acc_val: 0.9778\n",
      "Epoch: 4072 loss_train: 0.1803 acc_train: 0.8931 acc_val: 0.9778\n",
      "Epoch: 4073 loss_train: 0.1854 acc_train: 0.8842 acc_val: 0.9778\n",
      "Epoch: 4074 loss_train: 0.1834 acc_train: 0.8998 acc_val: 0.9778\n",
      "Epoch: 4075 loss_train: 0.1815 acc_train: 0.9072 acc_val: 0.9778\n",
      "Epoch: 4076 loss_train: 0.1764 acc_train: 0.8998 acc_val: 0.9778\n",
      "Epoch: 4077 loss_train: 0.1889 acc_train: 0.8924 acc_val: 0.9778\n",
      "Epoch: 4078 loss_train: 0.1849 acc_train: 0.8938 acc_val: 0.9778\n",
      "Epoch: 4079 loss_train: 0.1780 acc_train: 0.8953 acc_val: 0.9778\n",
      "Epoch: 4080 loss_train: 0.1837 acc_train: 0.8909 acc_val: 0.9778\n",
      "Epoch: 4081 loss_train: 0.1943 acc_train: 0.8834 acc_val: 0.9778\n",
      "Epoch: 4082 loss_train: 0.1416 acc_train: 0.9109 acc_val: 0.9778\n",
      "Epoch: 4083 loss_train: 0.1620 acc_train: 0.9094 acc_val: 0.9778\n",
      "Epoch: 4084 loss_train: 0.2136 acc_train: 0.8738 acc_val: 0.9778\n",
      "Epoch: 4085 loss_train: 0.2124 acc_train: 0.8760 acc_val: 0.9778\n",
      "Epoch: 4086 loss_train: 0.1912 acc_train: 0.8797 acc_val: 0.9778\n",
      "Epoch: 4087 loss_train: 0.1872 acc_train: 0.8909 acc_val: 0.9778\n",
      "Epoch: 4088 loss_train: 0.1799 acc_train: 0.8961 acc_val: 0.9778\n",
      "Epoch: 4089 loss_train: 0.2014 acc_train: 0.8805 acc_val: 0.9778\n",
      "Epoch: 4090 loss_train: 0.1894 acc_train: 0.8857 acc_val: 0.9778\n",
      "Epoch: 4091 loss_train: 0.1934 acc_train: 0.8879 acc_val: 0.9778\n",
      "Epoch: 4092 loss_train: 0.1986 acc_train: 0.8849 acc_val: 0.9778\n",
      "Epoch: 4093 loss_train: 0.2156 acc_train: 0.8731 acc_val: 0.9778\n",
      "Epoch: 4094 loss_train: 0.2078 acc_train: 0.8872 acc_val: 0.9778\n",
      "Epoch: 4095 loss_train: 0.1768 acc_train: 0.9042 acc_val: 0.9778\n",
      "Epoch: 4096 loss_train: 0.1710 acc_train: 0.8983 acc_val: 0.9778\n",
      "Epoch: 4097 loss_train: 0.1869 acc_train: 0.8953 acc_val: 0.9778\n",
      "Epoch: 4098 loss_train: 0.1666 acc_train: 0.9027 acc_val: 0.9778\n",
      "Epoch: 4099 loss_train: 0.1795 acc_train: 0.8946 acc_val: 0.9778\n",
      "Epoch: 4100 loss_train: 0.1920 acc_train: 0.8886 acc_val: 0.9778\n",
      "Epoch: 4101 loss_train: 0.1784 acc_train: 0.8961 acc_val: 0.9778\n",
      "Epoch: 4102 loss_train: 0.1906 acc_train: 0.8916 acc_val: 0.9778\n",
      "Epoch: 4103 loss_train: 0.1940 acc_train: 0.8886 acc_val: 0.9778\n",
      "Epoch: 4104 loss_train: 0.1868 acc_train: 0.8938 acc_val: 0.9778\n",
      "Epoch: 4105 loss_train: 0.1893 acc_train: 0.8916 acc_val: 0.9778\n",
      "Epoch: 4106 loss_train: 0.1773 acc_train: 0.8916 acc_val: 0.9778\n",
      "Epoch: 4107 loss_train: 0.1748 acc_train: 0.8983 acc_val: 0.9778\n",
      "Epoch: 4108 loss_train: 0.1879 acc_train: 0.8916 acc_val: 0.9778\n",
      "Epoch: 4109 loss_train: 0.1911 acc_train: 0.8886 acc_val: 0.9778\n",
      "Epoch: 4110 loss_train: 0.2054 acc_train: 0.8782 acc_val: 0.9778\n",
      "Epoch: 4111 loss_train: 0.2004 acc_train: 0.8790 acc_val: 0.9778\n",
      "Epoch: 4112 loss_train: 0.2132 acc_train: 0.8723 acc_val: 0.9778\n",
      "Epoch: 4113 loss_train: 0.1878 acc_train: 0.8909 acc_val: 0.9778\n",
      "Epoch: 4114 loss_train: 0.1636 acc_train: 0.9042 acc_val: 0.9778\n",
      "Epoch: 4115 loss_train: 0.1789 acc_train: 0.8946 acc_val: 0.9778\n",
      "Epoch: 4116 loss_train: 0.1892 acc_train: 0.8879 acc_val: 0.9778\n",
      "Epoch: 4117 loss_train: 0.1880 acc_train: 0.8842 acc_val: 0.9778\n",
      "Epoch: 4118 loss_train: 0.1841 acc_train: 0.8983 acc_val: 0.9778\n",
      "Epoch: 4119 loss_train: 0.1893 acc_train: 0.8916 acc_val: 0.9778\n",
      "Epoch: 4120 loss_train: 0.1839 acc_train: 0.9005 acc_val: 0.9778\n",
      "Epoch: 4121 loss_train: 0.1796 acc_train: 0.8924 acc_val: 0.9778\n",
      "Epoch: 4122 loss_train: 0.1828 acc_train: 0.8909 acc_val: 0.9778\n",
      "Epoch: 4123 loss_train: 0.1782 acc_train: 0.8946 acc_val: 0.9778\n",
      "Epoch: 4124 loss_train: 0.1888 acc_train: 0.8820 acc_val: 0.9778\n",
      "Epoch: 4125 loss_train: 0.2052 acc_train: 0.8738 acc_val: 0.9778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4126 loss_train: 0.1639 acc_train: 0.9102 acc_val: 0.9778\n",
      "Epoch: 4127 loss_train: 0.1717 acc_train: 0.8983 acc_val: 0.9778\n",
      "Epoch: 4128 loss_train: 0.1994 acc_train: 0.8790 acc_val: 0.9778\n",
      "Epoch: 4129 loss_train: 0.1776 acc_train: 0.8842 acc_val: 0.9778\n",
      "Epoch: 4130 loss_train: 0.1897 acc_train: 0.8924 acc_val: 0.9778\n",
      "Epoch: 4131 loss_train: 0.1991 acc_train: 0.8775 acc_val: 0.9778\n",
      "Epoch: 4132 loss_train: 0.1667 acc_train: 0.8998 acc_val: 0.9778\n",
      "Epoch: 4133 loss_train: 0.1740 acc_train: 0.8998 acc_val: 0.9778\n",
      "Epoch: 4134 loss_train: 0.2116 acc_train: 0.8782 acc_val: 0.9778\n",
      "Epoch: 4135 loss_train: 0.1813 acc_train: 0.8894 acc_val: 0.9778\n",
      "Epoch: 4136 loss_train: 0.1748 acc_train: 0.8953 acc_val: 0.9778\n",
      "Epoch: 4137 loss_train: 0.1744 acc_train: 0.8909 acc_val: 0.9778\n",
      "Epoch: 4138 loss_train: 0.2012 acc_train: 0.8790 acc_val: 0.9778\n",
      "Epoch: 4139 loss_train: 0.1704 acc_train: 0.8983 acc_val: 0.9778\n",
      "Epoch: 4140 loss_train: 0.1865 acc_train: 0.8901 acc_val: 0.9778\n",
      "Epoch: 4141 loss_train: 0.1867 acc_train: 0.8797 acc_val: 0.9778\n",
      "Epoch: 4142 loss_train: 0.1984 acc_train: 0.8901 acc_val: 0.9778\n",
      "Epoch: 4143 loss_train: 0.1705 acc_train: 0.8976 acc_val: 0.9778\n",
      "Epoch: 4144 loss_train: 0.1857 acc_train: 0.8901 acc_val: 0.9778\n",
      "Epoch: 4145 loss_train: 0.1880 acc_train: 0.8924 acc_val: 0.9778\n",
      "Epoch: 4146 loss_train: 0.1747 acc_train: 0.8946 acc_val: 0.9778\n",
      "Epoch: 4147 loss_train: 0.1819 acc_train: 0.8961 acc_val: 0.9778\n",
      "Epoch: 4148 loss_train: 0.1906 acc_train: 0.8886 acc_val: 0.9778\n",
      "Epoch: 4149 loss_train: 0.1783 acc_train: 0.8983 acc_val: 0.9778\n",
      "Epoch: 4150 loss_train: 0.1781 acc_train: 0.9065 acc_val: 0.9778\n",
      "Epoch: 4151 loss_train: 0.1723 acc_train: 0.8946 acc_val: 0.9778\n",
      "Epoch: 4152 loss_train: 0.1640 acc_train: 0.9050 acc_val: 0.9778\n",
      "Epoch: 4153 loss_train: 0.1828 acc_train: 0.8931 acc_val: 0.9778\n",
      "Epoch: 4154 loss_train: 0.1837 acc_train: 0.8938 acc_val: 0.9778\n",
      "Epoch: 4155 loss_train: 0.1802 acc_train: 0.8886 acc_val: 0.9778\n",
      "Epoch: 4156 loss_train: 0.1913 acc_train: 0.8916 acc_val: 0.9778\n",
      "Epoch: 4157 loss_train: 0.1809 acc_train: 0.8827 acc_val: 0.9778\n",
      "Epoch: 4158 loss_train: 0.1602 acc_train: 0.9072 acc_val: 0.9778\n",
      "Epoch: 4159 loss_train: 0.1816 acc_train: 0.8938 acc_val: 0.9778\n",
      "Epoch: 4160 loss_train: 0.1809 acc_train: 0.9027 acc_val: 0.9778\n",
      "Epoch: 4161 loss_train: 0.1937 acc_train: 0.8886 acc_val: 0.9778\n",
      "Epoch: 4162 loss_train: 0.1922 acc_train: 0.8901 acc_val: 0.9778\n",
      "Epoch: 4163 loss_train: 0.1729 acc_train: 0.8976 acc_val: 0.9778\n",
      "Epoch: 4164 loss_train: 0.2054 acc_train: 0.8820 acc_val: 0.9778\n",
      "Epoch: 4165 loss_train: 0.1834 acc_train: 0.8864 acc_val: 0.9778\n",
      "Epoch: 4166 loss_train: 0.1622 acc_train: 0.9072 acc_val: 0.9778\n",
      "Epoch: 4167 loss_train: 0.2013 acc_train: 0.8753 acc_val: 0.9778\n",
      "Epoch: 4168 loss_train: 0.2004 acc_train: 0.8924 acc_val: 0.9778\n",
      "Epoch: 4169 loss_train: 0.1808 acc_train: 0.8998 acc_val: 0.9778\n",
      "Epoch: 4170 loss_train: 0.1959 acc_train: 0.8842 acc_val: 0.9778\n",
      "Epoch: 4171 loss_train: 0.1826 acc_train: 0.8886 acc_val: 0.9778\n",
      "Epoch: 4172 loss_train: 0.1846 acc_train: 0.8901 acc_val: 0.9778\n",
      "Epoch: 4173 loss_train: 0.1819 acc_train: 0.8968 acc_val: 0.9778\n",
      "Epoch: 4174 loss_train: 0.2012 acc_train: 0.8797 acc_val: 0.9778\n",
      "Epoch: 4175 loss_train: 0.1985 acc_train: 0.8753 acc_val: 0.9778\n",
      "Epoch: 4176 loss_train: 0.1632 acc_train: 0.9020 acc_val: 0.9778\n",
      "Epoch: 4177 loss_train: 0.1796 acc_train: 0.8849 acc_val: 0.9778\n",
      "Epoch: 4178 loss_train: 0.1802 acc_train: 0.8998 acc_val: 0.9778\n",
      "Epoch: 4179 loss_train: 0.1774 acc_train: 0.8990 acc_val: 0.9778\n",
      "Epoch: 4180 loss_train: 0.1979 acc_train: 0.8872 acc_val: 0.9778\n",
      "Epoch: 4181 loss_train: 0.1894 acc_train: 0.8961 acc_val: 0.9778\n",
      "Epoch: 4182 loss_train: 0.1973 acc_train: 0.8842 acc_val: 0.9778\n",
      "Epoch: 4183 loss_train: 0.1848 acc_train: 0.8879 acc_val: 0.9778\n",
      "Epoch: 4184 loss_train: 0.1785 acc_train: 0.9005 acc_val: 0.9778\n",
      "Epoch: 4185 loss_train: 0.1815 acc_train: 0.8901 acc_val: 0.9778\n",
      "Epoch: 4186 loss_train: 0.1793 acc_train: 0.8946 acc_val: 0.9778\n",
      "Epoch: 4187 loss_train: 0.1700 acc_train: 0.8931 acc_val: 0.9778\n",
      "Epoch: 4188 loss_train: 0.1949 acc_train: 0.8931 acc_val: 0.9778\n",
      "Epoch: 4189 loss_train: 0.1908 acc_train: 0.8894 acc_val: 0.9778\n",
      "Epoch: 4190 loss_train: 0.1852 acc_train: 0.8864 acc_val: 0.9778\n",
      "Epoch: 4191 loss_train: 0.1902 acc_train: 0.8901 acc_val: 0.9778\n",
      "Epoch: 4192 loss_train: 0.1876 acc_train: 0.8968 acc_val: 0.9778\n",
      "Epoch: 4193 loss_train: 0.1751 acc_train: 0.9005 acc_val: 0.9778\n",
      "Epoch: 4194 loss_train: 0.1868 acc_train: 0.8968 acc_val: 0.9778\n",
      "Epoch: 4195 loss_train: 0.1811 acc_train: 0.8946 acc_val: 0.9778\n",
      "Epoch: 4196 loss_train: 0.2024 acc_train: 0.8790 acc_val: 0.9778\n",
      "Epoch: 4197 loss_train: 0.1778 acc_train: 0.8805 acc_val: 0.9778\n",
      "Epoch: 4198 loss_train: 0.1771 acc_train: 0.8938 acc_val: 0.9778\n",
      "Epoch: 4199 loss_train: 0.2013 acc_train: 0.8782 acc_val: 0.9778\n",
      "Epoch: 4200 loss_train: 0.1821 acc_train: 0.9035 acc_val: 0.9778\n",
      "Epoch: 4201 loss_train: 0.1932 acc_train: 0.8924 acc_val: 0.9778\n",
      "Epoch: 4202 loss_train: 0.1827 acc_train: 0.8968 acc_val: 0.9778\n",
      "Epoch: 4203 loss_train: 0.1858 acc_train: 0.9035 acc_val: 0.9778\n",
      "Epoch: 4204 loss_train: 0.1931 acc_train: 0.8864 acc_val: 0.9778\n",
      "Epoch: 4205 loss_train: 0.2015 acc_train: 0.8716 acc_val: 0.9778\n",
      "Epoch: 4206 loss_train: 0.2051 acc_train: 0.8834 acc_val: 0.9778\n",
      "Epoch: 4207 loss_train: 0.2006 acc_train: 0.8857 acc_val: 0.9778\n",
      "Epoch: 4208 loss_train: 0.2003 acc_train: 0.8931 acc_val: 0.9778\n",
      "Epoch: 4209 loss_train: 0.1775 acc_train: 0.8886 acc_val: 0.9778\n",
      "Epoch: 4210 loss_train: 0.1921 acc_train: 0.8849 acc_val: 0.9778\n",
      "Epoch: 4211 loss_train: 0.1981 acc_train: 0.8731 acc_val: 0.9778\n",
      "Epoch: 4212 loss_train: 0.2073 acc_train: 0.8797 acc_val: 0.9778\n",
      "Epoch: 4213 loss_train: 0.2054 acc_train: 0.8775 acc_val: 0.9778\n",
      "Epoch: 4214 loss_train: 0.1873 acc_train: 0.8924 acc_val: 0.9778\n",
      "Epoch: 4215 loss_train: 0.1959 acc_train: 0.8775 acc_val: 0.9778\n",
      "Epoch: 4216 loss_train: 0.1944 acc_train: 0.8842 acc_val: 0.9778\n",
      "Epoch: 4217 loss_train: 0.1963 acc_train: 0.8790 acc_val: 0.9778\n",
      "Epoch: 4218 loss_train: 0.1751 acc_train: 0.8983 acc_val: 0.9778\n",
      "Epoch: 4219 loss_train: 0.1920 acc_train: 0.8872 acc_val: 0.9778\n",
      "Epoch: 4220 loss_train: 0.1869 acc_train: 0.8886 acc_val: 0.9778\n",
      "Epoch: 4221 loss_train: 0.1833 acc_train: 0.8864 acc_val: 0.9778\n",
      "Epoch: 4222 loss_train: 0.2000 acc_train: 0.8768 acc_val: 0.9778\n",
      "Epoch: 4223 loss_train: 0.1868 acc_train: 0.8916 acc_val: 0.9778\n",
      "Epoch: 4224 loss_train: 0.1981 acc_train: 0.8834 acc_val: 0.9778\n",
      "Epoch: 4225 loss_train: 0.1752 acc_train: 0.9027 acc_val: 0.9778\n",
      "Epoch: 4226 loss_train: 0.2018 acc_train: 0.8820 acc_val: 0.9778\n",
      "Epoch: 4227 loss_train: 0.1861 acc_train: 0.8879 acc_val: 0.9778\n",
      "Epoch: 4228 loss_train: 0.1933 acc_train: 0.8797 acc_val: 0.9778\n",
      "Epoch: 4229 loss_train: 0.2000 acc_train: 0.8827 acc_val: 0.9756\n",
      "Epoch: 4230 loss_train: 0.1980 acc_train: 0.8760 acc_val: 0.9756\n",
      "Epoch: 4231 loss_train: 0.2009 acc_train: 0.8738 acc_val: 0.9756\n",
      "Epoch: 4232 loss_train: 0.1871 acc_train: 0.8901 acc_val: 0.9756\n",
      "Epoch: 4233 loss_train: 0.1856 acc_train: 0.8916 acc_val: 0.9756\n",
      "Epoch: 4234 loss_train: 0.1738 acc_train: 0.9035 acc_val: 0.9756\n",
      "Epoch: 4235 loss_train: 0.1980 acc_train: 0.8857 acc_val: 0.9756\n",
      "Epoch: 4236 loss_train: 0.1962 acc_train: 0.8872 acc_val: 0.9756\n",
      "Epoch: 4237 loss_train: 0.1889 acc_train: 0.8909 acc_val: 0.9756\n",
      "Epoch: 4238 loss_train: 0.1957 acc_train: 0.8812 acc_val: 0.9756\n",
      "Epoch: 4239 loss_train: 0.1859 acc_train: 0.8968 acc_val: 0.9756\n",
      "Epoch: 4240 loss_train: 0.1898 acc_train: 0.8760 acc_val: 0.9756\n",
      "Epoch: 4241 loss_train: 0.1887 acc_train: 0.8901 acc_val: 0.9756\n",
      "Epoch: 4242 loss_train: 0.1940 acc_train: 0.8849 acc_val: 0.9756\n",
      "Epoch: 4243 loss_train: 0.1877 acc_train: 0.8857 acc_val: 0.9756\n",
      "Epoch: 4244 loss_train: 0.1618 acc_train: 0.8968 acc_val: 0.9756\n",
      "Epoch: 4245 loss_train: 0.1979 acc_train: 0.8864 acc_val: 0.9756\n",
      "Epoch: 4246 loss_train: 0.1612 acc_train: 0.9042 acc_val: 0.9756\n",
      "Epoch: 4247 loss_train: 0.1949 acc_train: 0.8872 acc_val: 0.9756\n",
      "Epoch: 4248 loss_train: 0.1918 acc_train: 0.8916 acc_val: 0.9756\n",
      "Epoch: 4249 loss_train: 0.1743 acc_train: 0.9042 acc_val: 0.9756\n",
      "Epoch: 4250 loss_train: 0.2028 acc_train: 0.8834 acc_val: 0.9756\n",
      "Epoch: 4251 loss_train: 0.1841 acc_train: 0.8931 acc_val: 0.9756\n",
      "Epoch: 4252 loss_train: 0.1716 acc_train: 0.9020 acc_val: 0.9756\n",
      "Epoch: 4253 loss_train: 0.1840 acc_train: 0.8953 acc_val: 0.9756\n",
      "Epoch: 4254 loss_train: 0.1965 acc_train: 0.8864 acc_val: 0.9756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4255 loss_train: 0.2044 acc_train: 0.8872 acc_val: 0.9756\n",
      "Epoch: 4256 loss_train: 0.1896 acc_train: 0.8753 acc_val: 0.9756\n",
      "Epoch: 4257 loss_train: 0.1817 acc_train: 0.8857 acc_val: 0.9756\n",
      "Epoch: 4258 loss_train: 0.1931 acc_train: 0.8805 acc_val: 0.9756\n",
      "Epoch: 4259 loss_train: 0.1850 acc_train: 0.8968 acc_val: 0.9756\n",
      "Epoch: 4260 loss_train: 0.1797 acc_train: 0.8976 acc_val: 0.9756\n",
      "Epoch: 4261 loss_train: 0.2268 acc_train: 0.8708 acc_val: 0.9756\n",
      "Epoch: 4262 loss_train: 0.2032 acc_train: 0.8805 acc_val: 0.9756\n",
      "Epoch: 4263 loss_train: 0.1825 acc_train: 0.8931 acc_val: 0.9756\n",
      "Epoch: 4264 loss_train: 0.1767 acc_train: 0.8901 acc_val: 0.9756\n",
      "Epoch: 4265 loss_train: 0.1960 acc_train: 0.8879 acc_val: 0.9756\n",
      "Epoch: 4266 loss_train: 0.1724 acc_train: 0.8983 acc_val: 0.9756\n",
      "Epoch: 4267 loss_train: 0.1769 acc_train: 0.8976 acc_val: 0.9756\n",
      "Epoch: 4268 loss_train: 0.1828 acc_train: 0.8946 acc_val: 0.9756\n",
      "Epoch: 4269 loss_train: 0.1890 acc_train: 0.8768 acc_val: 0.9756\n",
      "Epoch: 4270 loss_train: 0.2107 acc_train: 0.8760 acc_val: 0.9756\n",
      "Epoch: 4271 loss_train: 0.1591 acc_train: 0.9050 acc_val: 0.9756\n",
      "Epoch: 4272 loss_train: 0.1863 acc_train: 0.8946 acc_val: 0.9756\n",
      "Epoch: 4273 loss_train: 0.1934 acc_train: 0.8857 acc_val: 0.9756\n",
      "Epoch: 4274 loss_train: 0.1666 acc_train: 0.9042 acc_val: 0.9756\n",
      "Epoch: 4275 loss_train: 0.1930 acc_train: 0.8775 acc_val: 0.9756\n",
      "Epoch: 4276 loss_train: 0.1858 acc_train: 0.8924 acc_val: 0.9756\n",
      "Epoch: 4277 loss_train: 0.2000 acc_train: 0.8864 acc_val: 0.9756\n",
      "Epoch: 4278 loss_train: 0.1721 acc_train: 0.9005 acc_val: 0.9756\n",
      "Epoch: 4279 loss_train: 0.1810 acc_train: 0.8931 acc_val: 0.9756\n",
      "Epoch: 4280 loss_train: 0.2044 acc_train: 0.8768 acc_val: 0.9756\n",
      "Epoch: 4281 loss_train: 0.1816 acc_train: 0.8909 acc_val: 0.9756\n",
      "Epoch: 4282 loss_train: 0.1846 acc_train: 0.8916 acc_val: 0.9756\n",
      "Epoch: 4283 loss_train: 0.1827 acc_train: 0.8976 acc_val: 0.9756\n",
      "Epoch: 4284 loss_train: 0.1976 acc_train: 0.8872 acc_val: 0.9756\n",
      "Epoch: 4285 loss_train: 0.1621 acc_train: 0.9057 acc_val: 0.9756\n",
      "Epoch: 4286 loss_train: 0.1907 acc_train: 0.8938 acc_val: 0.9756\n",
      "Epoch: 4287 loss_train: 0.1821 acc_train: 0.8990 acc_val: 0.9756\n",
      "Epoch: 4288 loss_train: 0.1726 acc_train: 0.9027 acc_val: 0.9756\n",
      "Epoch: 4289 loss_train: 0.1986 acc_train: 0.8842 acc_val: 0.9756\n",
      "Epoch: 4290 loss_train: 0.1904 acc_train: 0.8805 acc_val: 0.9756\n",
      "Epoch: 4291 loss_train: 0.1774 acc_train: 0.8872 acc_val: 0.9756\n",
      "Epoch: 4292 loss_train: 0.1998 acc_train: 0.8812 acc_val: 0.9756\n",
      "Epoch: 4293 loss_train: 0.1920 acc_train: 0.8842 acc_val: 0.9756\n",
      "Epoch: 4294 loss_train: 0.2039 acc_train: 0.8760 acc_val: 0.9756\n",
      "Epoch: 4295 loss_train: 0.2110 acc_train: 0.8797 acc_val: 0.9756\n",
      "Epoch: 4296 loss_train: 0.1874 acc_train: 0.8976 acc_val: 0.9756\n",
      "Epoch: 4297 loss_train: 0.1734 acc_train: 0.8894 acc_val: 0.9756\n",
      "Epoch: 4298 loss_train: 0.1993 acc_train: 0.8820 acc_val: 0.9756\n",
      "Epoch: 4299 loss_train: 0.1800 acc_train: 0.8946 acc_val: 0.9756\n",
      "Epoch: 4300 loss_train: 0.1844 acc_train: 0.8864 acc_val: 0.9756\n",
      "Epoch: 4301 loss_train: 0.1765 acc_train: 0.8909 acc_val: 0.9756\n",
      "Epoch: 4302 loss_train: 0.1944 acc_train: 0.8834 acc_val: 0.9756\n",
      "Epoch: 4303 loss_train: 0.1882 acc_train: 0.8820 acc_val: 0.9756\n",
      "Epoch: 4304 loss_train: 0.1968 acc_train: 0.8686 acc_val: 0.9756\n",
      "Epoch: 4305 loss_train: 0.2234 acc_train: 0.8834 acc_val: 0.9756\n",
      "Epoch: 4306 loss_train: 0.1796 acc_train: 0.8983 acc_val: 0.9756\n",
      "Epoch: 4307 loss_train: 0.1876 acc_train: 0.8879 acc_val: 0.9756\n",
      "Epoch: 4308 loss_train: 0.1663 acc_train: 0.9050 acc_val: 0.9756\n",
      "Epoch: 4309 loss_train: 1.9594 acc_train: 0.8924 acc_val: 0.9756\n",
      "Epoch: 4310 loss_train: 0.1840 acc_train: 0.8827 acc_val: 0.9756\n",
      "Epoch: 4311 loss_train: 0.1821 acc_train: 0.8983 acc_val: 0.9756\n",
      "Epoch: 4312 loss_train: 0.1895 acc_train: 0.8879 acc_val: 0.9733\n",
      "Epoch: 4313 loss_train: 0.1878 acc_train: 0.8938 acc_val: 0.9733\n",
      "Epoch: 4314 loss_train: 0.2080 acc_train: 0.8805 acc_val: 0.9733\n",
      "Epoch: 4315 loss_train: 18.1797 acc_train: 0.8864 acc_val: 0.9733\n",
      "Epoch: 4316 loss_train: 0.1921 acc_train: 0.8931 acc_val: 0.9756\n",
      "Epoch: 4317 loss_train: 0.1840 acc_train: 0.8946 acc_val: 0.9756\n",
      "Epoch: 4318 loss_train: 0.1709 acc_train: 0.8990 acc_val: 0.9756\n",
      "Epoch: 4319 loss_train: 0.1838 acc_train: 0.8976 acc_val: 0.9756\n",
      "Epoch: 4320 loss_train: 0.2009 acc_train: 0.8790 acc_val: 0.9756\n",
      "Epoch: 4321 loss_train: 2.1811 acc_train: 0.8938 acc_val: 0.9756\n",
      "Epoch: 4322 loss_train: 0.1834 acc_train: 0.8916 acc_val: 0.9756\n",
      "Epoch: 4323 loss_train: 1.4414 acc_train: 0.8731 acc_val: 0.9756\n",
      "Epoch: 4324 loss_train: 0.5955 acc_train: 0.8990 acc_val: 0.9756\n",
      "Epoch: 4325 loss_train: 0.2010 acc_train: 0.8872 acc_val: 0.9756\n",
      "Epoch: 4326 loss_train: 0.1856 acc_train: 0.8872 acc_val: 0.9756\n",
      "Epoch: 4327 loss_train: 0.1759 acc_train: 0.8990 acc_val: 0.9756\n",
      "Epoch: 4328 loss_train: 1.3361 acc_train: 0.8990 acc_val: 0.9756\n",
      "Epoch: 4329 loss_train: 0.1964 acc_train: 0.8790 acc_val: 0.9756\n",
      "Epoch: 4330 loss_train: 0.1726 acc_train: 0.8976 acc_val: 0.9756\n",
      "Epoch: 4331 loss_train: 0.1830 acc_train: 0.8990 acc_val: 0.9756\n",
      "Epoch: 4332 loss_train: 0.1689 acc_train: 0.8953 acc_val: 0.9756\n",
      "Epoch: 4333 loss_train: 0.1778 acc_train: 0.8938 acc_val: 0.9756\n",
      "Epoch: 4334 loss_train: 0.1718 acc_train: 0.9050 acc_val: 0.9733\n",
      "Epoch: 4335 loss_train: 8.4576 acc_train: 0.8924 acc_val: 0.9778\n",
      "Epoch: 4336 loss_train: 1.9888 acc_train: 0.8805 acc_val: 0.9778\n",
      "Epoch: 4337 loss_train: 1.7151 acc_train: 0.8857 acc_val: 0.9778\n",
      "Epoch: 4338 loss_train: 0.1818 acc_train: 0.8968 acc_val: 0.9756\n",
      "Epoch: 4339 loss_train: 0.1827 acc_train: 0.8946 acc_val: 0.9756\n",
      "Epoch: 4340 loss_train: 0.1785 acc_train: 0.8946 acc_val: 0.9756\n",
      "Epoch: 4341 loss_train: 0.1884 acc_train: 0.8990 acc_val: 0.9756\n",
      "Epoch: 4342 loss_train: 0.1923 acc_train: 0.8990 acc_val: 0.9756\n",
      "Epoch: 4343 loss_train: 1.4476 acc_train: 0.8842 acc_val: 0.9733\n",
      "Epoch: 4344 loss_train: 2.8731 acc_train: 0.8879 acc_val: 0.9756\n",
      "Epoch: 4345 loss_train: 0.2035 acc_train: 0.8708 acc_val: 0.9756\n",
      "Epoch: 4346 loss_train: 0.2000 acc_train: 0.8820 acc_val: 0.9756\n",
      "Epoch: 4347 loss_train: 0.2273 acc_train: 0.8760 acc_val: 0.9756\n",
      "Epoch: 4348 loss_train: 0.1886 acc_train: 0.8775 acc_val: 0.9756\n",
      "Epoch: 4349 loss_train: 1.1513 acc_train: 0.8894 acc_val: 0.9733\n",
      "Epoch: 4350 loss_train: 0.1859 acc_train: 0.9005 acc_val: 0.9733\n",
      "Epoch: 4351 loss_train: 0.1936 acc_train: 0.8753 acc_val: 0.9733\n",
      "Epoch: 4352 loss_train: 0.1877 acc_train: 0.8990 acc_val: 0.9733\n",
      "Epoch: 4353 loss_train: 7.9437 acc_train: 0.8938 acc_val: 0.9733\n",
      "Epoch: 4354 loss_train: 0.2097 acc_train: 0.8716 acc_val: 0.9733\n",
      "Epoch: 4355 loss_train: 0.1717 acc_train: 0.9065 acc_val: 0.9733\n",
      "Epoch: 4356 loss_train: 0.1983 acc_train: 0.8753 acc_val: 0.9756\n",
      "Epoch: 4357 loss_train: 0.2024 acc_train: 0.8834 acc_val: 0.9756\n",
      "Epoch: 4358 loss_train: 0.2046 acc_train: 0.8857 acc_val: 0.9756\n",
      "Epoch: 4359 loss_train: 2.3106 acc_train: 0.8909 acc_val: 0.9756\n",
      "Epoch: 4360 loss_train: 0.1675 acc_train: 0.8998 acc_val: 0.9756\n",
      "Epoch: 4361 loss_train: 0.1933 acc_train: 0.8790 acc_val: 0.9733\n",
      "Epoch: 4362 loss_train: 0.1826 acc_train: 0.8894 acc_val: 0.9733\n",
      "Epoch: 4363 loss_train: 0.1971 acc_train: 0.8901 acc_val: 0.9733\n",
      "Epoch: 4364 loss_train: 0.1878 acc_train: 0.8864 acc_val: 0.9733\n",
      "Epoch: 4365 loss_train: 0.1966 acc_train: 0.8909 acc_val: 0.9733\n",
      "Epoch: 4366 loss_train: 0.3585 acc_train: 0.9020 acc_val: 0.9733\n",
      "Epoch: 4367 loss_train: 0.2032 acc_train: 0.8775 acc_val: 0.9733\n",
      "Epoch: 4368 loss_train: 0.1827 acc_train: 0.8886 acc_val: 0.9733\n",
      "Epoch: 4369 loss_train: 3.3794 acc_train: 0.8931 acc_val: 0.9733\n",
      "Epoch: 4370 loss_train: 0.1941 acc_train: 0.8857 acc_val: 0.9756\n",
      "Epoch: 4371 loss_train: 0.1843 acc_train: 0.8879 acc_val: 0.9756\n",
      "Epoch: 4372 loss_train: 0.2438 acc_train: 0.8976 acc_val: 0.9778\n",
      "Epoch: 4373 loss_train: 0.1794 acc_train: 0.8931 acc_val: 0.9778\n",
      "Epoch: 4374 loss_train: 0.1848 acc_train: 0.8924 acc_val: 0.9778\n",
      "Epoch: 4375 loss_train: 0.3938 acc_train: 0.8901 acc_val: 0.9778\n",
      "Epoch: 4376 loss_train: 0.1780 acc_train: 0.8834 acc_val: 0.9756\n",
      "Epoch: 4377 loss_train: 0.1839 acc_train: 0.8901 acc_val: 0.9756\n",
      "Epoch: 4378 loss_train: 0.1865 acc_train: 0.8805 acc_val: 0.9756\n",
      "Epoch: 4379 loss_train: 0.1890 acc_train: 0.8768 acc_val: 0.9756\n",
      "Epoch: 4380 loss_train: 1.7180 acc_train: 0.8879 acc_val: 0.9756\n",
      "Epoch: 4381 loss_train: 0.2103 acc_train: 0.8775 acc_val: 0.9756\n",
      "Epoch: 4382 loss_train: 5.4380 acc_train: 0.8983 acc_val: 0.9778\n",
      "Epoch: 4383 loss_train: 0.1998 acc_train: 0.8782 acc_val: 0.9756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4384 loss_train: 0.1870 acc_train: 0.8953 acc_val: 0.9756\n",
      "Epoch: 4385 loss_train: 1.2294 acc_train: 0.8931 acc_val: 0.9756\n",
      "Epoch: 4386 loss_train: 1.1392 acc_train: 0.8857 acc_val: 0.9756\n",
      "Epoch: 4387 loss_train: 0.2013 acc_train: 0.8708 acc_val: 0.9756\n",
      "Epoch: 4388 loss_train: 0.1630 acc_train: 0.9005 acc_val: 0.9756\n",
      "Epoch: 4389 loss_train: 0.1775 acc_train: 0.8938 acc_val: 0.9756\n",
      "Epoch: 4390 loss_train: 0.1850 acc_train: 0.8909 acc_val: 0.9733\n",
      "Epoch: 4391 loss_train: 0.1741 acc_train: 0.8931 acc_val: 0.9733\n",
      "Epoch: 4392 loss_train: 0.4969 acc_train: 0.8857 acc_val: 0.9733\n",
      "Epoch: 4393 loss_train: 0.1796 acc_train: 0.8976 acc_val: 0.9756\n",
      "Epoch: 4394 loss_train: 6.2919 acc_train: 0.8775 acc_val: 0.9756\n",
      "Epoch: 4395 loss_train: 7.6319 acc_train: 0.8901 acc_val: 0.9756\n",
      "Epoch: 4396 loss_train: 0.1880 acc_train: 0.8916 acc_val: 0.9778\n",
      "Epoch: 4397 loss_train: 0.1884 acc_train: 0.8894 acc_val: 0.9778\n",
      "Epoch: 4398 loss_train: 0.1868 acc_train: 0.8946 acc_val: 0.9778\n",
      "Epoch: 4399 loss_train: 9.6958 acc_train: 0.8894 acc_val: 0.9756\n",
      "Epoch: 4400 loss_train: 0.1957 acc_train: 0.8842 acc_val: 0.9756\n",
      "Epoch: 4401 loss_train: 0.1860 acc_train: 0.8842 acc_val: 0.9756\n",
      "Epoch: 4402 loss_train: 0.1902 acc_train: 0.8834 acc_val: 0.9756\n",
      "Epoch: 4403 loss_train: 10.8486 acc_train: 0.8842 acc_val: 0.9756\n",
      "Epoch: 4404 loss_train: 0.1810 acc_train: 0.8938 acc_val: 0.9756\n",
      "Epoch: 4405 loss_train: 0.1972 acc_train: 0.8812 acc_val: 0.9756\n",
      "Epoch: 4406 loss_train: 10.2258 acc_train: 0.8886 acc_val: 0.9756\n",
      "Epoch: 4407 loss_train: 0.1896 acc_train: 0.8953 acc_val: 0.9756\n",
      "Epoch: 4408 loss_train: 0.1934 acc_train: 0.8805 acc_val: 0.9756\n",
      "Epoch: 4409 loss_train: 1.2310 acc_train: 0.9035 acc_val: 0.9756\n",
      "Epoch: 4410 loss_train: 0.1836 acc_train: 0.8901 acc_val: 0.9756\n",
      "Epoch: 4411 loss_train: 0.1996 acc_train: 0.8820 acc_val: 0.9756\n",
      "Epoch: 4412 loss_train: 0.1856 acc_train: 0.8894 acc_val: 0.9733\n",
      "Epoch: 4413 loss_train: 0.1737 acc_train: 0.8990 acc_val: 0.9733\n",
      "Epoch: 4414 loss_train: 3.4719 acc_train: 0.8872 acc_val: 0.9733\n",
      "Epoch: 4415 loss_train: 0.1932 acc_train: 0.8857 acc_val: 0.9733\n",
      "Epoch: 4416 loss_train: 1.4969 acc_train: 0.8938 acc_val: 0.9733\n",
      "Epoch: 4417 loss_train: 3.0523 acc_train: 0.8842 acc_val: 0.9733\n",
      "Epoch: 4418 loss_train: 2.3088 acc_train: 0.8849 acc_val: 0.9733\n",
      "Epoch: 4419 loss_train: 0.1861 acc_train: 0.8886 acc_val: 0.9756\n",
      "Epoch: 4420 loss_train: 0.1792 acc_train: 0.8946 acc_val: 0.9756\n",
      "Epoch: 4421 loss_train: 0.1820 acc_train: 0.8901 acc_val: 0.9756\n",
      "Epoch: 4422 loss_train: 0.2021 acc_train: 0.8768 acc_val: 0.9756\n",
      "Epoch: 4423 loss_train: 1.7093 acc_train: 0.8983 acc_val: 0.9756\n",
      "Epoch: 4424 loss_train: 0.1853 acc_train: 0.8901 acc_val: 0.9756\n",
      "Epoch: 4425 loss_train: 1.9587 acc_train: 0.8909 acc_val: 0.9756\n",
      "Epoch: 4426 loss_train: 0.4291 acc_train: 0.8753 acc_val: 0.9711\n",
      "Epoch: 4427 loss_train: 7.7308 acc_train: 0.8961 acc_val: 0.9778\n",
      "Epoch: 4428 loss_train: 0.1802 acc_train: 0.8849 acc_val: 0.9800\n",
      "Epoch: 4429 loss_train: 8.3370 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 4430 loss_train: 4.2608 acc_train: 0.8886 acc_val: 0.9800\n",
      "Epoch: 4431 loss_train: 0.1867 acc_train: 0.8842 acc_val: 0.9778\n",
      "Epoch: 4432 loss_train: 1.8064 acc_train: 0.8998 acc_val: 0.9778\n",
      "Epoch: 4433 loss_train: 7.0511 acc_train: 0.8760 acc_val: 0.9778\n",
      "Epoch: 4434 loss_train: 3.5676 acc_train: 0.8961 acc_val: 0.9778\n",
      "Epoch: 4435 loss_train: 0.1787 acc_train: 0.8938 acc_val: 0.9800\n",
      "Epoch: 4436 loss_train: 0.1942 acc_train: 0.8790 acc_val: 0.9733\n",
      "Epoch: 4437 loss_train: 18.3676 acc_train: 0.8946 acc_val: 0.9689\n",
      "Epoch: 4438 loss_train: 18.1410 acc_train: 0.9013 acc_val: 0.9733\n",
      "Epoch: 4439 loss_train: 4.1131 acc_train: 0.8924 acc_val: 0.9778\n",
      "Epoch: 4440 loss_train: 0.5569 acc_train: 0.8990 acc_val: 0.9778\n",
      "Epoch: 4441 loss_train: 0.2032 acc_train: 0.8990 acc_val: 0.9778\n",
      "Epoch: 4442 loss_train: 9.7745 acc_train: 0.8775 acc_val: 0.9756\n",
      "Epoch: 4443 loss_train: 11.0956 acc_train: 0.8953 acc_val: 0.9733\n",
      "Epoch: 4444 loss_train: 1.3939 acc_train: 0.8931 acc_val: 0.9733\n",
      "Epoch: 4445 loss_train: 6.3734 acc_train: 0.9020 acc_val: 0.9667\n",
      "Epoch: 4446 loss_train: 14.1583 acc_train: 0.8849 acc_val: 0.9711\n",
      "Epoch: 4447 loss_train: 2.4622 acc_train: 0.8820 acc_val: 0.9778\n",
      "Epoch: 4448 loss_train: 2.6813 acc_train: 0.8894 acc_val: 0.9800\n",
      "Epoch: 4449 loss_train: 0.2134 acc_train: 0.8753 acc_val: 0.9778\n",
      "Epoch: 4450 loss_train: 6.9052 acc_train: 0.8872 acc_val: 0.9778\n",
      "Epoch: 4451 loss_train: 16.2590 acc_train: 0.8753 acc_val: 0.9800\n",
      "Epoch: 4452 loss_train: 10.4785 acc_train: 0.8864 acc_val: 0.9756\n",
      "Epoch: 4453 loss_train: 16.3487 acc_train: 0.8857 acc_val: 0.9778\n",
      "Epoch: 4454 loss_train: 3.6526 acc_train: 0.8834 acc_val: 0.9778\n",
      "Epoch: 4455 loss_train: 0.1736 acc_train: 0.9065 acc_val: 0.9756\n",
      "Epoch: 4456 loss_train: 2.3991 acc_train: 0.8946 acc_val: 0.9733\n",
      "Epoch: 4457 loss_train: 27.1030 acc_train: 0.8723 acc_val: 0.9756\n",
      "Epoch: 4458 loss_train: 1.2784 acc_train: 0.8961 acc_val: 0.9733\n",
      "Epoch: 4459 loss_train: 5.6502 acc_train: 0.8879 acc_val: 0.9711\n",
      "Epoch: 4460 loss_train: 8.1907 acc_train: 0.8990 acc_val: 0.9689\n",
      "Epoch: 4461 loss_train: 11.1949 acc_train: 0.8753 acc_val: 0.9756\n",
      "Epoch: 4462 loss_train: 0.2042 acc_train: 0.8797 acc_val: 0.9756\n",
      "Epoch: 4463 loss_train: 0.1829 acc_train: 0.8886 acc_val: 0.9778\n",
      "Epoch: 4464 loss_train: 0.1806 acc_train: 0.8886 acc_val: 0.9778\n",
      "Epoch: 4465 loss_train: 2.1338 acc_train: 0.8872 acc_val: 0.9800\n",
      "Epoch: 4466 loss_train: 4.2015 acc_train: 0.8916 acc_val: 0.9800\n",
      "Epoch: 4467 loss_train: 0.1678 acc_train: 0.9027 acc_val: 0.9778\n",
      "Epoch: 4468 loss_train: 2.2420 acc_train: 0.8946 acc_val: 0.9778\n",
      "Epoch: 4469 loss_train: 0.1787 acc_train: 0.8879 acc_val: 0.9733\n",
      "Epoch: 4470 loss_train: 0.9399 acc_train: 0.8976 acc_val: 0.9667\n",
      "Epoch: 4471 loss_train: 3.3247 acc_train: 0.8976 acc_val: 0.9667\n",
      "Epoch: 4472 loss_train: 4.7938 acc_train: 0.8842 acc_val: 0.9711\n",
      "Epoch: 4473 loss_train: 2.0081 acc_train: 0.8894 acc_val: 0.9711\n",
      "Epoch: 4474 loss_train: 2.8892 acc_train: 0.8946 acc_val: 0.9711\n",
      "Epoch: 4475 loss_train: 0.1678 acc_train: 0.9042 acc_val: 0.9733\n",
      "Epoch: 4476 loss_train: 8.0951 acc_train: 0.8842 acc_val: 0.9756\n",
      "Epoch: 4477 loss_train: 3.7085 acc_train: 0.8834 acc_val: 0.9733\n",
      "Epoch: 4478 loss_train: 2.9205 acc_train: 0.9005 acc_val: 0.9667\n",
      "Epoch: 4479 loss_train: 3.1773 acc_train: 0.8864 acc_val: 0.9667\n",
      "Epoch: 4480 loss_train: 0.1829 acc_train: 0.8872 acc_val: 0.9667\n",
      "Epoch: 4481 loss_train: 8.5717 acc_train: 0.8938 acc_val: 0.9689\n",
      "Epoch: 4482 loss_train: 3.7911 acc_train: 0.8916 acc_val: 0.9689\n",
      "Epoch: 4483 loss_train: 0.4115 acc_train: 0.8938 acc_val: 0.9711\n",
      "Epoch: 4484 loss_train: 17.7774 acc_train: 0.8805 acc_val: 0.9689\n",
      "Epoch: 4485 loss_train: 0.2492 acc_train: 0.8827 acc_val: 0.9644\n",
      "Epoch: 4486 loss_train: 0.9110 acc_train: 0.8931 acc_val: 0.9689\n",
      "Epoch: 4487 loss_train: 5.8553 acc_train: 0.8909 acc_val: 0.9689\n",
      "Epoch: 4488 loss_train: 12.2338 acc_train: 0.8834 acc_val: 0.9667\n",
      "Epoch: 4489 loss_train: 0.1899 acc_train: 0.8812 acc_val: 0.9733\n",
      "Epoch: 4490 loss_train: 0.1726 acc_train: 0.9079 acc_val: 0.9756\n",
      "Epoch: 4491 loss_train: 0.4236 acc_train: 0.8879 acc_val: 0.9756\n",
      "Epoch: 4492 loss_train: 3.1311 acc_train: 0.8901 acc_val: 0.9756\n",
      "Epoch: 4493 loss_train: 0.2713 acc_train: 0.9020 acc_val: 0.9756\n",
      "Epoch: 4494 loss_train: 0.2037 acc_train: 0.8946 acc_val: 0.9756\n",
      "Epoch: 4495 loss_train: 2.3830 acc_train: 0.8998 acc_val: 0.9756\n",
      "Epoch: 4496 loss_train: 3.2184 acc_train: 0.8924 acc_val: 0.9756\n",
      "Epoch: 4497 loss_train: 0.1739 acc_train: 0.8946 acc_val: 0.9756\n",
      "Epoch: 4498 loss_train: 2.0957 acc_train: 0.8924 acc_val: 0.9733\n",
      "Epoch: 4499 loss_train: 0.1812 acc_train: 0.8894 acc_val: 0.9756\n",
      "Epoch: 4500 loss_train: 0.4981 acc_train: 0.9065 acc_val: 0.9756\n",
      "Epoch: 4501 loss_train: 2.0776 acc_train: 0.8968 acc_val: 0.9756\n",
      "Epoch: 4502 loss_train: 0.1931 acc_train: 0.8909 acc_val: 0.9733\n",
      "Epoch: 4503 loss_train: 1.8210 acc_train: 0.8805 acc_val: 0.9733\n",
      "Epoch: 4504 loss_train: 1.2032 acc_train: 0.8901 acc_val: 0.9756\n",
      "Epoch: 4505 loss_train: 1.9515 acc_train: 0.8924 acc_val: 0.9756\n",
      "Epoch: 4506 loss_train: 2.8001 acc_train: 0.8953 acc_val: 0.9733\n",
      "Epoch: 4507 loss_train: 0.3535 acc_train: 0.8909 acc_val: 0.9756\n",
      "Epoch: 4508 loss_train: 0.1687 acc_train: 0.8953 acc_val: 0.9756\n",
      "Epoch: 4509 loss_train: 0.8071 acc_train: 0.8976 acc_val: 0.9733\n",
      "Epoch: 4510 loss_train: 0.2062 acc_train: 0.8790 acc_val: 0.9733\n",
      "Epoch: 4511 loss_train: 0.1974 acc_train: 0.8797 acc_val: 0.9733\n",
      "Epoch: 4512 loss_train: 0.3573 acc_train: 0.8812 acc_val: 0.9733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4513 loss_train: 0.4520 acc_train: 0.8990 acc_val: 0.9733\n",
      "Epoch: 4514 loss_train: 0.2087 acc_train: 0.8716 acc_val: 0.9733\n",
      "Epoch: 4515 loss_train: 0.1841 acc_train: 0.8938 acc_val: 0.9733\n",
      "Epoch: 4516 loss_train: 0.1866 acc_train: 0.8872 acc_val: 0.9756\n",
      "Epoch: 4517 loss_train: 0.1888 acc_train: 0.8886 acc_val: 0.9711\n",
      "Epoch: 4518 loss_train: 1.4060 acc_train: 0.8731 acc_val: 0.9756\n",
      "Epoch: 4519 loss_train: 2.7366 acc_train: 0.8827 acc_val: 0.9733\n",
      "Epoch: 4520 loss_train: 0.1917 acc_train: 0.8938 acc_val: 0.9733\n",
      "Epoch: 4521 loss_train: 0.5870 acc_train: 0.9005 acc_val: 0.9733\n",
      "Epoch: 4522 loss_train: 0.1944 acc_train: 0.8886 acc_val: 0.9756\n",
      "Epoch: 4523 loss_train: 3.1927 acc_train: 0.8924 acc_val: 0.9756\n",
      "Epoch: 4524 loss_train: 1.0195 acc_train: 0.8864 acc_val: 0.9756\n",
      "Epoch: 4525 loss_train: 0.1855 acc_train: 0.8782 acc_val: 0.9756\n",
      "Epoch: 4526 loss_train: 0.1704 acc_train: 0.8909 acc_val: 0.9778\n",
      "Epoch: 4527 loss_train: 0.1975 acc_train: 0.8834 acc_val: 0.9778\n",
      "Epoch: 4528 loss_train: 1.4552 acc_train: 0.8968 acc_val: 0.9756\n",
      "Epoch: 4529 loss_train: 1.9755 acc_train: 0.8857 acc_val: 0.9756\n",
      "Epoch: 4530 loss_train: 0.1866 acc_train: 0.8894 acc_val: 0.9756\n",
      "Epoch: 4531 loss_train: 0.4550 acc_train: 0.8879 acc_val: 0.9756\n",
      "Epoch: 4532 loss_train: 5.0860 acc_train: 0.8968 acc_val: 0.9756\n",
      "Epoch: 4533 loss_train: 0.1895 acc_train: 0.8931 acc_val: 0.9733\n",
      "Epoch: 4534 loss_train: 0.1817 acc_train: 0.9005 acc_val: 0.9733\n",
      "Epoch: 4535 loss_train: 0.1809 acc_train: 0.8968 acc_val: 0.9756\n",
      "Epoch: 4536 loss_train: 2.5835 acc_train: 0.8931 acc_val: 0.9756\n",
      "Epoch: 4537 loss_train: 0.1866 acc_train: 0.8983 acc_val: 0.9756\n",
      "Epoch: 4538 loss_train: 0.1912 acc_train: 0.8938 acc_val: 0.9756\n",
      "Epoch: 4539 loss_train: 2.3568 acc_train: 0.8782 acc_val: 0.9756\n",
      "Epoch: 4540 loss_train: 0.1814 acc_train: 0.8894 acc_val: 0.9756\n",
      "Epoch: 4541 loss_train: 0.1909 acc_train: 0.8924 acc_val: 0.9756\n",
      "Epoch: 4542 loss_train: 0.1935 acc_train: 0.8805 acc_val: 0.9756\n",
      "Epoch: 4543 loss_train: 0.5306 acc_train: 0.9005 acc_val: 0.9756\n",
      "Epoch: 4544 loss_train: 0.2134 acc_train: 0.8768 acc_val: 0.9756\n",
      "Epoch: 4545 loss_train: 0.1873 acc_train: 0.8805 acc_val: 0.9733\n",
      "Epoch: 4546 loss_train: 0.1860 acc_train: 0.8901 acc_val: 0.9733\n",
      "Epoch: 4547 loss_train: 0.2049 acc_train: 0.8842 acc_val: 0.9733\n",
      "Epoch: 4548 loss_train: 0.2023 acc_train: 0.8775 acc_val: 0.9733\n",
      "Epoch: 4549 loss_train: 0.1781 acc_train: 0.8886 acc_val: 0.9733\n",
      "Epoch: 4550 loss_train: 0.8414 acc_train: 0.8909 acc_val: 0.9756\n",
      "Epoch: 4551 loss_train: 0.1834 acc_train: 0.8916 acc_val: 0.9778\n",
      "Epoch: 4552 loss_train: 0.1843 acc_train: 0.8849 acc_val: 0.9756\n",
      "Epoch: 4553 loss_train: 0.1890 acc_train: 0.8909 acc_val: 0.9733\n",
      "Epoch: 4554 loss_train: 2.7529 acc_train: 0.8968 acc_val: 0.9756\n",
      "Epoch: 4555 loss_train: 0.1833 acc_train: 0.8834 acc_val: 0.9756\n",
      "Epoch: 4556 loss_train: 0.3673 acc_train: 0.8797 acc_val: 0.9778\n",
      "Epoch: 4557 loss_train: 0.1830 acc_train: 0.8872 acc_val: 0.9756\n",
      "Epoch: 4558 loss_train: 1.9002 acc_train: 0.8924 acc_val: 0.9756\n",
      "Epoch: 4559 loss_train: 9.4252 acc_train: 0.9057 acc_val: 0.9756\n",
      "Epoch: 4560 loss_train: 0.3751 acc_train: 0.8938 acc_val: 0.9778\n",
      "Epoch: 4561 loss_train: 2.4690 acc_train: 0.8790 acc_val: 0.9756\n",
      "Epoch: 4562 loss_train: 0.1823 acc_train: 0.8976 acc_val: 0.9733\n",
      "Epoch: 4563 loss_train: 48.7611 acc_train: 0.8864 acc_val: 0.9756\n",
      "Epoch: 4564 loss_train: 0.1987 acc_train: 0.8827 acc_val: 0.9778\n",
      "Epoch: 4565 loss_train: 0.4397 acc_train: 0.8961 acc_val: 0.9733\n",
      "Epoch: 4566 loss_train: 21.9217 acc_train: 0.9005 acc_val: 0.9733\n",
      "Epoch: 4567 loss_train: 0.1819 acc_train: 0.8812 acc_val: 0.9733\n",
      "Epoch: 4568 loss_train: 9.7303 acc_train: 0.8990 acc_val: 0.9733\n",
      "Epoch: 4569 loss_train: 8.5598 acc_train: 0.8976 acc_val: 0.9733\n",
      "Epoch: 4570 loss_train: 6.4431 acc_train: 0.8968 acc_val: 0.9778\n",
      "Epoch: 4571 loss_train: 0.2746 acc_train: 0.8879 acc_val: 0.9778\n",
      "Epoch: 4572 loss_train: 13.0011 acc_train: 0.8805 acc_val: 0.9778\n",
      "Epoch: 4573 loss_train: 2.1442 acc_train: 0.9005 acc_val: 0.9778\n",
      "Epoch: 4574 loss_train: 0.1855 acc_train: 0.8961 acc_val: 0.9800\n",
      "Epoch: 4575 loss_train: 0.1930 acc_train: 0.8916 acc_val: 0.9778\n",
      "Epoch: 4576 loss_train: 0.2006 acc_train: 0.8879 acc_val: 0.9756\n",
      "Epoch: 4577 loss_train: 17.5560 acc_train: 0.9027 acc_val: 0.9733\n",
      "Epoch: 4578 loss_train: 5.9025 acc_train: 0.8998 acc_val: 0.9756\n",
      "Epoch: 4579 loss_train: 0.7427 acc_train: 0.8968 acc_val: 0.9756\n",
      "Epoch: 4580 loss_train: 0.1766 acc_train: 0.9020 acc_val: 0.9756\n",
      "Epoch: 4581 loss_train: 0.1793 acc_train: 0.8894 acc_val: 0.9756\n",
      "Epoch: 4582 loss_train: 2.1737 acc_train: 0.8797 acc_val: 0.9756\n",
      "Epoch: 4583 loss_train: 2.4846 acc_train: 0.8894 acc_val: 0.9756\n",
      "Epoch: 4584 loss_train: 2.4525 acc_train: 0.8901 acc_val: 0.9756\n",
      "Epoch: 4585 loss_train: 0.1897 acc_train: 0.8879 acc_val: 0.9733\n",
      "Epoch: 4586 loss_train: 0.1847 acc_train: 0.8894 acc_val: 0.9733\n",
      "Epoch: 4587 loss_train: 0.1933 acc_train: 0.8864 acc_val: 0.9756\n",
      "Epoch: 4588 loss_train: 0.1893 acc_train: 0.8894 acc_val: 0.9756\n",
      "Epoch: 4589 loss_train: 0.1681 acc_train: 0.8968 acc_val: 0.9756\n",
      "Epoch: 4590 loss_train: 0.1879 acc_train: 0.8894 acc_val: 0.9756\n",
      "Epoch: 4591 loss_train: 3.9342 acc_train: 0.8894 acc_val: 0.9756\n",
      "Epoch: 4592 loss_train: 17.4911 acc_train: 0.8693 acc_val: 0.9756\n",
      "Epoch: 4593 loss_train: 4.1701 acc_train: 0.8976 acc_val: 0.9733\n",
      "Epoch: 4594 loss_train: 7.0699 acc_train: 0.8886 acc_val: 0.9756\n",
      "Epoch: 4595 loss_train: 0.1965 acc_train: 0.8894 acc_val: 0.9756\n",
      "Epoch: 4596 loss_train: 0.1958 acc_train: 0.8805 acc_val: 0.9733\n",
      "Epoch: 4597 loss_train: 0.1795 acc_train: 0.9035 acc_val: 0.9733\n",
      "Epoch: 4598 loss_train: 0.1844 acc_train: 0.8946 acc_val: 0.9733\n",
      "Epoch: 4599 loss_train: 0.1868 acc_train: 0.8834 acc_val: 0.9733\n",
      "Epoch: 4600 loss_train: 5.3538 acc_train: 0.9035 acc_val: 0.9756\n",
      "Epoch: 4601 loss_train: 0.8232 acc_train: 0.8731 acc_val: 0.9733\n",
      "Epoch: 4602 loss_train: 4.0644 acc_train: 0.8976 acc_val: 0.9756\n",
      "Epoch: 4603 loss_train: 6.8565 acc_train: 0.8998 acc_val: 0.9756\n",
      "Epoch: 4604 loss_train: 0.2024 acc_train: 0.8775 acc_val: 0.9756\n",
      "Epoch: 4605 loss_train: 5.5788 acc_train: 0.8946 acc_val: 0.9733\n",
      "Epoch: 4606 loss_train: 0.2003 acc_train: 0.8857 acc_val: 0.9733\n",
      "Epoch: 4607 loss_train: 0.1816 acc_train: 0.8909 acc_val: 0.9733\n",
      "Epoch: 4608 loss_train: 0.2044 acc_train: 0.8834 acc_val: 0.9733\n",
      "Epoch: 4609 loss_train: 7.2366 acc_train: 0.8842 acc_val: 0.9733\n",
      "Epoch: 4610 loss_train: 0.1826 acc_train: 0.8961 acc_val: 0.9733\n",
      "Epoch: 4611 loss_train: 2.7314 acc_train: 0.8886 acc_val: 0.9733\n",
      "Epoch: 4612 loss_train: 0.1877 acc_train: 0.8924 acc_val: 0.9733\n",
      "Epoch: 4613 loss_train: 0.1688 acc_train: 0.8901 acc_val: 0.9733\n",
      "Epoch: 4614 loss_train: 1.3209 acc_train: 0.9042 acc_val: 0.9756\n",
      "Epoch: 4615 loss_train: 0.1885 acc_train: 0.8842 acc_val: 0.9733\n",
      "Epoch: 4616 loss_train: 0.7592 acc_train: 0.8775 acc_val: 0.9733\n",
      "Epoch: 4617 loss_train: 0.3226 acc_train: 0.8953 acc_val: 0.9733\n",
      "Epoch: 4618 loss_train: 1.4242 acc_train: 0.8745 acc_val: 0.9711\n",
      "Epoch: 4619 loss_train: 0.1895 acc_train: 0.8827 acc_val: 0.9711\n",
      "Epoch: 4620 loss_train: 0.4461 acc_train: 0.8864 acc_val: 0.9711\n",
      "Epoch: 4621 loss_train: 0.1636 acc_train: 0.9013 acc_val: 0.9733\n",
      "Epoch: 4622 loss_train: 0.1823 acc_train: 0.8924 acc_val: 0.9756\n",
      "Epoch: 4623 loss_train: 0.1709 acc_train: 0.9065 acc_val: 0.9756\n",
      "Epoch: 4624 loss_train: 0.1818 acc_train: 0.8894 acc_val: 0.9756\n",
      "Epoch: 4625 loss_train: 4.4130 acc_train: 0.8961 acc_val: 0.9756\n",
      "Epoch: 4626 loss_train: 0.1778 acc_train: 0.9020 acc_val: 0.9756\n",
      "Epoch: 4627 loss_train: 0.1933 acc_train: 0.8894 acc_val: 0.9756\n",
      "Epoch: 4628 loss_train: 0.1631 acc_train: 0.9169 acc_val: 0.9756\n",
      "Epoch: 4629 loss_train: 0.1979 acc_train: 0.8790 acc_val: 0.9756\n",
      "Epoch: 4630 loss_train: 0.1830 acc_train: 0.8879 acc_val: 0.9756\n",
      "Epoch: 4631 loss_train: 0.2858 acc_train: 0.9020 acc_val: 0.9756\n",
      "Epoch: 4632 loss_train: 0.1781 acc_train: 0.8879 acc_val: 0.9756\n",
      "Epoch: 4633 loss_train: 0.1713 acc_train: 0.8998 acc_val: 0.9756\n",
      "Epoch: 4634 loss_train: 0.1795 acc_train: 0.8909 acc_val: 0.9756\n",
      "Epoch: 4635 loss_train: 1.7357 acc_train: 0.8894 acc_val: 0.9756\n",
      "Epoch: 4636 loss_train: 0.2017 acc_train: 0.8812 acc_val: 0.9733\n",
      "Epoch: 4637 loss_train: 7.2381 acc_train: 0.8931 acc_val: 0.9733\n",
      "Epoch: 4638 loss_train: 3.4572 acc_train: 0.8894 acc_val: 0.9733\n",
      "Epoch: 4639 loss_train: 0.1863 acc_train: 0.8916 acc_val: 0.9711\n",
      "Epoch: 4640 loss_train: 0.1901 acc_train: 0.8849 acc_val: 0.9711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4641 loss_train: 5.9717 acc_train: 0.8768 acc_val: 0.9711\n",
      "Epoch: 4642 loss_train: 0.1943 acc_train: 0.8879 acc_val: 0.9711\n",
      "Epoch: 4643 loss_train: 0.1862 acc_train: 0.8990 acc_val: 0.9711\n",
      "Epoch: 4644 loss_train: 0.1831 acc_train: 0.8976 acc_val: 0.9711\n",
      "Epoch: 4645 loss_train: 0.1978 acc_train: 0.8849 acc_val: 0.9711\n",
      "Epoch: 4646 loss_train: 0.1856 acc_train: 0.8916 acc_val: 0.9711\n",
      "Epoch: 4647 loss_train: 0.1842 acc_train: 0.9005 acc_val: 0.9733\n",
      "Epoch: 4648 loss_train: 0.1863 acc_train: 0.8961 acc_val: 0.9733\n",
      "Epoch: 4649 loss_train: 0.1907 acc_train: 0.8901 acc_val: 0.9733\n",
      "Epoch: 4650 loss_train: 0.1622 acc_train: 0.9035 acc_val: 0.9733\n",
      "Epoch: 4651 loss_train: 1.9801 acc_train: 0.8916 acc_val: 0.9756\n",
      "Epoch: 4652 loss_train: 0.1818 acc_train: 0.8946 acc_val: 0.9756\n",
      "Epoch: 4653 loss_train: 0.1832 acc_train: 0.8894 acc_val: 0.9756\n",
      "Epoch: 4654 loss_train: 0.1887 acc_train: 0.8849 acc_val: 0.9756\n",
      "Epoch: 4655 loss_train: 0.1685 acc_train: 0.8946 acc_val: 0.9733\n",
      "Epoch: 4656 loss_train: 0.2066 acc_train: 0.8671 acc_val: 0.9733\n",
      "Epoch: 4657 loss_train: 0.4448 acc_train: 0.8931 acc_val: 0.9733\n",
      "Epoch: 4658 loss_train: 0.1855 acc_train: 0.8968 acc_val: 0.9756\n",
      "Epoch: 4659 loss_train: 0.1880 acc_train: 0.8953 acc_val: 0.9756\n",
      "Epoch: 4660 loss_train: 0.1839 acc_train: 0.8812 acc_val: 0.9756\n",
      "Epoch: 4661 loss_train: 0.1885 acc_train: 0.8879 acc_val: 0.9756\n",
      "Epoch: 4662 loss_train: 0.1948 acc_train: 0.8790 acc_val: 0.9756\n",
      "Epoch: 4663 loss_train: 0.1870 acc_train: 0.8976 acc_val: 0.9756\n",
      "Epoch: 4664 loss_train: 0.1885 acc_train: 0.8812 acc_val: 0.9756\n",
      "Epoch: 4665 loss_train: 0.1756 acc_train: 0.8990 acc_val: 0.9756\n",
      "Epoch: 4666 loss_train: 0.1873 acc_train: 0.8894 acc_val: 0.9756\n",
      "Epoch: 4667 loss_train: 0.1698 acc_train: 0.8909 acc_val: 0.9756\n",
      "Epoch: 4668 loss_train: 0.1806 acc_train: 0.9013 acc_val: 0.9778\n",
      "Epoch: 4669 loss_train: 0.1900 acc_train: 0.8901 acc_val: 0.9756\n",
      "Epoch: 4670 loss_train: 0.1758 acc_train: 0.8976 acc_val: 0.9756\n",
      "Epoch: 4671 loss_train: 0.1923 acc_train: 0.8916 acc_val: 0.9756\n",
      "Epoch: 4672 loss_train: 0.1815 acc_train: 0.8961 acc_val: 0.9756\n",
      "Epoch: 4673 loss_train: 0.1903 acc_train: 0.8983 acc_val: 0.9756\n",
      "Epoch: 4674 loss_train: 0.1712 acc_train: 0.9050 acc_val: 0.9756\n",
      "Epoch: 4675 loss_train: 2.1402 acc_train: 0.8938 acc_val: 0.9733\n",
      "Epoch: 4676 loss_train: 0.1624 acc_train: 0.9013 acc_val: 0.9733\n",
      "Epoch: 4677 loss_train: 0.1761 acc_train: 0.8901 acc_val: 0.9733\n",
      "Epoch: 4678 loss_train: 0.1857 acc_train: 0.8938 acc_val: 0.9733\n",
      "Epoch: 4679 loss_train: 0.1943 acc_train: 0.8961 acc_val: 0.9733\n",
      "Epoch: 4680 loss_train: 0.1771 acc_train: 0.8924 acc_val: 0.9733\n",
      "Epoch: 4681 loss_train: 0.1872 acc_train: 0.8968 acc_val: 0.9733\n",
      "Epoch: 4682 loss_train: 0.1858 acc_train: 0.8805 acc_val: 0.9756\n",
      "Epoch: 4683 loss_train: 0.1958 acc_train: 0.8805 acc_val: 0.9756\n",
      "Epoch: 4684 loss_train: 0.1717 acc_train: 0.8946 acc_val: 0.9756\n",
      "Epoch: 4685 loss_train: 0.1837 acc_train: 0.9005 acc_val: 0.9756\n",
      "Epoch: 4686 loss_train: 0.1874 acc_train: 0.8916 acc_val: 0.9756\n",
      "Epoch: 4687 loss_train: 0.1753 acc_train: 0.8953 acc_val: 0.9733\n",
      "Epoch: 4688 loss_train: 0.1677 acc_train: 0.9027 acc_val: 0.9733\n",
      "Epoch: 4689 loss_train: 0.1920 acc_train: 0.8879 acc_val: 0.9733\n",
      "Epoch: 4690 loss_train: 0.3072 acc_train: 0.8716 acc_val: 0.9733\n",
      "Epoch: 4691 loss_train: 0.1950 acc_train: 0.8894 acc_val: 0.9733\n",
      "Epoch: 4692 loss_train: 0.1748 acc_train: 0.8983 acc_val: 0.9756\n",
      "Epoch: 4693 loss_train: 1.1279 acc_train: 0.8961 acc_val: 0.9756\n",
      "Epoch: 4694 loss_train: 0.1842 acc_train: 0.8931 acc_val: 0.9733\n",
      "Epoch: 4695 loss_train: 0.2054 acc_train: 0.8738 acc_val: 0.9733\n",
      "Epoch: 4696 loss_train: 0.1781 acc_train: 0.9020 acc_val: 0.9756\n",
      "Epoch: 4697 loss_train: 0.1955 acc_train: 0.8782 acc_val: 0.9756\n",
      "Epoch: 4698 loss_train: 0.1814 acc_train: 0.8976 acc_val: 0.9756\n",
      "Epoch: 4699 loss_train: 0.1715 acc_train: 0.8968 acc_val: 0.9756\n",
      "Epoch: 4700 loss_train: 0.1955 acc_train: 0.8916 acc_val: 0.9756\n",
      "Epoch: 4701 loss_train: 2.2585 acc_train: 0.8968 acc_val: 0.9756\n",
      "Epoch: 4702 loss_train: 0.1844 acc_train: 0.8901 acc_val: 0.9778\n",
      "Epoch: 4703 loss_train: 0.1722 acc_train: 0.8901 acc_val: 0.9778\n",
      "Epoch: 4704 loss_train: 0.1974 acc_train: 0.8872 acc_val: 0.9756\n",
      "Epoch: 4705 loss_train: 0.1905 acc_train: 0.8864 acc_val: 0.9756\n",
      "Epoch: 4706 loss_train: 0.1785 acc_train: 0.8998 acc_val: 0.9756\n",
      "Epoch: 4707 loss_train: 1.5382 acc_train: 0.8916 acc_val: 0.9756\n",
      "Epoch: 4708 loss_train: 0.1952 acc_train: 0.8872 acc_val: 0.9778\n",
      "Epoch: 4709 loss_train: 0.1796 acc_train: 0.8983 acc_val: 0.9778\n",
      "Epoch: 4710 loss_train: 0.1886 acc_train: 0.8827 acc_val: 0.9778\n",
      "Epoch: 4711 loss_train: 0.1831 acc_train: 0.8901 acc_val: 0.9756\n",
      "Epoch: 4712 loss_train: 0.1870 acc_train: 0.8953 acc_val: 0.9756\n",
      "Epoch: 4713 loss_train: 0.1658 acc_train: 0.9027 acc_val: 0.9756\n",
      "Epoch: 4714 loss_train: 0.1621 acc_train: 0.9087 acc_val: 0.9756\n",
      "Epoch: 4715 loss_train: 0.1680 acc_train: 0.8961 acc_val: 0.9756\n",
      "Epoch: 4716 loss_train: 0.1733 acc_train: 0.8983 acc_val: 0.9756\n",
      "Epoch: 4717 loss_train: 0.1715 acc_train: 0.8931 acc_val: 0.9756\n",
      "Epoch: 4718 loss_train: 0.1846 acc_train: 0.8886 acc_val: 0.9756\n",
      "Epoch: 4719 loss_train: 0.1889 acc_train: 0.8849 acc_val: 0.9756\n",
      "Epoch: 4720 loss_train: 0.1930 acc_train: 0.8797 acc_val: 0.9756\n",
      "Epoch: 4721 loss_train: 0.1682 acc_train: 0.8968 acc_val: 0.9756\n",
      "Epoch: 4722 loss_train: 1.6188 acc_train: 0.8909 acc_val: 0.9756\n",
      "Epoch: 4723 loss_train: 0.1925 acc_train: 0.8872 acc_val: 0.9756\n",
      "Epoch: 4724 loss_train: 0.1771 acc_train: 0.9013 acc_val: 0.9756\n",
      "Epoch: 4725 loss_train: 0.1763 acc_train: 0.8931 acc_val: 0.9756\n",
      "Epoch: 4726 loss_train: 0.1722 acc_train: 0.8901 acc_val: 0.9756\n",
      "Epoch: 4727 loss_train: 0.1564 acc_train: 0.9013 acc_val: 0.9733\n",
      "Epoch: 4728 loss_train: 0.1961 acc_train: 0.8805 acc_val: 0.9733\n",
      "Epoch: 4729 loss_train: 0.1906 acc_train: 0.8938 acc_val: 0.9733\n",
      "Epoch: 4730 loss_train: 0.1732 acc_train: 0.9035 acc_val: 0.9733\n",
      "Epoch: 4731 loss_train: 0.3857 acc_train: 0.8857 acc_val: 0.9733\n",
      "Epoch: 4732 loss_train: 0.1890 acc_train: 0.8924 acc_val: 0.9733\n",
      "Epoch: 4733 loss_train: 0.1615 acc_train: 0.9005 acc_val: 0.9733\n",
      "Epoch: 4734 loss_train: 0.1952 acc_train: 0.8872 acc_val: 0.9733\n",
      "Epoch: 4735 loss_train: 0.2034 acc_train: 0.8857 acc_val: 0.9756\n",
      "Epoch: 4736 loss_train: 0.1811 acc_train: 0.8916 acc_val: 0.9756\n",
      "Epoch: 4737 loss_train: 0.1932 acc_train: 0.8827 acc_val: 0.9756\n",
      "Epoch: 4738 loss_train: 0.1898 acc_train: 0.8946 acc_val: 0.9756\n",
      "Epoch: 4739 loss_train: 0.1841 acc_train: 0.8886 acc_val: 0.9756\n",
      "Epoch: 4740 loss_train: 0.2038 acc_train: 0.8768 acc_val: 0.9756\n",
      "Epoch: 4741 loss_train: 0.1781 acc_train: 0.8953 acc_val: 0.9756\n",
      "Epoch: 4742 loss_train: 0.1940 acc_train: 0.8820 acc_val: 0.9756\n",
      "Epoch: 4743 loss_train: 0.1655 acc_train: 0.8938 acc_val: 0.9756\n",
      "Epoch: 4744 loss_train: 0.1961 acc_train: 0.8872 acc_val: 0.9756\n",
      "Epoch: 4745 loss_train: 0.1822 acc_train: 0.8968 acc_val: 0.9756\n",
      "Epoch: 4746 loss_train: 0.1863 acc_train: 0.9013 acc_val: 0.9756\n",
      "Epoch: 4747 loss_train: 0.2019 acc_train: 0.8812 acc_val: 0.9756\n",
      "Epoch: 4748 loss_train: 0.1801 acc_train: 0.9020 acc_val: 0.9756\n",
      "Epoch: 4749 loss_train: 0.1958 acc_train: 0.8834 acc_val: 0.9756\n",
      "Epoch: 4750 loss_train: 0.1918 acc_train: 0.8879 acc_val: 0.9756\n",
      "Epoch: 4751 loss_train: 0.2027 acc_train: 0.8775 acc_val: 0.9756\n",
      "Epoch: 4752 loss_train: 0.1669 acc_train: 0.9005 acc_val: 0.9756\n",
      "Epoch: 4753 loss_train: 0.1853 acc_train: 0.8924 acc_val: 0.9756\n",
      "Epoch: 4754 loss_train: 0.1830 acc_train: 0.8886 acc_val: 0.9756\n",
      "Epoch: 4755 loss_train: 0.1868 acc_train: 0.8916 acc_val: 0.9756\n",
      "Epoch: 4756 loss_train: 0.1864 acc_train: 0.8938 acc_val: 0.9756\n",
      "Epoch: 4757 loss_train: 0.1746 acc_train: 0.8946 acc_val: 0.9756\n",
      "Epoch: 4758 loss_train: 0.1801 acc_train: 0.8894 acc_val: 0.9756\n",
      "Epoch: 4759 loss_train: 0.1916 acc_train: 0.8953 acc_val: 0.9756\n",
      "Epoch: 4760 loss_train: 0.1830 acc_train: 0.8864 acc_val: 0.9756\n",
      "Epoch: 4761 loss_train: 0.1901 acc_train: 0.8857 acc_val: 0.9756\n",
      "Epoch: 4762 loss_train: 0.1872 acc_train: 0.8938 acc_val: 0.9756\n",
      "Epoch: 4763 loss_train: 0.2073 acc_train: 0.8738 acc_val: 0.9756\n",
      "Epoch: 4764 loss_train: 0.1736 acc_train: 0.8931 acc_val: 0.9756\n",
      "Epoch: 4765 loss_train: 0.1760 acc_train: 0.8976 acc_val: 0.9756\n",
      "Epoch: 4766 loss_train: 0.2034 acc_train: 0.8827 acc_val: 0.9756\n",
      "Epoch: 4767 loss_train: 0.1784 acc_train: 0.8894 acc_val: 0.9756\n",
      "Epoch: 4768 loss_train: 0.1915 acc_train: 0.8879 acc_val: 0.9756\n",
      "Epoch: 4769 loss_train: 0.2110 acc_train: 0.8731 acc_val: 0.9756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4770 loss_train: 0.1929 acc_train: 0.8953 acc_val: 0.9756\n",
      "Epoch: 4771 loss_train: 0.2104 acc_train: 0.8768 acc_val: 0.9756\n",
      "Epoch: 4772 loss_train: 0.1866 acc_train: 0.8916 acc_val: 0.9756\n",
      "Epoch: 4773 loss_train: 0.1765 acc_train: 0.8924 acc_val: 0.9756\n",
      "Epoch: 4774 loss_train: 0.1687 acc_train: 0.8976 acc_val: 0.9756\n",
      "Epoch: 4775 loss_train: 0.1715 acc_train: 0.9005 acc_val: 0.9756\n",
      "Epoch: 4776 loss_train: 0.1765 acc_train: 0.8968 acc_val: 0.9756\n",
      "Epoch: 4777 loss_train: 0.1827 acc_train: 0.8872 acc_val: 0.9756\n",
      "Epoch: 4778 loss_train: 0.1792 acc_train: 0.8909 acc_val: 0.9756\n",
      "Epoch: 4779 loss_train: 0.1692 acc_train: 0.8938 acc_val: 0.9756\n",
      "Epoch: 4780 loss_train: 0.1911 acc_train: 0.8775 acc_val: 0.9756\n",
      "Epoch: 4781 loss_train: 0.1893 acc_train: 0.8901 acc_val: 0.9756\n",
      "Epoch: 4782 loss_train: 0.1871 acc_train: 0.8857 acc_val: 0.9756\n",
      "Epoch: 4783 loss_train: 0.1791 acc_train: 0.8938 acc_val: 0.9756\n",
      "Epoch: 4784 loss_train: 0.1886 acc_train: 0.8946 acc_val: 0.9756\n",
      "Epoch: 4785 loss_train: 0.1610 acc_train: 0.9146 acc_val: 0.9756\n",
      "Epoch: 4786 loss_train: 0.1932 acc_train: 0.8842 acc_val: 0.9756\n",
      "Epoch: 4787 loss_train: 0.1905 acc_train: 0.8931 acc_val: 0.9756\n",
      "Epoch: 4788 loss_train: 0.1782 acc_train: 0.8909 acc_val: 0.9756\n",
      "Epoch: 4789 loss_train: 0.1781 acc_train: 0.8946 acc_val: 0.9756\n",
      "Epoch: 4790 loss_train: 0.2062 acc_train: 0.8797 acc_val: 0.9756\n",
      "Epoch: 4791 loss_train: 0.1905 acc_train: 0.8797 acc_val: 0.9756\n",
      "Epoch: 4792 loss_train: 0.1960 acc_train: 0.8820 acc_val: 0.9756\n",
      "Epoch: 4793 loss_train: 0.1846 acc_train: 0.8894 acc_val: 0.9756\n",
      "Epoch: 4794 loss_train: 0.1883 acc_train: 0.8901 acc_val: 0.9756\n",
      "Epoch: 4795 loss_train: 0.1902 acc_train: 0.8820 acc_val: 0.9756\n",
      "Epoch: 4796 loss_train: 0.1747 acc_train: 0.8990 acc_val: 0.9756\n",
      "Epoch: 4797 loss_train: 0.1899 acc_train: 0.8857 acc_val: 0.9756\n",
      "Epoch: 4798 loss_train: 0.1916 acc_train: 0.8805 acc_val: 0.9756\n",
      "Epoch: 4799 loss_train: 0.1685 acc_train: 0.9005 acc_val: 0.9756\n",
      "Epoch: 4800 loss_train: 0.1900 acc_train: 0.8879 acc_val: 0.9756\n",
      "Epoch: 4801 loss_train: 0.2062 acc_train: 0.8679 acc_val: 0.9756\n",
      "Epoch: 4802 loss_train: 0.1613 acc_train: 0.9065 acc_val: 0.9756\n",
      "Epoch: 4803 loss_train: 0.2052 acc_train: 0.8872 acc_val: 0.9756\n",
      "Epoch: 4804 loss_train: 0.1900 acc_train: 0.8909 acc_val: 0.9756\n",
      "Epoch: 4805 loss_train: 0.1999 acc_train: 0.8805 acc_val: 0.9756\n",
      "Epoch: 4806 loss_train: 0.1837 acc_train: 0.8901 acc_val: 0.9756\n",
      "Epoch: 4807 loss_train: 0.2070 acc_train: 0.8701 acc_val: 0.9756\n",
      "Epoch: 4808 loss_train: 0.1784 acc_train: 0.8879 acc_val: 0.9756\n",
      "Epoch: 4809 loss_train: 0.1802 acc_train: 0.8857 acc_val: 0.9756\n",
      "Epoch: 4810 loss_train: 0.1548 acc_train: 0.9139 acc_val: 0.9756\n",
      "Epoch: 4811 loss_train: 0.1933 acc_train: 0.8775 acc_val: 0.9756\n",
      "Epoch: 4812 loss_train: 0.1948 acc_train: 0.8886 acc_val: 0.9756\n",
      "Epoch: 4813 loss_train: 0.1856 acc_train: 0.8953 acc_val: 0.9756\n",
      "Epoch: 4814 loss_train: 0.1899 acc_train: 0.8849 acc_val: 0.9756\n",
      "Epoch: 4815 loss_train: 0.1897 acc_train: 0.8864 acc_val: 0.9756\n",
      "Epoch: 4816 loss_train: 0.1790 acc_train: 0.8976 acc_val: 0.9756\n",
      "Epoch: 4817 loss_train: 0.1820 acc_train: 0.8953 acc_val: 0.9756\n",
      "Epoch: 4818 loss_train: 0.1792 acc_train: 0.8983 acc_val: 0.9756\n",
      "Epoch: 4819 loss_train: 0.1733 acc_train: 0.8983 acc_val: 0.9756\n",
      "Epoch: 4820 loss_train: 0.1875 acc_train: 0.8924 acc_val: 0.9756\n",
      "Epoch: 4821 loss_train: 0.1755 acc_train: 0.9050 acc_val: 0.9756\n",
      "Epoch: 4822 loss_train: 0.1845 acc_train: 0.8924 acc_val: 0.9756\n",
      "Epoch: 4823 loss_train: 0.1836 acc_train: 0.8901 acc_val: 0.9756\n",
      "Epoch: 4824 loss_train: 0.1782 acc_train: 0.8931 acc_val: 0.9756\n",
      "Epoch: 4825 loss_train: 0.1904 acc_train: 0.8886 acc_val: 0.9756\n",
      "Epoch: 4826 loss_train: 0.3046 acc_train: 0.8894 acc_val: 0.9756\n",
      "Epoch: 4827 loss_train: 0.1817 acc_train: 0.8998 acc_val: 0.9756\n",
      "Epoch: 4828 loss_train: 0.1915 acc_train: 0.8849 acc_val: 0.9756\n",
      "Epoch: 4829 loss_train: 0.1851 acc_train: 0.8938 acc_val: 0.9756\n",
      "Epoch: 4830 loss_train: 0.1910 acc_train: 0.8834 acc_val: 0.9756\n",
      "Epoch: 4831 loss_train: 0.1701 acc_train: 0.8909 acc_val: 0.9756\n",
      "Epoch: 4832 loss_train: 1.5260 acc_train: 0.8946 acc_val: 0.9756\n",
      "Epoch: 4833 loss_train: 0.9851 acc_train: 0.8924 acc_val: 0.9756\n",
      "Epoch: 4834 loss_train: 0.1893 acc_train: 0.8886 acc_val: 0.9756\n",
      "Epoch: 4835 loss_train: 0.2019 acc_train: 0.8894 acc_val: 0.9756\n",
      "Epoch: 4836 loss_train: 0.1749 acc_train: 0.9005 acc_val: 0.9756\n",
      "Epoch: 4837 loss_train: 0.1856 acc_train: 0.8924 acc_val: 0.9733\n",
      "Epoch: 4838 loss_train: 0.2022 acc_train: 0.8857 acc_val: 0.9733\n",
      "Epoch: 4839 loss_train: 0.1741 acc_train: 0.9013 acc_val: 0.9733\n",
      "Epoch: 4840 loss_train: 0.1821 acc_train: 0.8894 acc_val: 0.9733\n",
      "Epoch: 4841 loss_train: 0.1834 acc_train: 0.8820 acc_val: 0.9733\n",
      "Epoch: 4842 loss_train: 0.1785 acc_train: 0.8924 acc_val: 0.9733\n",
      "Epoch: 4843 loss_train: 0.1859 acc_train: 0.8946 acc_val: 0.9733\n",
      "Epoch: 4844 loss_train: 0.1926 acc_train: 0.8849 acc_val: 0.9733\n",
      "Epoch: 4845 loss_train: 0.1884 acc_train: 0.8886 acc_val: 0.9733\n",
      "Epoch: 4846 loss_train: 0.2037 acc_train: 0.8760 acc_val: 0.9733\n",
      "Epoch: 4847 loss_train: 0.1931 acc_train: 0.8961 acc_val: 0.9733\n",
      "Epoch: 4848 loss_train: 0.1846 acc_train: 0.8886 acc_val: 0.9733\n",
      "Epoch: 4849 loss_train: 0.3103 acc_train: 0.8938 acc_val: 0.9733\n",
      "Epoch: 4850 loss_train: 0.1787 acc_train: 0.8916 acc_val: 0.9733\n",
      "Epoch: 4851 loss_train: 0.1748 acc_train: 0.8938 acc_val: 0.9733\n",
      "Epoch: 4852 loss_train: 0.1770 acc_train: 0.8894 acc_val: 0.9733\n",
      "Epoch: 4853 loss_train: 0.1810 acc_train: 0.8916 acc_val: 0.9778\n",
      "Epoch: 4854 loss_train: 0.1935 acc_train: 0.8857 acc_val: 0.9778\n",
      "Epoch: 4855 loss_train: 0.1626 acc_train: 0.8990 acc_val: 0.9778\n",
      "Epoch: 4856 loss_train: 0.1808 acc_train: 0.8849 acc_val: 0.9778\n",
      "Epoch: 4857 loss_train: 0.1981 acc_train: 0.8849 acc_val: 0.9756\n",
      "Epoch: 4858 loss_train: 0.1889 acc_train: 0.8797 acc_val: 0.9756\n",
      "Epoch: 4859 loss_train: 0.1835 acc_train: 0.8976 acc_val: 0.9756\n",
      "Epoch: 4860 loss_train: 0.1704 acc_train: 0.9065 acc_val: 0.9756\n",
      "Epoch: 4861 loss_train: 0.1712 acc_train: 0.9020 acc_val: 0.9756\n",
      "Epoch: 4862 loss_train: 0.1982 acc_train: 0.8879 acc_val: 0.9756\n",
      "Epoch: 4863 loss_train: 0.1849 acc_train: 0.8916 acc_val: 0.9756\n",
      "Epoch: 4864 loss_train: 0.1602 acc_train: 0.9013 acc_val: 0.9756\n",
      "Epoch: 4865 loss_train: 0.1975 acc_train: 0.8864 acc_val: 0.9756\n",
      "Epoch: 4866 loss_train: 0.1781 acc_train: 0.8901 acc_val: 0.9756\n",
      "Epoch: 4867 loss_train: 0.1791 acc_train: 0.8976 acc_val: 0.9756\n",
      "Epoch: 4868 loss_train: 0.1923 acc_train: 0.8857 acc_val: 0.9756\n",
      "Epoch: 4869 loss_train: 1.8673 acc_train: 0.8998 acc_val: 0.9756\n",
      "Epoch: 4870 loss_train: 0.1779 acc_train: 0.8946 acc_val: 0.9756\n",
      "Epoch: 4871 loss_train: 0.1893 acc_train: 0.8872 acc_val: 0.9756\n",
      "Epoch: 4872 loss_train: 0.1860 acc_train: 0.8968 acc_val: 0.9756\n",
      "Epoch: 4873 loss_train: 0.1740 acc_train: 0.9087 acc_val: 0.9778\n",
      "Epoch: 4874 loss_train: 0.1907 acc_train: 0.8894 acc_val: 0.9756\n",
      "Epoch: 4875 loss_train: 0.2106 acc_train: 0.8760 acc_val: 0.9756\n",
      "Epoch: 4876 loss_train: 0.2046 acc_train: 0.8782 acc_val: 0.9733\n",
      "Epoch: 4877 loss_train: 0.1977 acc_train: 0.8782 acc_val: 0.9733\n",
      "Epoch: 4878 loss_train: 0.1735 acc_train: 0.8909 acc_val: 0.9733\n",
      "Epoch: 4879 loss_train: 0.1864 acc_train: 0.8924 acc_val: 0.9733\n",
      "Epoch: 4880 loss_train: 0.2032 acc_train: 0.8805 acc_val: 0.9733\n",
      "Epoch: 4881 loss_train: 0.1947 acc_train: 0.8782 acc_val: 0.9733\n",
      "Epoch: 4882 loss_train: 0.1972 acc_train: 0.8894 acc_val: 0.9733\n",
      "Epoch: 4883 loss_train: 0.1879 acc_train: 0.8931 acc_val: 0.9733\n",
      "Epoch: 4884 loss_train: 0.2017 acc_train: 0.8924 acc_val: 0.9733\n",
      "Epoch: 4885 loss_train: 0.1755 acc_train: 0.9020 acc_val: 0.9733\n",
      "Epoch: 4886 loss_train: 0.1822 acc_train: 0.8894 acc_val: 0.9733\n",
      "Epoch: 4887 loss_train: 0.1854 acc_train: 0.8909 acc_val: 0.9733\n",
      "Epoch: 4888 loss_train: 0.1923 acc_train: 0.8857 acc_val: 0.9733\n",
      "Epoch: 4889 loss_train: 0.1958 acc_train: 0.8894 acc_val: 0.9733\n",
      "Epoch: 4890 loss_train: 0.1778 acc_train: 0.8909 acc_val: 0.9733\n",
      "Epoch: 4891 loss_train: 0.1865 acc_train: 0.8768 acc_val: 0.9733\n",
      "Epoch: 4892 loss_train: 0.1844 acc_train: 0.8916 acc_val: 0.9733\n",
      "Epoch: 4893 loss_train: 0.2058 acc_train: 0.8857 acc_val: 0.9733\n",
      "Epoch: 4894 loss_train: 0.1761 acc_train: 0.9005 acc_val: 0.9733\n",
      "Epoch: 4895 loss_train: 0.1757 acc_train: 0.9005 acc_val: 0.9733\n",
      "Epoch: 4896 loss_train: 0.1930 acc_train: 0.8946 acc_val: 0.9733\n",
      "Epoch: 4897 loss_train: 0.1887 acc_train: 0.8901 acc_val: 0.9733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4898 loss_train: 0.1758 acc_train: 0.8938 acc_val: 0.9733\n",
      "Epoch: 4899 loss_train: 0.1909 acc_train: 0.8909 acc_val: 0.9733\n",
      "Epoch: 4900 loss_train: 0.1756 acc_train: 0.9050 acc_val: 0.9733\n",
      "Epoch: 4901 loss_train: 0.1707 acc_train: 0.8998 acc_val: 0.9733\n",
      "Epoch: 4902 loss_train: 0.1805 acc_train: 0.8924 acc_val: 0.9733\n",
      "Epoch: 4903 loss_train: 0.1896 acc_train: 0.8909 acc_val: 0.9733\n",
      "Epoch: 4904 loss_train: 0.1819 acc_train: 0.8976 acc_val: 0.9733\n",
      "Epoch: 4905 loss_train: 0.1937 acc_train: 0.8872 acc_val: 0.9733\n",
      "Epoch: 4906 loss_train: 0.1741 acc_train: 0.8946 acc_val: 0.9733\n",
      "Epoch: 4907 loss_train: 0.1848 acc_train: 0.8901 acc_val: 0.9733\n",
      "Epoch: 4908 loss_train: 0.1918 acc_train: 0.8857 acc_val: 0.9733\n",
      "Epoch: 4909 loss_train: 0.1617 acc_train: 0.9050 acc_val: 0.9733\n",
      "Epoch: 4910 loss_train: 0.1784 acc_train: 0.9005 acc_val: 0.9733\n",
      "Epoch: 4911 loss_train: 0.1776 acc_train: 0.8976 acc_val: 0.9733\n",
      "Epoch: 4912 loss_train: 0.2004 acc_train: 0.8738 acc_val: 0.9733\n",
      "Epoch: 4913 loss_train: 0.1901 acc_train: 0.8834 acc_val: 0.9733\n",
      "Epoch: 4914 loss_train: 0.2359 acc_train: 0.9042 acc_val: 0.9733\n",
      "Epoch: 4915 loss_train: 0.1964 acc_train: 0.8731 acc_val: 0.9733\n",
      "Epoch: 4916 loss_train: 0.1976 acc_train: 0.8864 acc_val: 0.9733\n",
      "Epoch: 4917 loss_train: 0.1826 acc_train: 0.8968 acc_val: 0.9756\n",
      "Epoch: 4918 loss_train: 0.1845 acc_train: 0.8946 acc_val: 0.9756\n",
      "Epoch: 4919 loss_train: 0.1920 acc_train: 0.8983 acc_val: 0.9756\n",
      "Epoch: 4920 loss_train: 0.1922 acc_train: 0.8872 acc_val: 0.9733\n",
      "Epoch: 4921 loss_train: 0.1818 acc_train: 0.8894 acc_val: 0.9733\n",
      "Epoch: 4922 loss_train: 0.1809 acc_train: 0.8968 acc_val: 0.9733\n",
      "Epoch: 4923 loss_train: 0.2011 acc_train: 0.8886 acc_val: 0.9733\n",
      "Epoch: 4924 loss_train: 0.2006 acc_train: 0.8812 acc_val: 0.9733\n",
      "Epoch: 4925 loss_train: 0.1628 acc_train: 0.9027 acc_val: 0.9733\n",
      "Epoch: 4926 loss_train: 0.1915 acc_train: 0.8820 acc_val: 0.9733\n",
      "Epoch: 4927 loss_train: 0.1881 acc_train: 0.8946 acc_val: 0.9733\n",
      "Epoch: 4928 loss_train: 0.1971 acc_train: 0.8834 acc_val: 0.9733\n",
      "Epoch: 4929 loss_train: 0.1734 acc_train: 0.8931 acc_val: 0.9733\n",
      "Epoch: 4930 loss_train: 0.1849 acc_train: 0.8857 acc_val: 0.9733\n",
      "Epoch: 4931 loss_train: 0.1691 acc_train: 0.8864 acc_val: 0.9756\n",
      "Epoch: 4932 loss_train: 0.2013 acc_train: 0.8894 acc_val: 0.9756\n",
      "Epoch: 4933 loss_train: 0.2013 acc_train: 0.8805 acc_val: 0.9756\n",
      "Epoch: 4934 loss_train: 0.2054 acc_train: 0.8745 acc_val: 0.9756\n",
      "Epoch: 4935 loss_train: 0.1801 acc_train: 0.8953 acc_val: 0.9756\n",
      "Epoch: 4936 loss_train: 0.1882 acc_train: 0.8909 acc_val: 0.9756\n",
      "Epoch: 4937 loss_train: 0.1878 acc_train: 0.8872 acc_val: 0.9756\n",
      "Epoch: 4938 loss_train: 0.1899 acc_train: 0.8916 acc_val: 0.9756\n",
      "Epoch: 4939 loss_train: 0.1740 acc_train: 0.9087 acc_val: 0.9756\n",
      "Epoch: 4940 loss_train: 0.1845 acc_train: 0.8894 acc_val: 0.9756\n",
      "Epoch: 4941 loss_train: 0.1720 acc_train: 0.9042 acc_val: 0.9756\n",
      "Epoch: 4942 loss_train: 0.1837 acc_train: 0.8864 acc_val: 0.9756\n",
      "Epoch: 4943 loss_train: 0.2078 acc_train: 0.8782 acc_val: 0.9756\n",
      "Epoch: 4944 loss_train: 0.8869 acc_train: 0.8953 acc_val: 0.9756\n",
      "Epoch: 4945 loss_train: 0.1994 acc_train: 0.8872 acc_val: 0.9756\n",
      "Epoch: 4946 loss_train: 0.1856 acc_train: 0.8961 acc_val: 0.9756\n",
      "Epoch: 4947 loss_train: 0.1928 acc_train: 0.8805 acc_val: 0.9756\n",
      "Epoch: 4948 loss_train: 0.1779 acc_train: 0.8820 acc_val: 0.9778\n",
      "Epoch: 4949 loss_train: 0.1813 acc_train: 0.8924 acc_val: 0.9778\n",
      "Epoch: 4950 loss_train: 0.1907 acc_train: 0.8901 acc_val: 0.9778\n",
      "Epoch: 4951 loss_train: 1.4151 acc_train: 0.8797 acc_val: 0.9778\n",
      "Epoch: 4952 loss_train: 0.1980 acc_train: 0.8827 acc_val: 0.9778\n",
      "Epoch: 4953 loss_train: 0.1948 acc_train: 0.8812 acc_val: 0.9756\n",
      "Epoch: 4954 loss_train: 0.1850 acc_train: 0.8938 acc_val: 0.9756\n",
      "Epoch: 4955 loss_train: 0.1876 acc_train: 0.8864 acc_val: 0.9756\n",
      "Epoch: 4956 loss_train: 0.1871 acc_train: 0.8834 acc_val: 0.9756\n",
      "Epoch: 4957 loss_train: 0.1923 acc_train: 0.8775 acc_val: 0.9756\n",
      "Epoch: 4958 loss_train: 0.2011 acc_train: 0.8790 acc_val: 0.9756\n",
      "Epoch: 4959 loss_train: 0.1768 acc_train: 0.8909 acc_val: 0.9756\n",
      "Epoch: 4960 loss_train: 12.2105 acc_train: 0.8879 acc_val: 0.9756\n",
      "Epoch: 4961 loss_train: 0.1859 acc_train: 0.8983 acc_val: 0.9756\n",
      "Epoch: 4962 loss_train: 0.1805 acc_train: 0.8909 acc_val: 0.9756\n",
      "Epoch: 4963 loss_train: 0.1939 acc_train: 0.8872 acc_val: 0.9756\n",
      "Epoch: 4964 loss_train: 0.1880 acc_train: 0.8849 acc_val: 0.9756\n",
      "Epoch: 4965 loss_train: 0.1868 acc_train: 0.8901 acc_val: 0.9756\n",
      "Epoch: 4966 loss_train: 0.1781 acc_train: 0.8909 acc_val: 0.9756\n",
      "Epoch: 4967 loss_train: 0.1751 acc_train: 0.8968 acc_val: 0.9756\n",
      "Epoch: 4968 loss_train: 0.1891 acc_train: 0.8916 acc_val: 0.9756\n",
      "Epoch: 4969 loss_train: 0.1692 acc_train: 0.8916 acc_val: 0.9756\n",
      "Epoch: 4970 loss_train: 0.1941 acc_train: 0.8805 acc_val: 0.9733\n",
      "Epoch: 4971 loss_train: 0.1914 acc_train: 0.8842 acc_val: 0.9733\n",
      "Epoch: 4972 loss_train: 0.1789 acc_train: 0.8946 acc_val: 0.9733\n",
      "Epoch: 4973 loss_train: 0.1981 acc_train: 0.8805 acc_val: 0.9733\n",
      "Epoch: 4974 loss_train: 0.1984 acc_train: 0.8790 acc_val: 0.9733\n",
      "Epoch: 4975 loss_train: 0.1944 acc_train: 0.8901 acc_val: 0.9733\n",
      "Epoch: 4976 loss_train: 0.1848 acc_train: 0.8916 acc_val: 0.9733\n",
      "Epoch: 4977 loss_train: 0.2111 acc_train: 0.8790 acc_val: 0.9733\n",
      "Epoch: 4978 loss_train: 0.1766 acc_train: 0.9005 acc_val: 0.9733\n",
      "Epoch: 4979 loss_train: 0.1784 acc_train: 0.8924 acc_val: 0.9733\n",
      "Epoch: 4980 loss_train: 0.1797 acc_train: 0.8894 acc_val: 0.9733\n",
      "Epoch: 4981 loss_train: 0.1978 acc_train: 0.8842 acc_val: 0.9733\n",
      "Epoch: 4982 loss_train: 0.1944 acc_train: 0.8931 acc_val: 0.9733\n",
      "Epoch: 4983 loss_train: 0.1686 acc_train: 0.9079 acc_val: 0.9733\n",
      "Epoch: 4984 loss_train: 0.1716 acc_train: 0.8990 acc_val: 0.9733\n",
      "Epoch: 4985 loss_train: 0.2065 acc_train: 0.8745 acc_val: 0.9733\n",
      "Epoch: 4986 loss_train: 0.1853 acc_train: 0.8872 acc_val: 0.9733\n",
      "Epoch: 4987 loss_train: 0.1923 acc_train: 0.8864 acc_val: 0.9733\n",
      "Epoch: 4988 loss_train: 0.1936 acc_train: 0.8946 acc_val: 0.9733\n",
      "Epoch: 4989 loss_train: 0.1903 acc_train: 0.8805 acc_val: 0.9733\n",
      "Epoch: 4990 loss_train: 0.2022 acc_train: 0.8834 acc_val: 0.9733\n",
      "Epoch: 4991 loss_train: 0.2031 acc_train: 0.8775 acc_val: 0.9733\n",
      "Epoch: 4992 loss_train: 0.1717 acc_train: 0.8961 acc_val: 0.9733\n",
      "Epoch: 4993 loss_train: 0.1846 acc_train: 0.8894 acc_val: 0.9733\n",
      "Epoch: 4994 loss_train: 0.1818 acc_train: 0.8938 acc_val: 0.9733\n",
      "Epoch: 4995 loss_train: 0.1856 acc_train: 0.8968 acc_val: 0.9733\n",
      "Epoch: 4996 loss_train: 0.1705 acc_train: 0.8901 acc_val: 0.9733\n",
      "Epoch: 4997 loss_train: 0.1772 acc_train: 0.8924 acc_val: 0.9733\n",
      "Epoch: 4998 loss_train: 0.1722 acc_train: 0.9065 acc_val: 0.9733\n",
      "Epoch: 4999 loss_train: 0.2133 acc_train: 0.8693 acc_val: 0.9733\n",
      "Epoch: 5000 loss_train: 0.1756 acc_train: 0.8961 acc_val: 0.9733\n",
      "Optimization Finished!\n",
      "Total time elapsed: 133.3544s\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "t_total = time.time()\n",
    "for epoch in range(5000):\n",
    "    train(epoch,model)\n",
    "print(\"Optimization Finished!\")\n",
    "print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
